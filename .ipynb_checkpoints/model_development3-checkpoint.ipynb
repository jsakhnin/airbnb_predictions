{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>all_year_avail</th>\n",
       "      <th>low_avail</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_Williamsburg</th>\n",
       "      <th>neighbourhood_Willowbrook</th>\n",
       "      <th>neighbourhood_Windsor Terrace</th>\n",
       "      <th>neighbourhood_Woodhaven</th>\n",
       "      <th>neighbourhood_Woodlawn</th>\n",
       "      <th>neighbourhood_Woodrow</th>\n",
       "      <th>neighbourhood_Woodside</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>3021</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude     price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237  5.010635               1                  9   \n",
       "1  40.75362  -73.98377  5.420535               1                 45   \n",
       "2  40.80902  -73.94190  5.017280               3                  0   \n",
       "3  40.68514  -73.95976  4.499810               1                270   \n",
       "4  40.79851  -73.94399  4.394449              10                  9   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0         2762               0.21                               6   \n",
       "1         2976               0.38                               2   \n",
       "2            0               0.00                               1   \n",
       "3         3021               4.64                               1   \n",
       "4         2793               0.10                               1   \n",
       "\n",
       "   all_year_avail  low_avail  ...  neighbourhood_Williamsburg  \\\n",
       "0            True      False  ...                           0   \n",
       "1            True      False  ...                           0   \n",
       "2            True      False  ...                           0   \n",
       "3           False      False  ...                           0   \n",
       "4           False       True  ...                           0   \n",
       "\n",
       "   neighbourhood_Willowbrook  neighbourhood_Windsor Terrace  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   neighbourhood_Woodhaven  neighbourhood_Woodlawn  neighbourhood_Woodrow  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "\n",
       "   neighbourhood_Woodside  room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                       0                          0                       1   \n",
       "1                       0                          1                       0   \n",
       "2                       0                          0                       1   \n",
       "3                       0                          1                       0   \n",
       "4                       0                          1                       0   \n",
       "\n",
       "   room_type_Shared room  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/processed_data_nyc.csv', index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.price\n",
    "X_wp = np.asarray(data).astype(np.float32)\n",
    "data = data.drop(['price'], axis=1)\n",
    "\n",
    "X = np.asarray(data).astype(np.float32)\n",
    "y = np.asarray(y).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: (39014, 239)\n",
      "Testing Dataset: (9754, 239)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "print(\"Testing Dataset: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.075362e+01, -7.398377e+01,  5.420535e+00,  1.000000e+00,\n",
       "        4.500000e+01,  2.976000e+03,  3.800000e-01,  2.000000e+00,\n",
       "        1.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  1.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  1.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00,\n",
       "        0.000000e+00,  1.000000e+00,  0.000000e+00,  0.000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Data with GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the General Adversarial Network (GAN) using the GAN class in 'models.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = models.GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GAN model consists of a generator and a discriminator, which work together to generate and check the generated data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               61696     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 240)               61680     \n",
      "=================================================================\n",
      "Total params: 123,376\n",
      "Trainable params: 123,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               123392    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 558,593\n",
      "Trainable params: 558,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate data using the train function. The first input is the real data, the second is the number of training epochs, and the third is the number of samples to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 12736 samples divided into 199 batches\n",
      "Validating on 20 samples\n",
      "Time for epoch 1 is 12.620837926864624 sec\n",
      "train mse = 24469.501953125     val mse = 25044.880859375\n",
      "Time for epoch 2 is 10.527913570404053 sec\n",
      "train mse = 25019.94921875     val mse = 25595.42578125\n",
      "Time for epoch 3 is 11.256608009338379 sec\n",
      "train mse = 25759.826171875     val mse = 26364.1015625\n",
      "Time for epoch 4 is 11.480194807052612 sec\n",
      "train mse = 26223.978515625     val mse = 26843.962890625\n",
      "Time for epoch 5 is 9.153471946716309 sec\n",
      "train mse = 26772.287109375     val mse = 27443.05078125\n",
      "Time for epoch 6 is 7.003467798233032 sec\n",
      "train mse = 26998.8125     val mse = 27696.908203125\n",
      "Time for epoch 7 is 6.75046443939209 sec\n",
      "train mse = 26494.01953125     val mse = 27161.0390625\n",
      "Time for epoch 8 is 6.613415956497192 sec\n",
      "train mse = 27004.7265625     val mse = 27665.740234375\n",
      "Time for epoch 9 is 10.578461408615112 sec\n",
      "train mse = 27655.583984375     val mse = 28303.021484375\n",
      "Time for epoch 10 is 13.443174123764038 sec\n",
      "train mse = 28130.466796875     val mse = 28845.130859375\n",
      "Time for epoch 11 is 10.525392532348633 sec\n",
      "train mse = 28308.21875     val mse = 29023.125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-81682f92d62a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerated_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_wp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Need to make sure batch is dividable by batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\airbnb_predictions\\lib\\models.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset, epochs, num_samples)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_proc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Time for epoch {} is {} sec'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\airbnb_predictions\\lib\\models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mgradients_of_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\airbnbEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\airbnbEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\airbnbEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\airbnbEnv\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_BiasAddGrad\u001b[1;34m(op, received_grad)\u001b[0m\n\u001b[0;32m    348\u001b[0m   return (received_grad,\n\u001b[0;32m    349\u001b[0m           gen_nn_ops.bias_add_grad(\n\u001b[1;32m--> 350\u001b[1;33m               out_backprop=received_grad, data_format=data_format))\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\airbnbEnv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add_grad\u001b[1;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[0;32m    744\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m    745\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BiasAddGrad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m         tld.op_callbacks, out_backprop, \"data_format\", data_format)\n\u001b[0m\u001b[0;32m    747\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generated_data = gan.train(X_wp[:50*256], 200, 20)\n",
    "# Need to make sure batch is dividable by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.825003  0.        0.        ... 0.        0.        0.       ]\n",
      " [4.6397886 0.        0.        ... 0.        0.        0.       ]\n",
      " [2.5917861 0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [2.7451532 0.        0.        ... 0.        0.        0.       ]\n",
      " [4.427025  0.        0.        ... 0.        0.        0.       ]\n",
      " [2.1830513 0.        0.        ... 0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 240)\n"
     ]
    }
   ],
   "source": [
    "print(generated_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30296.693\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(X_wp[60:80,:], generated_data)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble architecture will include all three regressor models (huber, rf, and ridge regressors) and a neural network; all trained on original processed data as well as new representation of the data retreived from the autoencoder. All 8 models (4 with and 4 without autoencoder) will be connected to a fusion layer which will be used as training data for the final neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 500\n",
    "# BATCH_SIZE = 128\n",
    "\n",
    "# # Models\n",
    "# sae = models.build_autoencoder(X_train, num_hidden_layers = 4, num_nodes = 32, act = 'relu')\n",
    "# rf = RandomForestRegressor(n_estimators=50)\n",
    "# ridge = Ridge(alpha=5)\n",
    "# huber = HuberRegressor(alpha=10, epsilon=3)\n",
    "# ann_inner = models.buildNN (data, num_hidden_layers = 3, hidden_nodes = 128, act = 'relu', do = 0, regularizer = True,\n",
    "#                 loss_function = 'mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "# earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                                       min_delta=0.0001, patience=10,\n",
    "#                                                       verbose=0, mode='auto')\n",
    "\n",
    "# # Get new representations\n",
    "# sae.fit(X_train, X_train, epochs = EPOCHS,  batch_size = BATCH_SIZE, validation_split = 0.2,\n",
    "#         callbacks = [earlystop_callback])\n",
    "# X_train_new = sae.predict(X_train)\n",
    "# X_test_new = sae.predict(X_test)\n",
    "\n",
    "# # Models on original representation\n",
    "# rf.fit(X_train, y_train)\n",
    "# ridge.fit(X_train, y_train)\n",
    "# huber.fit(X_train, y_train)\n",
    "# ann_inner.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "#             validation_split = 0.2)\n",
    "\n",
    "# # Get original model outputs\n",
    "# rf_out = rf.predict(X_train)\n",
    "# ridge_out = ridge.predict(X_train)\n",
    "# huber_out = huber.predict(X_train)\n",
    "# ann_inner_out = ann_inner.predict(X_train)\n",
    "\n",
    "# rf_out_test = rf.predict(X_test)\n",
    "# ridge_out_test = ridge.predict(X_test)\n",
    "# huber_out_test = huber.predict(X_test)\n",
    "# ann_inner_out_test = ann_inner.predict(X_test)\n",
    "\n",
    "# # Models on new representation\n",
    "# rf.fit(X_train_new, y_train)\n",
    "# ridge.fit(X_train_new, y_train)\n",
    "# huber.fit(X_train_new, y_train)\n",
    "# ann_inner.fit(X_train_new, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "#             validation_split = 0.2, callbacks = [earlystop_callback])\n",
    "\n",
    "# # Get new representation model outputs\n",
    "# rf_out2 = rf.predict(X_train_new)\n",
    "# ridge_out2 = ridge.predict(X_train_new)\n",
    "# huber_out2 = huber.predict(X_train_new)\n",
    "# ann_inner_out2 = ann_inner.predict(X_train_new)\n",
    "\n",
    "# rf_out_test2 = rf.predict(X_test_new)\n",
    "# ridge_out_test2 = ridge.predict(X_test_new)\n",
    "# huber_out_test2 = huber.predict(X_test_new)\n",
    "# ann_inner_out_test2 = ann_inner.predict(X_test_new)\n",
    "\n",
    "# # Reshape\n",
    "# rf_out = rf_out.reshape(X_train.shape[0], 1)\n",
    "# ridge_out = ridge_out.reshape(X_train.shape[0], 1)\n",
    "# huber_out = huber_out.reshape(X_train.shape[0], 1)\n",
    "# rf_out2 = rf_out2.reshape(X_train.shape[0], 1)\n",
    "# ridge_out2 = ridge_out2.reshape(X_train.shape[0], 1)\n",
    "# huber_out2 = huber_out2.reshape(X_train.shape[0], 1)\n",
    "\n",
    "# rf_out_test = rf_out_test.reshape(X_test.shape[0], 1)\n",
    "# ridge_out_test = ridge_out_test.reshape(X_test.shape[0], 1)\n",
    "# huber_out_test = huber_out_test.reshape(X_test.shape[0], 1)\n",
    "# rf_out_test2 = rf_out_test2.reshape(X_test.shape[0], 1)\n",
    "# ridge_out_test2 = ridge_out_test2.reshape(X_test.shape[0], 1)\n",
    "# huber_out_test2 = huber_out_test2.reshape(X_test.shape[0], 1)\n",
    "\n",
    "\n",
    "# # Creating fusion vectors\n",
    "# fused_train = (rf_out, ridge_out, huber_out, ann_inner_out, rf_out2, ridge_out2, huber_out2, ann_inner_out2)\n",
    "# fused_train = np.concatenate(fused_train, axis=1)\n",
    "# fused_test = (rf_out_test, ridge_out_test, huber_out_test, ann_inner_out_test,\n",
    "#               rf_out_test2, ridge_out_test2, huber_out_test2, ann_inner_out_test2)\n",
    "# fused_test = np.concatenate(fused_test, axis=1)\n",
    "\n",
    "# # Outer Neural Net\n",
    "# # ann_outer = buildNN (fused_train, num_hidden_layers = 3, hidden_nodes = 256, act = 'relu', do = 0, regularizer = True,\n",
    "# #                 loss_function = 'mean_absolute_error')\n",
    "\n",
    "# # ann_outer.fit(fused_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "# #             validation_split = 0.2, callbacks = [earlystop_callback])\n",
    "# model_outer = RandomForestRegressor(n_estimators=50)\n",
    "# model_outer.fit(fused_train, y_train)\n",
    "\n",
    "# print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_outer = RandomForestRegressor(n_estimators=50)\n",
    "# model_outer.fit(fused_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse, r2, mae = evaluateModel(model_outer, fused_test, y_test)\n",
    "# print('MSE = {}'.format(mse))\n",
    "# print('R2 = {}'.format(r2))\n",
    "# print(\"MAE = {}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = np.arange(10).reshape(10,1)\n",
    "# a2 = np.arange(10).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3 = np.concatenate((a1, a2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb_env",
   "language": "python",
   "name": "airbnb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
