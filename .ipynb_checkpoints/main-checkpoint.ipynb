{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import time\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from lib import data_generation as dg\n",
    "from lib import feature_processing as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "### 1.0 Loading Data\n",
    "Here we load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/AB_NYC_2019.csv')\n",
    "numerical_data = pd.read_csv('input/processed_data_nyc_numerical.csv')\n",
    "categorical_data = pd.read_csv('input/processed_data_nyc_categorical.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Processing Data\n",
    "The data is processed as explained in the data processing notebook of this project. The process function in feature_processing library is written based on that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "processed_data = fp.process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>all_year_avail</th>\n",
       "      <th>low_avail</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_Williamsburg</th>\n",
       "      <th>neighbourhood_Willowbrook</th>\n",
       "      <th>neighbourhood_Windsor Terrace</th>\n",
       "      <th>neighbourhood_Woodhaven</th>\n",
       "      <th>neighbourhood_Woodlawn</th>\n",
       "      <th>neighbourhood_Woodrow</th>\n",
       "      <th>neighbourhood_Woodside</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>3021</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude     price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237  5.010635               1                  9   \n",
       "1  40.75362  -73.98377  5.420535               1                 45   \n",
       "2  40.80902  -73.94190  5.017280               3                  0   \n",
       "3  40.68514  -73.95976  4.499810               1                270   \n",
       "4  40.79851  -73.94399  4.394449              10                  9   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0         2762               0.21                               6   \n",
       "1         2976               0.38                               2   \n",
       "2            0               0.00                               1   \n",
       "3         3021               4.64                               1   \n",
       "4         2793               0.10                               1   \n",
       "\n",
       "   all_year_avail  low_avail  ...  neighbourhood_Williamsburg  \\\n",
       "0            True      False  ...                           0   \n",
       "1            True      False  ...                           0   \n",
       "2            True      False  ...                           0   \n",
       "3           False      False  ...                           0   \n",
       "4           False       True  ...                           0   \n",
       "\n",
       "   neighbourhood_Willowbrook  neighbourhood_Windsor Terrace  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   neighbourhood_Woodhaven  neighbourhood_Woodlawn  neighbourhood_Woodrow  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "\n",
       "   neighbourhood_Woodside  room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                       0                          0                       1   \n",
       "1                       0                          1                       0   \n",
       "2                       0                          0                       1   \n",
       "3                       0                          1                       0   \n",
       "4                       0                          1                       0   \n",
       "\n",
       "   room_type_Shared room  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48768, 240)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48768, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split Data\n",
    "We split the data 80-20 into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: (39014, 239)\n",
      "Testing Dataset: (9754, 239)\n"
     ]
    }
   ],
   "source": [
    "y = processed_data.price\n",
    "processed_data = processed_data.drop(['price'], axis=1)\n",
    "\n",
    "X = np.asarray(processed_data)\n",
    "y = np.asarray(y).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "print(\"Testing Dataset: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to split the categorical and numerical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data =  numerical_data.drop(['price'], axis=1)\n",
    "\n",
    "X_num = np.asarray(numerical_data)\n",
    "X_cat = np.asarray(categorical_data)\n",
    "\n",
    "X_num_train, X_num_test, y_num_train, y_num_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
    "X_cat_train, X_cat_test, y_cat_train, y_cat_test = train_test_split(X_cat, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39014, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39014, 228)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,11:1000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Scaling Data\n",
    "The final step in data processing is using the robust scaler to scale all data! But we will apply the scaler after new data is generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML Models\n",
    "In this project we tested multiple regressors at varying parameters. We concluded that the ideal model parameters were as follows for the top 3 regressors:\n",
    "\n",
    "1) Random Forest: Number of estimators = 50  \n",
    "2) Ridge Regression: Alpha = 5  \n",
    "3) Huber Regression: Alpha = 10, Epsilon = 3  \n",
    "\n",
    "As such, we will define our final models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_final = RandomForestRegressor(n_estimators=50)\n",
    "ridge_final = Ridge(alpha=5)\n",
    "huber_final = HuberRegressor(alpha=10, epsilon=3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Unit Testing\n",
    "We perform unit testing to check which samples perform the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitTest(model, sampleX, sampleY):\n",
    "    y_pred = model.predict(sampleX)\n",
    "    return abs(sampleY - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinority(model, X, y, numFolds = 5, percent = 0.1):\n",
    "    # Split training data into chunks\n",
    "    cv = KFold(numFolds, True, 1)\n",
    "\n",
    "    round = 1\n",
    "    \n",
    "    numSamples = int( (percent * X.shape[0]) / numFolds)\n",
    "    \n",
    "    \n",
    "    # We test the model on each chunk after training on the other chunks\n",
    "    for train, test in cv.split(X):\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "        # Scale data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        diff_list = []\n",
    "        for i in range(X_test_scaled.shape[0]):\n",
    "            sampleX = X_test_scaled[i]\n",
    "            sampleY = y_test[i]\n",
    "            \n",
    "            temp = unitTest(model, sampleX.reshape(1,-1), sampleY.reshape(-1))\n",
    "            diff_list.append(temp)\n",
    "            \n",
    "        # Get poorest performance test values (highest mse)\n",
    "        highest_diff = sorted(range(len(diff_list)), key=lambda i: diff_list[i])[-numSamples:]\n",
    "        \n",
    "        \n",
    "        # We want to add unscaled data to minority so it returns unscaled\n",
    "        if (round==1):\n",
    "            X_minority = X_test[highest_diff]\n",
    "            y_minority = y_test[highest_diff]\n",
    "        else:\n",
    "            X_minority = np.concatenate( (X_minority, X_test[highest_diff]), axis = 0)\n",
    "            y_minority = np.concatenate( (y_minority, y_test[highest_diff]), axis = 0)\n",
    "            \n",
    "        round = round + 1\n",
    " \n",
    "    \n",
    "    return X_minority, y_minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_m, y_m = getMinority(randomForest_final, X_train, y_train, percent=0.01)\n",
    "# print(\"Minority data acquired! X-shape = {}  ,  y-shape = {} \".format(X_m.shape, y_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Additional Data\n",
    "We use the Synthetic Minority Oversampling Technique (SMOTE) to generate additional data from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minority_data = np.concatenate( (X_m, y_m.reshape(-1,1)), axis = 1)\n",
    "# print(\"Minority Data Shape: {}\".format(minority_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(minority_data, N, k=2):\n",
    "#     numerical_minority = minority_data[:,0:11]\n",
    "    newData = dg.SMOTE(minority_data, 100, 2)\n",
    "#     newCatData = minority_data[:,11:240]\n",
    "    \n",
    "#     newData = np.concatenate((newData, newCatData), axis = 1)\n",
    "\n",
    "#     print(\"Round 1/{}\".format(N))\n",
    "#     print(\"New data generated with MSE = {} , R2 = {} , MAE = {}\".format(mse,r2,mae))\n",
    "#     print(\"Size of training data = {}\".format(minority_data.shape))\n",
    "#     print(\"Size of new data = {}\".format(newData.shape))\n",
    "\n",
    "    for n in range(N-1):\n",
    "        temp = dg.SMOTE(minority_data, 100, k)\n",
    "#         temp = np.concatenate((temp, newCatData), axis = 1)\n",
    "\n",
    "        newData = np.concatenate((newData, temp), axis = 0)\n",
    "\n",
    "#         print(\"Round {}/{}\".format(n+2,N))\n",
    "#         print(\"New data generated with MSE = {} , R2 = {} , MAE = {}\".format(mse,r2,mae))\n",
    "#         print(\"Size of training data = {}\".format(minority_data.shape))\n",
    "#         print(\"Size of new data = {}\".format(newData.shape))\n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newData = genData(minority_data, 20, k= 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, we created a new dataset that is similar to the minority set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData(X_train, y_train, newData):\n",
    "#     print(\"Train data before new data: \")\n",
    "#     print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "#     print(\"Training Labels: {}\".format(y_train.shape))\n",
    "\n",
    "    y_m = newData[:,-1]\n",
    "    X_m = np.delete(newData, np.s_[-1:], axis=1)\n",
    "#     print(\"X_m shape = {}\".format(X_m.shape))\n",
    "#     print(\"y_m shape = {}\".format(y_m.shape))\n",
    "\n",
    "    combined_X_train = np.concatenate((X_train, X_m), axis = 0)\n",
    "    combined_y_train = np.concatenate((y_train, y_m), axis = 0)\n",
    "\n",
    "#     print(\"Train data after new data is added: \")\n",
    "#     print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "#     print(\"Training Labels: {}\".format(y_train.shape))\n",
    "    \n",
    "    return combined_X_train, combined_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = combineData(X_train, y_train, newData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function to combine numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineNumCat(X_cat, X_num):\n",
    "    print(\"numbered data : {}\".format(X_num.shape))\n",
    "    print(\"categorical data: {}\".format(X_cat.shape))\n",
    "    \n",
    "#     for i in range(X_num.shape[0] - X_cat.shape[0]):\n",
    "#         currentRow = i + X_cat.shape[0] - 1\n",
    "#         X_cat[currentRow] = \n",
    "    combined_X = np.concatenate((X_num, X_cat), axis = 1)\n",
    "    return combined_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ML Models With New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creating Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel( model, X_train, y_train, X_test, y_test):\n",
    "    # Scale data first\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "    model.fit(X_train_scaled,y_train)\n",
    "    out_y = model.predict(X_test_scaled)\n",
    "    \n",
    "    result = mean_squared_error(y_test, out_y)\n",
    "    print(\"Result: {}\".format(result))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = testModel( nn_model , X_train_new, y_train_new, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are better with more minority data in the training set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Testing data generation with different parameters\n",
    "Previously, we generated 3 similar sets to the 10% minority (10% of the worst performance samples in the training set). Now we are going to test the same thing but with different percet minority and different number of similar sets (as opposed to 10% and 3 respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "# N_values = [1,2,3,5]\n",
    "# K_values = [2,4,8,16]\n",
    "# model = randomForest_final\n",
    "\n",
    "# mse_final = []\n",
    "# p_final = []\n",
    "# n_final = []\n",
    "# k_final = []\n",
    "\n",
    "# for p in percentages:\n",
    "#     for n in N_values:\n",
    "#         for k in K_values:\n",
    "#             print(\"P = {} , N = {} , K = {}\".format(p,n,k))\n",
    "#             X_m, y_m = getMinority(model, X_train, y_train, percent = p)\n",
    "#             minority_data = np.concatenate( (X_m, y_m.reshape(-1,1)), axis = 1)\n",
    "#             newData = genData(minority_data, n, k=k)\n",
    "#             X_train_new, y_train_new = combineData(X_train, y_train, newData)\n",
    "\n",
    "\n",
    "#             rf_result = testModel( randomForest_final , X_train_new, y_train_new, X_test, y_test)\n",
    "#             p_final.append(p)\n",
    "#             n_final.append(n)\n",
    "#             k_final.append(k)\n",
    "#             mse_final.append(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalResult_df = pd.DataFrame({\n",
    "#     'Percentage': p_final,\n",
    "#     'Num of extra sets': n_final,\n",
    "#     'Neighbors': k_final,\n",
    "#     'MSE': mse_final,\n",
    "# })\n",
    "\n",
    "# finalResult_df.to_csv('output/results_dataGen_pnk_nn.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalResult_df = finalResult_df.sort_values('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalResult_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Cross validating with new data\n",
    "Here we will cross validate our ML mode, a Random Forest Regressor, with varying number of estimators (the main parameter of this model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_VALUES = [0.00001, 0.00005 ,0.0001, 0.0005, 0.001, 0.01]\n",
    "# # NUM_ESTIMATORS = [10, 50, 100, 200]\n",
    "# N_VALUES = [1,2,3]\n",
    "\n",
    "# n_final = []\n",
    "# estimators_final = []\n",
    "# mse_final = []\n",
    "# p_final = []\n",
    "\n",
    "# for p in P_VALUES:\n",
    "#     for n in N_VALUES:\n",
    "#         model = RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "#         X_m, y_m = getMinority(model, X_train, y_train, percent = p)\n",
    "#         minority_data = np.concatenate( (X_m, y_m.reshape(-1,1)), axis = 1)\n",
    "#         newData = genData(minority_data, n)\n",
    "#         X_train_new, y_train_new = combineData(X_train, y_train, newData)\n",
    "\n",
    "#         X_train_scaled = scaler.fit_transform(X_train_new)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#         model.fit(X_train_scaled,y_train_new)\n",
    "#         out_y1 = model.predict(X_test_scaled)\n",
    "#         mse = mean_squared_error(y_test, out_y1)\n",
    "#         print(\"N = {} , MSE = {}\".format(n, mse))\n",
    "\n",
    "#         mse_final.append(mse)\n",
    "#         n_final.append(n)\n",
    "#         p_final.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'Estimators': n_final,\n",
    "#     'Percent': p_final,\n",
    "#     'MSE': mse_final,\n",
    "# })\n",
    "\n",
    "# df.to_csv('output/results_rf_cv_SMOTE.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Model\n",
    "\n",
    "Here we will assemble everything to make our final model. We will generate data, train our model, test it, and show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 MSE = 0.19536508856535942\n",
      "model 2 MSE = 0.17456405378854703\n",
      "Final MSE = 0.17256143676962113\n"
     ]
    }
   ],
   "source": [
    "model1 = huber_final\n",
    "model2 = randomForest_final\n",
    "\n",
    "# p = 0.005\n",
    "# n = 2\n",
    "\n",
    "# X_m, y_m = getMinority(model, X_train, y_train, percent = p)\n",
    "# minority_data = np.concatenate( (X_m, y_m.reshape(-1,1)), axis = 1)\n",
    "# newData = genData(minority_data, n)\n",
    "# X_train_new, y_train_new = combineData(X_train, y_train, newData)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "# X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "\n",
    "model1.fit(X_train_scaled,y_train)\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "\n",
    "out_y1 = model1.predict(X_test_scaled)\n",
    "mse1 = mean_squared_error(y_test, out_y1)\n",
    "print(\"model 1 MSE = {}\".format(mse1))\n",
    "\n",
    "out_y2 = model2.predict(X_test_scaled)\n",
    "mse2 = mean_squared_error(y_test, out_y2)\n",
    "print(\"model 2 MSE = {}\".format(mse2))\n",
    "\n",
    "out_y = (out_y1 + out_y2)/2\n",
    "mse = mean_squared_error(y_test,out_y)\n",
    "print(\"Final MSE = {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the above results to the same model but without generating new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.17535730108666456\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "\n",
    "out_y1 = model2.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, out_y1)\n",
    "print(\"MSE = {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb_env",
   "language": "python",
   "name": "airbnb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
