{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Functions\n",
    "Here we define the functions used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function build the auto encoder model\n",
    "def build_autoencoder(data, num_hidden_layers = 2, base_nodes = 16, act = 'tanh'):\n",
    "\n",
    "    model=Sequential()\n",
    "    \n",
    "    input_layer= Input(shape=(data.shape[1],))\n",
    "    model.add(input_layer)\n",
    "    model.add(Dense(units = base_nodes, activation=act))\n",
    "    \n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(units = (i+2)*base_nodes, activation=act))\n",
    "    \n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(units = (num_hidden_layers - i+1)*base_nodes, activation=act))\n",
    "        \n",
    "    \n",
    "    model.add(Dense(units = base_nodes, activation=act))\n",
    "    \n",
    "    model.add(Dense(units=data.shape[1], activation=act))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss= 'mean_squared_error', metrics=['mse']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>all_year_avail</th>\n",
       "      <th>low_avail</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_Williamsburg</th>\n",
       "      <th>neighbourhood_Willowbrook</th>\n",
       "      <th>neighbourhood_Windsor Terrace</th>\n",
       "      <th>neighbourhood_Woodhaven</th>\n",
       "      <th>neighbourhood_Woodlawn</th>\n",
       "      <th>neighbourhood_Woodrow</th>\n",
       "      <th>neighbourhood_Woodside</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>3021</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude     price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237  5.010635               1                  9   \n",
       "1  40.75362  -73.98377  5.420535               1                 45   \n",
       "2  40.80902  -73.94190  5.017280               3                  0   \n",
       "3  40.68514  -73.95976  4.499810               1                270   \n",
       "4  40.79851  -73.94399  4.394449              10                  9   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0         2762               0.21                               6   \n",
       "1         2976               0.38                               2   \n",
       "2            0               0.00                               1   \n",
       "3         3021               4.64                               1   \n",
       "4         2793               0.10                               1   \n",
       "\n",
       "   all_year_avail  low_avail  ...  neighbourhood_Williamsburg  \\\n",
       "0            True      False  ...                           0   \n",
       "1            True      False  ...                           0   \n",
       "2            True      False  ...                           0   \n",
       "3           False      False  ...                           0   \n",
       "4           False       True  ...                           0   \n",
       "\n",
       "   neighbourhood_Willowbrook  neighbourhood_Windsor Terrace  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   neighbourhood_Woodhaven  neighbourhood_Woodlawn  neighbourhood_Woodrow  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "\n",
       "   neighbourhood_Woodside  room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                       0                          0                       1   \n",
       "1                       0                          1                       0   \n",
       "2                       0                          0                       1   \n",
       "3                       0                          1                       0   \n",
       "4                       0                          1                       0   \n",
       "\n",
       "   room_type_Shared room  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/processed_data_nyc.csv', index_col = 0)\n",
    "numerical_data = pd.read_csv('input/processed_data_nyc_numerical.csv',  index_col = 0)\n",
    "categorical_data = pd.read_csv('input/processed_data_nyc_categorical.csv',  index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>all_year_avail</th>\n",
       "      <th>low_avail</th>\n",
       "      <th>no_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>3021</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude     price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237  5.010635               1                  9   \n",
       "1  40.75362  -73.98377  5.420535               1                 45   \n",
       "2  40.80902  -73.94190  5.017280               3                  0   \n",
       "3  40.68514  -73.95976  4.499810               1                270   \n",
       "4  40.79851  -73.94399  4.394449              10                  9   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0         2762               0.21                               6   \n",
       "1         2976               0.38                               2   \n",
       "2            0               0.00                               1   \n",
       "3         3021               4.64                               1   \n",
       "4         2793               0.10                               1   \n",
       "\n",
       "   all_year_avail  low_avail  no_reviews  \n",
       "0            True      False       False  \n",
       "1            True      False       False  \n",
       "2            True      False        True  \n",
       "3           False      False       False  \n",
       "4           False       True       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group_Bronx</th>\n",
       "      <th>neighbourhood_group_Brooklyn</th>\n",
       "      <th>neighbourhood_group_Manhattan</th>\n",
       "      <th>neighbourhood_group_Queens</th>\n",
       "      <th>neighbourhood_group_Staten Island</th>\n",
       "      <th>neighbourhood_Allerton</th>\n",
       "      <th>neighbourhood_Arden Heights</th>\n",
       "      <th>neighbourhood_Arrochar</th>\n",
       "      <th>neighbourhood_Arverne</th>\n",
       "      <th>neighbourhood_Astoria</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_Williamsburg</th>\n",
       "      <th>neighbourhood_Willowbrook</th>\n",
       "      <th>neighbourhood_Windsor Terrace</th>\n",
       "      <th>neighbourhood_Woodhaven</th>\n",
       "      <th>neighbourhood_Woodlawn</th>\n",
       "      <th>neighbourhood_Woodrow</th>\n",
       "      <th>neighbourhood_Woodside</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbourhood_group_Bronx  neighbourhood_group_Brooklyn  \\\n",
       "0                          0                             1   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             1   \n",
       "4                          0                             0   \n",
       "\n",
       "   neighbourhood_group_Manhattan  neighbourhood_group_Queens  \\\n",
       "0                              0                           0   \n",
       "1                              1                           0   \n",
       "2                              1                           0   \n",
       "3                              0                           0   \n",
       "4                              1                           0   \n",
       "\n",
       "   neighbourhood_group_Staten Island  neighbourhood_Allerton  \\\n",
       "0                                  0                       0   \n",
       "1                                  0                       0   \n",
       "2                                  0                       0   \n",
       "3                                  0                       0   \n",
       "4                                  0                       0   \n",
       "\n",
       "   neighbourhood_Arden Heights  neighbourhood_Arrochar  neighbourhood_Arverne  \\\n",
       "0                            0                       0                      0   \n",
       "1                            0                       0                      0   \n",
       "2                            0                       0                      0   \n",
       "3                            0                       0                      0   \n",
       "4                            0                       0                      0   \n",
       "\n",
       "   neighbourhood_Astoria  ...  neighbourhood_Williamsburg  \\\n",
       "0                      0  ...                           0   \n",
       "1                      0  ...                           0   \n",
       "2                      0  ...                           0   \n",
       "3                      0  ...                           0   \n",
       "4                      0  ...                           0   \n",
       "\n",
       "   neighbourhood_Willowbrook  neighbourhood_Windsor Terrace  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   neighbourhood_Woodhaven  neighbourhood_Woodlawn  neighbourhood_Woodrow  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "\n",
       "   neighbourhood_Woodside  room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                       0                          0                       1   \n",
       "1                       0                          1                       0   \n",
       "2                       0                          0                       1   \n",
       "3                       0                          1                       0   \n",
       "4                       0                          1                       0   \n",
       "\n",
       "   room_type_Shared room  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to divide the data into categorical and numerical. We will attempt to get a new representation of the numerical data using the autoencoder. We will compare the new representation to the old one to see which one produces better performance using the same classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numerical_data.price\n",
    "numerical_data = numerical_data.drop(['price'], axis=1)\n",
    "data = data.drop(['price'], axis=1)\n",
    "\n",
    "# Converting to numpy arrays\n",
    "X_num = np.asarray(numerical_data).astype(np.float32)\n",
    "X_cat = np.asarray(categorical_data)\n",
    "X = np.asarray(data).astype(np.float32)\n",
    "y = np.asarray(y).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting to train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: (39014, 239)\n",
      "Testing Dataset: (9754, 239)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "print(\"Testing Dataset: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Testing Autoencoders\n",
    "In this section, I will test various architectures for autoencoders and judge based on Mean-Squared Error (MSE) as well as the performance of the three classifiers with and without autoencoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareClasifiers (ae_model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #Classifiers\n",
    "    randomForest_final = RandomForestRegressor(n_estimators=50)\n",
    "    ridge_final = Ridge(alpha=5)\n",
    "    huber_final = HuberRegressor(alpha=10, epsilon=3)\n",
    "    \n",
    "    #New representations:\n",
    "    X_train2 = ae_model.predict(X_train)\n",
    "    X_test2 = ae_model.predict(X_test)\n",
    "        \n",
    "    rf_result_final = []\n",
    "    ridge_result_final = []\n",
    "    huber_result_final = []\n",
    "    \n",
    "    # Random Forest\n",
    "    randomForest_final.fit(X_train,y_train)\n",
    "    rf_y = randomForest_final.predict(X_test)\n",
    "    rf_result = mean_squared_error(y_test, rf_y)\n",
    "\n",
    "    randomForest_final.fit(X_train2,y_train)\n",
    "    rf_y2 = randomForest_final.predict(X_test2)\n",
    "    rf_result2 = mean_squared_error(y_test, rf_y2)\n",
    "\n",
    "    print(\"Random Forest: {}\".format(rf_result))\n",
    "    print(\"Random Forest with Autoencoder: {}\".format(rf_result2))\n",
    "    rf_result_final.append(rf_result)\n",
    "    rf_result_final.append(rf_result2)\n",
    "    rf_result_final.append(rf_result-rf_result2)\n",
    "    \n",
    "    # Ridge\n",
    "    ridge_final.fit(X_train,y_train)\n",
    "    ridge_y = ridge_final.predict(X_test)\n",
    "    ridge_result = mean_squared_error(y_test, ridge_y)\n",
    "\n",
    "    ridge_final.fit(X_train2,y_train)\n",
    "    ridge_y2 = ridge_final.predict(X_test2)\n",
    "    ridge_result2 = mean_squared_error(y_test, ridge_y2)\n",
    "\n",
    "    print(\"Ridge : {}\".format(ridge_result))\n",
    "    print(\"Ridge with Autoencoder: {}\".format(ridge_result2))\n",
    "    ridge_result_final.append(ridge_result)\n",
    "    ridge_result_final.append(ridge_result2)\n",
    "    ridge_result_final.append(ridge_result-ridge_result2)\n",
    "\n",
    "    # Huber\n",
    "    huber_final.fit(X_train,y_train)\n",
    "    huber_y = huber_final.predict(X_test)\n",
    "    huber_result = mean_squared_error(y_test,huber_y)\n",
    "\n",
    "    huber_final.fit(X_train2,y_train)\n",
    "    huber_y2 = huber_final.predict(X_test2)\n",
    "    huber_result2 = mean_squared_error(y_test,huber_y2)\n",
    "\n",
    "    print(\"Huber: {}\".format(huber_result))\n",
    "    print(\"Huber with Autoencoder: {}\".format(huber_result2))\n",
    "    huber_result_final.append(huber_result)\n",
    "    huber_result_final.append(huber_result2)\n",
    "    huber_result_final.append(huber_result-ridge_result2)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'RF': rf_result_final,\n",
    "        'Ridge': ridge_result_final,\n",
    "        'Huber': huber_result_final,\n",
    "\n",
    "        \n",
    "    },\n",
    "    index = ['Before','After','Difference']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Test 1: Layers and Nodes\n",
    "In the first test, I will cross-validate for different numbers of layers and nodes. I will use 100 epochs with 512 for batch size. Once an ideal architecture is chosen, I will test the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-16-Epochs=50-TIME=1586470509\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 10171.1455 - mse: 10197.7354\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 38.3464 - mse: 38.3645\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 35.2844 - mse: 35.3052\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 34.0778 - mse: 34.0637\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.6427 - mse: 33.6300\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5449 - mse: 33.5560\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 33.5381 - mse: 33.5381\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 33.5493 - mse: 33.5379\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 33.5200 - mse: 33.5252\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5607 - mse: 33.5618\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5210 - mse: 33.5234\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5655 - mse: 33.5759\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5411 - mse: 33.5463\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5603 - mse: 33.5635\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.6029 - mse: 33.6155\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5821 - mse: 33.5912\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5346 - mse: 33.5382\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5729 - mse: 33.5810\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5496 - mse: 33.5561\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5425 - mse: 33.5414\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5675 - mse: 33.5783\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5459 - mse: 33.5490\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5385 - mse: 33.5376\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5794 - mse: 33.5764\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.6200 - mse: 33.6230\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5745 - mse: 33.5481\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5831 - mse: 33.5605\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5787 - mse: 33.5564\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5654 - mse: 33.5572\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5975 - mse: 33.5802\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5760 - mse: 33.5835\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 33.5451 - mse: 33.5571\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5446 - mse: 33.5477\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5792 - mse: 33.5772\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5615 - mse: 33.5700\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5791 - mse: 33.5798\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5529 - mse: 33.5468\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.5707 - mse: 33.5529\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 33.5840 - mse: 33.5870\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 33.5532 - mse: 33.5582\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5545 - mse: 33.5488\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5680 - mse: 33.5706\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5662 - mse: 33.5642\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5838 - mse: 33.5845\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5673 - mse: 33.5631\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5423 - mse: 33.5499\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 33.5656 - mse: 33.5556\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5608 - mse: 33.5604\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5926 - mse: 33.5970\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 33.5522 - mse: 33.5636\n",
      "1-16-Epochs=50-TIME=1586470551\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 4619.4351 - mse: 4631.5044\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23.2115 - mse: 23.1883\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 21.2312 - mse: 21.2214\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 20.2878 - mse: 20.2822\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 19.7704 - mse: 19.7839\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 19.5853 - mse: 19.5956\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 19.2590 - mse: 19.2618\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 19.0151 - mse: 19.0193\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 18.7345 - mse: 18.7232\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 18.3934 - mse: 18.4029\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 17.9633 - mse: 17.9665\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 17.2920 - mse: 17.2737\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 16.3429 - mse: 16.3448\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 14.6596 - mse: 14.6775\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 12.2219 - mse: 12.2305\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 9.1002 - mse: 9.1030\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 6.4658 - mse: 6.4756\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 5.9710 - mse: 5.9810\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 5.4346 - mse: 5.4339\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 4.9898 - mse: 4.9827\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 5.1587 - mse: 5.1557\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 4.6095 - mse: 4.6086\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 4.4173 - mse: 4.4122\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 4.2520 - mse: 4.2580\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 3.5095 - mse: 3.5124\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 3.0907 - mse: 3.0926\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 2.8271 - mse: 2.8313\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.5777 - mse: 2.5806\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.0469 - mse: 2.0468\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.2727 - mse: 2.2769\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.7329 - mse: 1.7354\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.7855 - mse: 1.7886\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.6558 - mse: 1.6508\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.6625 - mse: 1.6479\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.6175 - mse: 1.6065\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.5290 - mse: 1.5247\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.4942 - mse: 1.4917\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.2581 - mse: 1.2511\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.2750 - mse: 1.2765\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.0884 - mse: 1.0878\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.9601 - mse: 0.9622\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.3661 - mse: 0.3668\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.5215 - mse: 0.5226\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.4858 - mse: 0.4870\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.2388 - mse: 0.2388\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.5906 - mse: 0.5921\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.4088 - mse: 0.4097\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.2227 - mse: 0.2231\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.2596 - mse: 0.2597\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1465 - mse: 0.1468\n",
      "1-32-Epochs=50-TIME=1586470587\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25719.1562 - mse: 25716.6543\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 4569.2642 - mse: 4581.1216\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.9679 - mse: 45.9736\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 45.6793 - mse: 45.6912\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 45.6491 - mse: 45.6733\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6543 - mse: 45.6678\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6926 - mse: 45.6664\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6547 - mse: 45.6657\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6697 - mse: 45.6651\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6549 - mse: 45.6648\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6656 - mse: 45.6650\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6832 - mse: 45.6648\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6599 - mse: 45.6656\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6612 - mse: 45.6648\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6559 - mse: 45.6662\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6903 - mse: 45.6654\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6704 - mse: 45.6664\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6524 - mse: 45.6653\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6600 - mse: 45.6660\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6515 - mse: 45.6672\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6896 - mse: 45.6669\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6964 - mse: 45.6655\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6516 - mse: 45.6682\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6672 - mse: 45.6689\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6579 - mse: 45.6694\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6616 - mse: 45.6767\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6660 - mse: 45.6700\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 45.6824 - mse: 45.6758\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.6889 - mse: 45.6995\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.7285 - mse: 45.7203\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.6764 - mse: 45.6729\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 45.6666 - mse: 45.6853\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 45.7489 - mse: 45.7370\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7072 - mse: 45.7125\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7536 - mse: 45.7213\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7374 - mse: 45.7242\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7541 - mse: 45.7494\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7440 - mse: 45.7397\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7298 - mse: 45.7558\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7326 - mse: 45.7199\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6924 - mse: 45.6998\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.7826 - mse: 45.7989\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 45.6683 - mse: 45.6760\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.8060 - mse: 45.8249\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6589 - mse: 45.6684\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.7246 - mse: 45.7265\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.8387 - mse: 45.8282\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6862 - mse: 45.6936\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.6766 - mse: 45.6824\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 45.7493 - mse: 45.7499\n",
      "1-32-Epochs=50-TIME=1586470633\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 3224.5134 - mse: 3232.9380\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 20.1616 - mse: 20.1766\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 18.1903 - mse: 18.2033\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 16.7783 - mse: 16.7597\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 15.0204 - mse: 15.0405\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 13.1765 - mse: 13.1921\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 11.3520 - mse: 11.3483\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 9.7821 - mse: 9.7817\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 8.1782 - mse: 8.1870\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 6.9172 - mse: 6.9260\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 5.9927 - mse: 5.9832\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 4.4886 - mse: 4.4965\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 3.6945 - mse: 3.7020\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 3.3628 - mse: 3.3668\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.6588 - mse: 2.6567\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.0912 - mse: 2.0854\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 4ms/step - loss: 2.2819 - mse: 2.2866\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.5403 - mse: 2.5326\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.7187 - mse: 2.7233\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.3536 - mse: 2.3571\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.8804 - mse: 2.8853\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.8403 - mse: 1.8246\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.3463 - mse: 2.3515\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.3739 - mse: 1.3767\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.0584 - mse: 2.0556\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.5295 - mse: 1.5323\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.9266 - mse: 0.9272\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.9289 - mse: 0.9312\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.3039 - mse: 1.3058\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.0400 - mse: 1.0424\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.4481 - mse: 0.4434\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.7090 - mse: 0.7107\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.2164 - mse: 1.2196\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.7462 - mse: 0.7481\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.7295 - mse: 0.7314\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.6106 - mse: 0.6066\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.9079 - mse: 0.9102\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.6305 - mse: 0.6316\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.4679 - mse: 0.4690\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.4006 - mse: 0.4005\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6720 - mse: 0.6727\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 0.4395 - mse: 0.4324\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 0.6944 - mse: 0.6947\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.5987 - mse: 0.6002\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.3715 - mse: 0.3724\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.9148 - mse: 0.9171\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.2920 - mse: 0.2927\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.4120 - mse: 0.4079\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.5788 - mse: 0.5803\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.6846 - mse: 0.6864\n",
      "1-64-Epochs=50-TIME=1586470674\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 2331.4094 - mse: 2337.4421\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.5809 - mse: 36.5661\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4821 - mse: 36.4652\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.6035 - mse: 36.6008\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.2166 - mse: 36.1843\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.3087 - mse: 36.3064\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.3616 - mse: 36.3685\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.3382 - mse: 36.3166\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.2903 - mse: 36.3100\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.2976 - mse: 36.2962\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 36.3982 - mse: 36.4005\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 36.2800 - mse: 36.2862\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 36.5328 - mse: 36.5344\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.1218 - mse: 36.1383\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.1675 - mse: 36.1759\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.2636 - mse: 36.2501\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.3513 - mse: 36.3540\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 36.0090 - mse: 36.0326\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 36.8123 - mse: 36.8136\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 36.3902 - mse: 36.3609\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 36.1918 - mse: 36.1929\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 36.3819 - mse: 36.3618\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.1938 - mse: 36.1787\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.1388 - mse: 36.1289\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4045 - mse: 36.3746\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4049 - mse: 36.3992\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.2695 - mse: 36.2609\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.3756 - mse: 36.3694\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.5231 - mse: 36.5142\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.2041 - mse: 36.2178\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4220 - mse: 36.4124\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.0982 - mse: 36.1021\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 36.2281 - mse: 36.2255\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 36.4957 - mse: 36.4663\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.3571 - mse: 36.3400\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 36.4047 - mse: 36.4015\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 0s 3ms/step - loss: 36.2970 - mse: 36.2940\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 36.2148 - mse: 36.2239\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 36.2290 - mse: 36.2193\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4468 - mse: 36.4305\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.0772 - mse: 36.0666\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.7693 - mse: 36.7678\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.1232 - mse: 36.1324\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.1604 - mse: 36.1566\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.4250 - mse: 36.4254\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.3229 - mse: 36.3329\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.0970 - mse: 36.1035\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.1827 - mse: 36.1653\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.8067 - mse: 36.7853\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 36.0661 - mse: 36.0748\n",
      "1-64-Epochs=50-TIME=1586470736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 1809.5995 - mse: 1814.3052\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 18.2699 - mse: 18.2702\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 16.0405 - mse: 16.0626\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 14.4403 - mse: 14.4518\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 12.7539 - mse: 12.7636\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 11.6438 - mse: 11.6506\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 9.9023 - mse: 9.9060\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 7.3056 - mse: 7.3098\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 5.6962 - mse: 5.6925\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 4.8041 - mse: 4.8074\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.9086 - mse: 2.9120\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 5.3585 - mse: 5.3720\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.1685 - mse: 1.1433\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.7153 - mse: 2.7215\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.4145 - mse: 2.4205\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.9861 - mse: 1.9905\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.6850 - mse: 2.6918\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.8462 - mse: 1.8509\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.8904 - mse: 0.8898\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.9965 - mse: 2.0011\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.6194 - mse: 1.6212\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.7437 - mse: 1.7409\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.2903 - mse: 1.2936\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.9440 - mse: 1.9481\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.8807 - mse: 1.8851\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.9522 - mse: 1.9571\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.0502 - mse: 1.0526\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.2410 - mse: 1.2433\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.8012 - mse: 0.7980\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.8705 - mse: 0.8605\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.6696 - mse: 1.6702\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 1.3106 - mse: 1.3140\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 0.8275 - mse: 0.8275\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.5698 - mse: 1.5739\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 1.1951 - mse: 1.1970\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 1.0880 - mse: 1.0908\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.9459 - mse: 0.9483\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 1.5798 - mse: 1.5767\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.1255 - mse: 1.1283\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.8493 - mse: 0.8494\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 1.2234 - mse: 1.2251\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 0.9705 - mse: 0.9614\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 0.8978 - mse: 0.8926\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 1.1928 - mse: 1.1956\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 2.6813 - mse: 2.6882\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.7333 - mse: 0.7352\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.8402 - mse: 0.8376\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 1.0465 - mse: 1.0492\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.5213 - mse: 0.5209\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 1.1807 - mse: 1.1814\n",
      "1-128-Epochs=50-TIME=1586470783\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 2758.0874 - mse: 2765.2078\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.4284 - mse: 42.4073\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 42.4308 - mse: 42.4218\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 42.4521 - mse: 42.4597\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 42.3995 - mse: 42.3883\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 4s 22ms/step - loss: 43.0504 - mse: 43.0545\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 42.7522 - mse: 42.7616\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 42.2616 - mse: 42.2735\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 42.1219 - mse: 42.1209\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 42.1097 - mse: 42.1087\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.1992 - mse: 42.1879\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.0394 - mse: 42.0317\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 41.8871 - mse: 41.8739\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.2051 - mse: 42.1786\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.0913 - mse: 42.0956\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 41.8670 - mse: 41.8644\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 41.9160 - mse: 41.8937\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 41.7926 - mse: 41.7936\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.0477 - mse: 42.0462\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.4117 - mse: 42.3945\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 42.7580 - mse: 42.7605\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 42.1054 - mse: 42.1169\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.8366 - mse: 41.8246\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.2032 - mse: 42.1993\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.9645 - mse: 42.9400\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.9120 - mse: 41.9312\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.8244 - mse: 41.8210\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.3597 - mse: 42.3559\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.1531 - mse: 42.1379\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.6488 - mse: 41.6655\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.9618 - mse: 41.9692\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.4903 - mse: 42.5001\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.0844 - mse: 42.0924\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.0814 - mse: 42.0739\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.9230 - mse: 41.9154\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.7528 - mse: 41.7577\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.3167 - mse: 42.3187\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.6297 - mse: 41.6347\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.7831 - mse: 41.7991\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.2745 - mse: 42.2806\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.5829 - mse: 41.5782\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.9494 - mse: 41.9657\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.0030 - mse: 41.9822\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.7598 - mse: 42.7583\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.7740 - mse: 41.7844\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.6261 - mse: 41.6165\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 42.8312 - mse: 42.8499\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.5689 - mse: 41.5628\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 41.6190 - mse: 41.6182\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 41.6382 - mse: 41.6274\n",
      "1-128-Epochs=50-TIME=1586470845\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 1091.3356 - mse: 1094.1615\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 12.6772 - mse: 12.6869\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 9.9957 - mse: 10.0020\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 9.9257 - mse: 9.9324\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 7.7772 - mse: 7.6935\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 5.6746 - mse: 5.6872\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 3.5747 - mse: 3.5827\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 5.4654 - mse: 5.4668\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 2.8783 - mse: 2.8711\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 4.0392 - mse: 4.0260\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 5.1809 - mse: 5.1386\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 3.0311 - mse: 3.0374\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 2.4188 - mse: 2.4249\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 4.1081 - mse: 4.1187\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 3.5123 - mse: 3.5185\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 3.2603 - mse: 3.2677\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 3.9813 - mse: 3.9914\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 2.5082 - mse: 2.5139\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 2.5221 - mse: 2.5280\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 3.3952 - mse: 3.3540\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 2.6021 - mse: 2.5733\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 2.7135 - mse: 2.7200\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.9667 - mse: 1.9661\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 3.1692 - mse: 3.1754\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 4.1809 - mse: 4.1846\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.9716 - mse: 1.9753\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.4589 - mse: 1.4261\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 2.2290 - mse: 2.2348\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 3.5476 - mse: 3.5568\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 3.2538 - mse: 3.2604\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.1067 - mse: 1.1055\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.7970 - mse: 1.8013\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 4.2290 - mse: 4.2400\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 1.8729 - mse: 1.8728\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 0.4860 - mse: 0.4687\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 1.9623 - mse: 1.9397\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 4.6808 - mse: 4.6621\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 2.7637 - mse: 2.7709\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 0.2985 - mse: 0.2812\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 1.0780 - mse: 1.0791\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 1.4505 - mse: 1.4540\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 28.1137 - mse: 28.1206\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 1.4908 - mse: 1.4947\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.2396 - mse: 0.2402\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.3422 - mse: 0.3430\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.8582 - mse: 0.8604\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.8070 - mse: 0.8090\n",
      "1-256-Epochs=50-TIME=1586470911\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 816.8633 - mse: 818.9092\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2961 - mse: 43.2877\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2947 - mse: 43.2881\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2860 - mse: 43.2877\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2789 - mse: 43.2873\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.2890 - mse: 43.2873\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.2712 - mse: 43.2885\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 43.3061 - mse: 43.2922\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 43.3309 - mse: 43.3084\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2834 - mse: 43.2879\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2934 - mse: 43.2880\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.4283 - mse: 43.4205\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.5235 - mse: 43.5336\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 44.4856 - mse: 44.4881\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 46.9017 - mse: 46.9160\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 5s 25ms/step - loss: 43.2804 - mse: 43.2931\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2718 - mse: 43.2888\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 44.8432 - mse: 44.8367\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 43.4813 - mse: 43.4834\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 44.4435 - mse: 44.4599\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 44.4520 - mse: 44.4648\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 44.4899 - mse: 44.4893\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 46.2721 - mse: 46.2778\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 43.2751 - mse: 43.2924\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 45.1214 - mse: 45.1202\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 43.4099 - mse: 43.4233\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 44.2986 - mse: 44.3114\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 45.0605 - mse: 45.0649\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2911 - mse: 43.2886\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 45.3425 - mse: 45.2037\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 43.3975 - mse: 43.4019\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 43.9755 - mse: 43.9753\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 45.1918 - mse: 45.1810\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.3045 - mse: 43.2906\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 44.2789 - mse: 44.2683\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 44.6477 - mse: 44.6551\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 43.3670 - mse: 43.3559\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 47.2172 - mse: 47.2381\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.3162 - mse: 43.3286\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 43.2822 - mse: 43.2879\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 44.0127 - mse: 44.0256\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 44.7372 - mse: 44.7492\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.3059 - mse: 43.3184\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 43.9481 - mse: 43.9616\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 43.7876 - mse: 43.7909\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 44.3115 - mse: 44.3078\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.3449 - mse: 43.3337\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 44.0713 - mse: 44.0634\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 44.7129 - mse: 44.7284\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.4516 - mse: 43.4705\n",
      "1-256-Epochs=50-TIME=1586471078\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 867.6479 - mse: 869.9022\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 7.9547 - mse: 7.9553\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 10.0226 - mse: 10.0414\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 10.2208 - mse: 10.2378\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 6.7599 - mse: 6.7769\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 8.0209 - mse: 8.0411\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 8.1533 - mse: 8.1293\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 9.1729 - mse: 9.1949\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 5s 25ms/step - loss: 6.4031 - mse: 6.3948\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 8.8065 - mse: 8.8267\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 8.2852 - mse: 8.3041\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 4.8771 - mse: 4.8877\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 14.3055 - mse: 14.2308\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 3.7029 - mse: 3.6788\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 8.0267 - mse: 8.0382\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 8.8277 - mse: 8.8230\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 5.6038 - mse: 5.4636\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 6.8664 - mse: 6.8653\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 31.3702 - mse: 31.1112\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 32.6404 - mse: 32.7260\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.4518 - mse: 0.4432\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 1.3160 - mse: 1.3188\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.3140 - mse: 2.2955\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 5s 25ms/step - loss: 1.8668 - mse: 1.8706\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 1.8486 - mse: 1.8496\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 2.5889 - mse: 2.5952\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 2.7510 - mse: 2.7578\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 4.0213 - mse: 4.0286\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 16.5431 - mse: 16.5864\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.3191 - mse: 0.3197\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 3.7862 - mse: 3.7960\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 1250.1675 - mse: 1251.9172\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 24.8001 - mse: 24.8641\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.5352 - mse: 0.5341\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8611 - mse: 0.8631\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 1.3992 - mse: 1.4027\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 1.1451 - mse: 1.1480\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.4432 - mse: 2.4493\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.1997 - mse: 0.1986\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.6413 - mse: 0.6429\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 4.6942 - mse: 4.7064\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.9865 - mse: 0.9890\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 1.8225 - mse: 1.8259\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.1333 - mse: 0.1337\n",
      "1-512-Epochs=50-TIME=1586471230\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 8s 41ms/step - loss: 25728.2461 - mse: 25721.7871\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 7s 37ms/step - loss: 25724.4922 - mse: 25722.9102\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 10s 55ms/step - loss: 25714.7363 - mse: 25723.0605\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25720.1680 - mse: 25723.0703\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 25736.6016 - mse: 25733.6211\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 25720.7871 - mse: 25724.4785\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25716.1074 - mse: 25724.4824\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 25725.8926 - mse: 25724.4785\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 25726.2871 - mse: 25724.4824\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 25722.9766 - mse: 25724.4746\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 10s 54ms/step - loss: 25726.1230 - mse: 25724.4863\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25725.7363 - mse: 25724.4727\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 7s 37ms/step - loss: 25722.7090 - mse: 25724.4863\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 10s 55ms/step - loss: 25718.7930 - mse: 25724.4863\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 25720.2773 - mse: 25724.4805\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 25730.4434 - mse: 25724.4883\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 25733.3066 - mse: 25724.4727\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 25726.9785 - mse: 25724.4961\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 25722.7637 - mse: 25724.5020\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 9s 47ms/step - loss: 25726.3281 - mse: 25724.4883\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 11s 55ms/step - loss: 25725.8594 - mse: 25724.4902\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 25725.3828 - mse: 25724.4785\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 25728.2129 - mse: 25724.4863\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 25724.7676 - mse: 25724.4746\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 25722.9785 - mse: 25724.4727\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25718.5332 - mse: 25724.4863\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 25726.8477 - mse: 25724.4668\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 25724.3926 - mse: 25724.4805\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 25732.3438 - mse: 25724.4902\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 25726.0762 - mse: 25724.4863\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 25727.6172 - mse: 25724.4863\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 11s 55ms/step - loss: 25729.4082 - mse: 25724.4883\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 9s 46ms/step - loss: 25725.7988 - mse: 25724.4805\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 25728.9062 - mse: 25724.4824\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 9s 46ms/step - loss: 25723.4629 - mse: 25724.4883\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25722.9512 - mse: 25724.4883\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 25723.6797 - mse: 25724.4883\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 25726.7480 - mse: 25724.4785\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 25723.0176 - mse: 25724.4863\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 25719.7129 - mse: 25724.4727\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 25728.4102 - mse: 25724.4824\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 7s 38ms/step - loss: 25722.8359 - mse: 25724.4863\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 11s 55ms/step - loss: 25775.6992 - mse: 25769.6348\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 25730.1484 - mse: 25724.6133\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 25725.0312 - mse: 25724.4805\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 25721.5137 - mse: 25724.4805\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 25726.6836 - mse: 25724.4805\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 10s 54ms/step - loss: 25728.8027 - mse: 25724.4863\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 25717.5176 - mse: 25724.4785\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 25728.1855 - mse: 25724.4863\n",
      "1-512-Epochs=50-TIME=1586471670\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 10s 54ms/step - loss: 1858.1040 - mse: 1862.9565\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 3.2774 - mse: 3.2777\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 3.3437 - mse: 3.3521\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 9s 47ms/step - loss: 5.7820 - mse: 5.7900\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 6.1732 - mse: 6.1719\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 13.4687 - mse: 13.4985\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 7.5317 - mse: 7.5424\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 7s 38ms/step - loss: 37.6646 - mse: 37.7613\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 11s 56ms/step - loss: 5.0001 - mse: 5.0129\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 41.0760 - mse: 41.1830\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 0.0460 - mse: 0.0459\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 30.1831 - mse: 30.2623\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 8s 40ms/step - loss: 2.9083 - mse: 2.9108\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 10s 54ms/step - loss: 53.0528 - mse: 52.5952\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 14.3611 - mse: 14.3988\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 7s 36ms/step - loss: 1.2541 - mse: 1.2573\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 1.5869 - mse: 1.5891\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 3.8632 - mse: 3.8728\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 73107.0234 - mse: 73298.6953\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 28.3288 - mse: 28.3761\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 10.2166 - mse: 10.2246\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 6.4165 - mse: 6.4180\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 4.5767 - mse: 4.5771\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 3.5045 - mse: 3.5071\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 3.8504 - mse: 3.8520\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 191.2407 - mse: 191.7372\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 8s 39ms/step - loss: 2.5218 - mse: 2.5223\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 2.0916 - mse: 2.0910\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 1.7694 - mse: 1.7586\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 1.5283 - mse: 1.5297\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 1.3090 - mse: 1.3079\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 1.1496 - mse: 1.1504\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 1.0130 - mse: 1.0133\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 0.8841 - mse: 0.8843\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 7s 39ms/step - loss: 0.7978 - mse: 0.7979\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 0.7004 - mse: 0.7005\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 0.6051 - mse: 0.6049\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 7s 37ms/step - loss: 3.6569 - mse: 3.6647\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 7.0630 - mse: 7.0804\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 8s 44ms/step - loss: 0.4545 - mse: 0.4546\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 8.5141 - mse: 8.5242\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 0.5430 - mse: 0.5436\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 8s 39ms/step - loss: 0.3689 - mse: 0.3687\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 2.0302 - mse: 2.0257\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 417327.5938 - mse: 418422.3125\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 7s 38ms/step - loss: 117.9185 - mse: 117.9930\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 10s 55ms/step - loss: 52.0379 - mse: 52.1038\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 31.9334 - mse: 31.9563\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 21.5639 - mse: 21.5897\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 15.2647 - mse: 15.2661\n",
      "1-1024-Epochs=50-TIME=1586472109\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 30s 160ms/step - loss: 503.5573 - mse: 504.7615\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 32s 169ms/step - loss: 43.3272 - mse: 43.3124\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 30s 158ms/step - loss: 43.2712 - mse: 43.2896\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 31s 160ms/step - loss: 43.2843 - mse: 43.2881\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 30s 155ms/step - loss: 43.3503 - mse: 43.3620\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 31s 164ms/step - loss: 45.2083 - mse: 45.2175\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 30s 155ms/step - loss: 45.4948 - mse: 45.5114\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 47.1713 - mse: 47.1820\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 31s 160ms/step - loss: 49.4454 - mse: 49.4481\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 28s 149ms/step - loss: 53.8125 - mse: 53.8259\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 32s 167ms/step - loss: 43.4814 - mse: 43.4957\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 29s 154ms/step - loss: 46.3377 - mse: 46.3570\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 29s 153ms/step - loss: 45.4945 - mse: 45.4993\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 31s 164ms/step - loss: 47.2141 - mse: 47.2228\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 31s 161ms/step - loss: 46.6692 - mse: 46.6870\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 29s 153ms/step - loss: 46.8045 - mse: 46.8204\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 29s 154ms/step - loss: 48.8872 - mse: 48.8945\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 32s 170ms/step - loss: 44.1134 - mse: 44.1055\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 32s 167ms/step - loss: 45.7147 - mse: 45.7384\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 30s 157ms/step - loss: 48.9145 - mse: 48.9495\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 34s 176ms/step - loss: 43.2968 - mse: 43.2984\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 29s 154ms/step - loss: 47.2784 - mse: 47.1945\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 35s 182ms/step - loss: 49.4473 - mse: 49.4714\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 30s 157ms/step - loss: 43.2919 - mse: 43.2984\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 31s 162ms/step - loss: 43.3115 - mse: 43.3029\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 33s 175ms/step - loss: 45.8710 - mse: 45.8623\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 31s 162ms/step - loss: 47.5285 - mse: 47.5448\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 30s 158ms/step - loss: 44.3000 - mse: 44.3060\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 29s 152ms/step - loss: 45.5058 - mse: 45.5065\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 32s 167ms/step - loss: 44.8375 - mse: 44.8491\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 29s 154ms/step - loss: 45.1972 - mse: 45.1971\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 35s 182ms/step - loss: 46.3071 - mse: 46.3109\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 41s 213ms/step - loss: 43.4717 - mse: 43.4526\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 37s 191ms/step - loss: 48.6916 - mse: 48.7243\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 35s 183ms/step - loss: 43.2886 - mse: 43.2911\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 36s 190ms/step - loss: 43.9033 - mse: 43.9006\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 35s 182ms/step - loss: 44.4775 - mse: 44.4853\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 37s 191ms/step - loss: 44.3234 - mse: 44.3358\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 36s 189ms/step - loss: 44.7801 - mse: 44.7457\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 39s 207ms/step - loss: 44.6811 - mse: 44.7011\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 36s 186ms/step - loss: 45.5065 - mse: 45.5175\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 37s 191ms/step - loss: 44.6366 - mse: 44.6250\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 36s 187ms/step - loss: 44.3880 - mse: 44.3908\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 46.9681 - mse: 46.9936\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 36s 189ms/step - loss: 43.4108 - mse: 43.4182\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 37s 195ms/step - loss: 43.6466 - mse: 43.6541\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 36s 186ms/step - loss: 44.1478 - mse: 44.1381\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 44.7341 - mse: 44.7460\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 35s 181ms/step - loss: 44.0615 - mse: 44.0476\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 45.3705 - mse: 45.3881\n",
      "1-1024-Epochs=50-TIME=1586473764\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 37s 194ms/step - loss: 9902.3096 - mse: 9928.2686\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 35s 185ms/step - loss: 6.4770 - mse: 6.4875\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 35s 183ms/step - loss: 23.8708 - mse: 23.8578\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 38s 199ms/step - loss: 1.4220 - mse: 1.4250\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 37s 192ms/step - loss: 0.2640 - mse: 0.2635\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 36s 187ms/step - loss: 18.8851 - mse: 18.9343\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 41s 215ms/step - loss: 0.0753 - mse: 0.0754\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 37s 191ms/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 40s 208ms/step - loss: 0.0528 - mse: 0.0527\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 0.9543 - mse: 0.9566\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 38s 200ms/step - loss: 3.5642 - mse: 3.5735\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 40s 211ms/step - loss: 5.9903 - mse: 6.0060\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 39s 207ms/step - loss: 12.6325 - mse: 12.6656\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 37s 196ms/step - loss: 12.9803 - mse: 13.0008\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 40s 208ms/step - loss: 25.0675 - mse: 25.0155\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 36s 189ms/step - loss: 1.7107 - mse: 1.7133\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 32s 170ms/step - loss: 23.0469 - mse: 23.1020\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 28s 147ms/step - loss: 30.6231 - mse: 30.6897\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 37s 193ms/step - loss: 3902496.2500 - mse: 3732388.2500\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 39s 206ms/step - loss: 19964882.0000 - mse: 20017254.0000\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 35s 182ms/step - loss: 3431.0461 - mse: 3436.6060\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 37s 196ms/step - loss: 995.4382 - mse: 995.9163\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 35s 183ms/step - loss: 522.7242 - mse: 523.0627\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 38s 197ms/step - loss: 315.5523 - mse: 315.7655\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 37s 193ms/step - loss: 210.8355 - mse: 210.7944\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 35s 184ms/step - loss: 152.7345 - mse: 152.8209\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 35s 186ms/step - loss: 117.9766 - mse: 118.0720\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 40s 211ms/step - loss: 95.6593 - mse: 95.6867\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 79.4063 - mse: 79.4428\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 37s 193ms/step - loss: 67.6048 - mse: 67.6589\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 39s 204ms/step - loss: 58.4700 - mse: 58.4328\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 36s 189ms/step - loss: 50.6239 - mse: 50.6430\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 39s 203ms/step - loss: 43.9667 - mse: 43.9878\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 38s 201ms/step - loss: 38.3856 - mse: 38.3741\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 37s 193ms/step - loss: 33.2599 - mse: 33.2795\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 41s 215ms/step - loss: 29.1832 - mse: 29.1926\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 43s 223ms/step - loss: 25.4451 - mse: 25.4559\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 41s 213ms/step - loss: 22.0986 - mse: 22.1041\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 42s 219ms/step - loss: 19.2770 - mse: 19.2739\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 16.8716 - mse: 16.8580\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 14.6671 - mse: 14.6769\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 40s 210ms/step - loss: 12.8700 - mse: 12.8707\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 11.2755 - mse: 11.27027\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 9.8080 - mse: 9.8092\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 8.6861 - mse: 8.6947\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 37.6484 - mse: 32.0261\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 40s 210ms/step - loss: 930.5222 - mse: 932.9446\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 6.9907 - mse: 6.9971\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 44s 228ms/step - loss: 476.1042 - mse: 477.3372\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 42s 221ms/step - loss: 273.1374 - mse: 273.8095\n",
      "2-16-Epochs=50-TIME=1586475707\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 6408.7612 - mse: 6425.4907\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 40.0996 - mse: 40.1073\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 39.7957 - mse: 39.7732\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 39.4643 - mse: 39.4626\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 8ms/step - loss: 39.5136 - mse: 39.5037\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 39.2561 - mse: 39.2654\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 38.5744 - mse: 38.5772\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 38.5961 - mse: 38.5879\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 38.6310 - mse: 38.5961\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 38.4928 - mse: 38.4737\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 4s 22ms/step - loss: 39.0503 - mse: 39.0470\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.6571 - mse: 38.6478\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.7685 - mse: 38.7781\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 39.0188 - mse: 39.0264\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.5773 - mse: 38.5735\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.6369 - mse: 38.6326\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.9891 - mse: 38.9994\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 38.7935 - mse: 38.7973\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.5355 - mse: 38.5377\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.3222 - mse: 38.3287\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 38.7524 - mse: 38.7731\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 38.3616 - mse: 38.3562\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.5939 - mse: 38.6079\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.6799 - mse: 38.6903\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.6784 - mse: 38.6885\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.6930 - mse: 38.7101\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.6719 - mse: 38.6655\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.6928 - mse: 38.6938\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 39.0085 - mse: 38.9717\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.4573 - mse: 38.4497\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 38.5653 - mse: 38.5695\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 38.4645 - mse: 38.4712\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 38.4861 - mse: 38.4919\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 38.6447 - mse: 38.6529\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.5257 - mse: 38.5371\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.4983 - mse: 38.5087\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.3837 - mse: 38.3892\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.5567 - mse: 38.5432\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.4472 - mse: 38.4406\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.4615 - mse: 38.4574\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.4262 - mse: 38.4223\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.4892 - mse: 38.4889\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.3708 - mse: 38.3784\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.3879 - mse: 38.3905\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 4s 22ms/step - loss: 38.5075 - mse: 38.5284\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.5063 - mse: 38.5137\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.5417 - mse: 38.5386\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.3185 - mse: 38.3082\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 38.4792 - mse: 38.4738\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 38.4119 - mse: 38.4254\n",
      "2-16-Epochs=50-TIME=1586475810\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 3640.5815 - mse: 3650.0916\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 19.8443 - mse: 19.8251\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 19.3102 - mse: 19.3203\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 19.3327 - mse: 19.3299\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 19.3727 - mse: 19.3756\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 19.1035 - mse: 19.1070\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 18.2072 - mse: 18.2088\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 17.7310 - mse: 17.7423\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 16.1420 - mse: 16.1252\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 13.3806 - mse: 13.3874\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 13.7269 - mse: 13.7275\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 11.8188 - mse: 11.8253\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 10.8829 - mse: 10.8903\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 10.6010 - mse: 10.5957\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 9.2324 - mse: 9.2399\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 9.7600 - mse: 9.7788\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 4s 22ms/step - loss: 7.0015 - mse: 7.0028\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 6.9538 - mse: 6.9642\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 6.0681 - mse: 6.0676\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 6.4073 - mse: 6.4091\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 5.9929 - mse: 5.9851\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 5.9895 - mse: 5.9991\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 5.5412 - mse: 5.5398\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 6.0764 - mse: 6.0809\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 4.5961 - mse: 4.6037\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 4.8713 - mse: 4.8793\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 4.6115 - mse: 4.6125\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 5.2514 - mse: 5.1786: 0s - loss: 4.1188\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 3.4373 - mse: 3.4367\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 3.9688 - mse: 3.9712\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 2.8900 - mse: 2.8934\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 2.7040 - mse: 2.7096\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 2.3698 - mse: 2.3741\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 2.1127 - mse: 2.1162\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 2.1308 - mse: 2.1349\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 2.6801 - mse: 2.6848\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 1.6448 - mse: 1.6472\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 2.0458 - mse: 2.0505\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 2.0490 - mse: 2.0535\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 1.9782 - mse: 1.9805\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 1.8981 - mse: 1.8917\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 1.8466 - mse: 1.8496\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 1.8951 - mse: 1.8983\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 1.8592 - mse: 1.8608\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 2.2568 - mse: 2.2604\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 1.7001 - mse: 1.7015\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 1.6994 - mse: 1.7015\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 1.7347 - mse: 1.7367\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 1.7608 - mse: 1.7622\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 1.6945 - mse: 1.6977\n",
      "2-32-Epochs=50-TIME=1586475912\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 3804.3796 - mse: 3814.2573\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.6322 - mse: 43.6215\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2718 - mse: 43.2756\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.2981 - mse: 43.2944\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.3803 - mse: 43.3457\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.2877 - mse: 43.2822\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 43.3530 - mse: 43.3615\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 43.8704 - mse: 43.8779\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 43.1129 - mse: 43.1148: 3s \n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.2222 - mse: 43.2099\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.0468 - mse: 43.0386\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.1110 - mse: 43.1216\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 43.2718 - mse: 43.2484\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.4038 - mse: 43.3987\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 43.1869 - mse: 43.1918\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 43.2872 - mse: 43.2770\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 5s 24ms/step - loss: 43.2056 - mse: 43.2044\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.2950 - mse: 43.2876\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 43.5100 - mse: 43.5194\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.0316 - mse: 43.0287\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 43.0786 - mse: 43.0946\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 43.2881 - mse: 43.2913\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 43.1402 - mse: 43.1351\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 43.4915 - mse: 43.5077\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 4s 19ms/step - loss: 43.1693 - mse: 43.1326\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 42.3669 - mse: 42.3808\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.7099 - mse: 41.7175\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.8205 - mse: 41.8277\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.7715 - mse: 41.7411\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 41.6752 - mse: 41.6706\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 42.0884 - mse: 42.0994\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 41.6806 - mse: 41.6811\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 41.6960 - mse: 41.7180\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 42.0618 - mse: 42.0721\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 41.5490 - mse: 41.5611\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.7016 - mse: 41.6951\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.6228 - mse: 41.6051\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 41.7911 - mse: 41.7961\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 41.6746 - mse: 41.6741\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 41.7883 - mse: 41.7954\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 41.7454 - mse: 41.7668\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 5s 25ms/step - loss: 41.6931 - mse: 41.6831\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 42.5364 - mse: 42.5258\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.5714 - mse: 41.5682\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.5682 - mse: 41.5905\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 41.6956 - mse: 41.6898\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 41.7884 - mse: 41.8031\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 41.5460 - mse: 41.5457\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 41.6934 - mse: 41.7023\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 4s 23ms/step - loss: 41.7097 - mse: 41.7004\n",
      "2-32-Epochs=50-TIME=1586476058\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 2984.9138 - mse: 2992.6934\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 21.1737 - mse: 21.1725\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 21.1798 - mse: 21.1866\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 19.6177 - mse: 19.5348\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 18.9451 - mse: 18.9591\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 18.3759 - mse: 18.3802\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 16.8388 - mse: 16.8587\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 14.3738 - mse: 14.3745\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 13.5060 - mse: 13.5264\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 11.4572 - mse: 11.4624\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 9.7110 - mse: 9.7127\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 7.4030 - mse: 7.4026\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 6.3734 - mse: 6.3823\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 5.0031 - mse: 5.0080\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 4.0608 - mse: 4.0674\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 4.6408 - mse: 4.6473\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.0528 - mse: 2.0568\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 5s 24ms/step - loss: 2.9761 - mse: 2.9742\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 2.2651 - mse: 2.2700\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.5549 - mse: 2.5593\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 2.3364 - mse: 2.3327\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 1.9867 - mse: 1.9909\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.1368 - mse: 2.1421\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 1.7937 - mse: 1.7965\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 2.1836 - mse: 2.1886\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.9562 - mse: 0.9574\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 1.7676 - mse: 1.7721\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.9698 - mse: 0.9655\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 1.2119 - mse: 1.2149\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 1.4939 - mse: 1.4966\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.9445 - mse: 0.9443\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.7582 - mse: 0.7594\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 2.0031 - mse: 2.0022\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 0.8188 - mse: 0.8095\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 1.1512 - mse: 1.1531\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 5s 24ms/step - loss: 0.8688 - mse: 0.8689\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 1.2055 - mse: 1.2047\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.9489 - mse: 0.9480\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 1.1078 - mse: 1.1077\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 1.1826 - mse: 1.1831\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 0.9251 - mse: 0.9259\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.9836 - mse: 0.9859\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 1.9556 - mse: 1.9606\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 2s 10ms/step - loss: 0.6453 - mse: 0.6465\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 4s 23ms/step - loss: 0.8696 - mse: 0.8715: 1s\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.8642 - mse: 0.8663\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.9940 - mse: 0.9966\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 1.5081 - mse: 1.5120\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 0.6678 - mse: 0.6683\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 0.7002 - mse: 0.7004\n",
      "2-64-Epochs=50-TIME=1586476190\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25711.4395 - mse: 25707.8535\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 25700.8359 - mse: 25702.9297\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 4s 22ms/step - loss: 25698.2715 - mse: 25702.8340\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25708.0000 - mse: 25702.7656\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25704.5840 - mse: 25702.7461\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 25707.0527 - mse: 25702.7168\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25700.0527 - mse: 25702.7148\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 4s 23ms/step - loss: 25703.3398 - mse: 25702.7012\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 5s 24ms/step - loss: 25710.2539 - mse: 25702.7344\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25704.2559 - mse: 25702.7617\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25707.6602 - mse: 25702.6855\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25703.4707 - mse: 25702.7090\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25706.6680 - mse: 25702.7090\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25701.7676 - mse: 25702.7090\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 25710.4980 - mse: 25702.7344\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25698.0449 - mse: 25702.7188\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25697.0078 - mse: 25702.7480\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25703.2402 - mse: 25702.6934\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 25695.1797 - mse: 25702.6875\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25698.5098 - mse: 25702.7109\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 25696.5898 - mse: 25702.7051:\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25706.3438 - mse: 25702.6953\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25701.0605 - mse: 25702.7051\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 25705.0918 - mse: 25702.7031\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25704.3828 - mse: 25702.6895\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25706.8105 - mse: 25702.7090\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 25699.0664 - mse: 25702.6875\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25697.8027 - mse: 25702.6953\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25701.7402 - mse: 25702.7012\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 25704.4297 - mse: 25702.6953\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 25704.9219 - mse: 25702.6934\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25698.3359 - mse: 25702.7188\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 25705.3906 - mse: 25702.7227\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25701.1855 - mse: 25702.7246\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25699.7051 - mse: 25702.6895\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25710.9316 - mse: 25702.6895\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25706.2090 - mse: 25702.6953\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25700.5762 - mse: 25702.7188\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 25701.4824 - mse: 25702.6855: 0s - loss: 25716.\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 25703.0293 - mse: 25702.6895\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25701.7051 - mse: 25702.6953\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25702.8359 - mse: 25702.6973\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 25705.4238 - mse: 25702.6953\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 25701.2441 - mse: 25702.6953\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 25704.3867 - mse: 25702.7012\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 25706.5918 - mse: 25702.6855\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 25700.6523 - mse: 25702.6934\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 25705.1934 - mse: 25702.7188\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - ETA: 0s - loss: 25696.9746 - mse: 25696.974 - 3s 18ms/step - loss: 25708.4141 - mse: 25702.7090\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 25697.8789 - mse: 25702.6797\n",
      "2-64-Epochs=50-TIME=1586476383\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 1582.4769 - mse: 1586.5801\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 18.8083 - mse: 18.7717\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 17.7250 - mse: 17.7352\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 17.4464 - mse: 17.4417\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 13.9015 - mse: 13.9193\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 14.0874 - mse: 14.1114\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 7.0063 - mse: 6.9921\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 7.0480 - mse: 7.0638\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 4.1078 - mse: 4.1134\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 6.7005 - mse: 6.7159\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2.3662 - mse: 2.3600\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 3.9001 - mse: 3.9035\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 3.4046 - mse: 3.4103\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 3.4803 - mse: 3.4858\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 3.1474 - mse: 3.1550: 3s - loss: 1 \n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 3.6560 - mse: 3.6576\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 2.5651 - mse: 2.5678\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 1.2442 - mse: 1.1895\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 4.0720 - mse: 4.0780\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 2.5160 - mse: 2.5192\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 4.9409 - mse: 4.9469\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.6301 - mse: 1.6340\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 3.2621 - mse: 3.2700\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 6.0382 - mse: 6.0522\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.0653 - mse: 0.0654\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 1.4067 - mse: 1.4096\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 3.0939 - mse: 3.1009\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 3.2323 - mse: 3.2306\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.2097 - mse: 1.2125\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2.0723 - mse: 2.0756\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 2.5105 - mse: 2.5170\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 1.7097 - mse: 1.7116\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2.4723 - mse: 2.4779\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 4.4087 - mse: 4.4202\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.1631 - mse: 0.1632\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 5s 26ms/step - loss: 2.3587 - mse: 2.3610\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 3.8493 - mse: 3.7756\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 1.3354 - mse: 1.3388\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.8501 - mse: 0.8520\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 1.6944 - mse: 1.6895\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 2.3565 - mse: 2.3623\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 4s 23ms/step - loss: 17.9386 - mse: 17.9822: 0s - loss: 18.7740 - mse:\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.2092 - mse: 0.2097\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.0213 - mse: 0.0206\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2026 - mse: 0.2031\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 1.3618 - mse: 1.3653\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.6516 - mse: 0.6532\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 1.4167 - mse: 1.4199\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 5.6413 - mse: 5.6492\n",
      "2-128-Epochs=50-TIME=1586476558\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1369.6405 - mse: 1373.1062\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 42.6113 - mse: 42.6209\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 43.2631 - mse: 43.2597\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 44.2826 - mse: 44.2920\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 43.4196 - mse: 43.4005\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 44.2535 - mse: 44.2509\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 45.1820 - mse: 45.1996\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 44.7425 - mse: 44.7250\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 44.7702 - mse: 44.7747\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 45.5952 - mse: 45.5606\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 8s 42ms/step - loss: 43.3062 - mse: 43.3210\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 44.6410 - mse: 44.6367\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 46.5239 - mse: 46.5098\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 7s 38ms/step - loss: 43.3196 - mse: 43.2939\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 52.9431 - mse: 52.9596\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 43.2903 - mse: 43.2882\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 43.2810 - mse: 43.2893\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 8s 41ms/step - loss: 43.2885 - mse: 43.2880\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 43.5891 - mse: 43.5560: 1s - loss: 43.615\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 44.7886 - mse: 44.7824\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 45.2139 - mse: 45.2312\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 44.7501 - mse: 44.6673\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 43.8106 - mse: 43.8101\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 44.2850 - mse: 44.2707\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 44.7059 - mse: 44.6798\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 45.0536 - mse: 45.0577\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 43.9292 - mse: 43.9410\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 44.7008 - mse: 44.7175\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 44.5218 - mse: 44.5400\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 45.4954 - mse: 45.5103\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 43.3653 - mse: 43.3774\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 44.8421 - mse: 44.8530\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 43.4955 - mse: 43.5150\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 44.5239 - mse: 44.5418\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 46.7401 - mse: 46.7307\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 43.2938 - mse: 43.2911\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 43.2944 - mse: 43.2939\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 49.7543 - mse: 49.7804\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 43.2788 - mse: 43.2903\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 43.3102 - mse: 43.2880\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2733 - mse: 43.2878\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 43.3355 - mse: 43.3560\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 44.1929 - mse: 44.2144\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 45.4620 - mse: 45.4887\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 43.2876 - mse: 43.2900\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 45.1024 - mse: 45.0932\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 43.2857 - mse: 43.2901\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 45.8021 - mse: 45.8014\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 43.2783 - mse: 43.2889\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 44.1765 - mse: 44.1567\n",
      "2-128-Epochs=50-TIME=1586476800\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 1349.4022 - mse: 1352.9171\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 13.9041 - mse: 13.9052\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 13.0168 - mse: 13.0384\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 12.7972 - mse: 12.8116\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 8.4069 - mse: 8.2380\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 6.5825 - mse: 6.5935\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 3.8675 - mse: 3.8740\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 7.1616 - mse: 7.1794\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 4.3039 - mse: 4.2919\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 5.8172 - mse: 5.8249\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 4.4309 - mse: 4.4392\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 7.9775 - mse: 7.9967\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2.5505 - mse: 2.5546\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 5.1788 - mse: 5.1880\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 14.2494 - mse: 14.2867\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 3.1036 - mse: 3.1114\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 5s 26ms/step - loss: 6.4331 - mse: 6.4498\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 7.5616 - mse: 7.5804\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 8.5011 - mse: 8.4945\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2.7827 - mse: 2.7793\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 3.4962 - mse: 3.4139\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 2s 13ms/step - loss: 4.4383 - mse: 4.4236\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 29.0817 - mse: 27.6566\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 28.1175 - mse: 28.1913\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 1.2369 - mse: 1.2398\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.0251 - mse: 0.0252\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 2494.1716 - mse: 2459.9636\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 1271.6492 - mse: 1274.9656\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 5.2765 - mse: 5.2800\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 3.7623 - mse: 3.7624\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 2.6831 - mse: 2.6861\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 1.8369 - mse: 1.8370\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 1.1942 - mse: 1.1951\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 0.7532 - mse: 0.7542\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.4738 - mse: 0.4742\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.3034 - mse: 0.3040\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.2006 - mse: 0.2008\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.1413 - mse: 0.1414\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 8.9206 - mse: 8.9438\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 0.0737 - mse: 0.0738\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.0336 - mse: 0.0337\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.0282 - mse: 0.0281\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 3.2061 - mse: 3.2144\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.0220 - mse: 0.0220\n",
      "2-256-Epochs=50-TIME=1586476991\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 435.6698 - mse: 436.6941\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 11s 56ms/step - loss: 58.1892 - mse: 58.2385\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 9s 46ms/step - loss: 43.3106 - mse: 43.3166\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 12s 62ms/step - loss: 43.4107 - mse: 43.3304\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 48.9880 - mse: 49.0040\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 12s 60ms/step - loss: 45.0041 - mse: 45.0135\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 48.8684 - mse: 48.8724\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 48.3712 - mse: 48.3873\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 46.7981 - mse: 46.7816\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 9s 46ms/step - loss: 48.9789 - mse: 49.0074\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 12s 63ms/step - loss: 43.3667 - mse: 43.3592\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 46.2307 - mse: 46.2326\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 12s 61ms/step - loss: 47.6645 - mse: 47.6554\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 46.6735 - mse: 46.6725\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 50.1611 - mse: 50.1869\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 43.2903 - mse: 43.2976\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 50.4632 - mse: 50.4853\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 43.2859 - mse: 43.2902\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 9s 46ms/step - loss: 46.5753 - mse: 46.5977\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 12s 62ms/step - loss: 45.8406 - mse: 45.8634\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 9s 49ms/step - loss: 46.9142 - mse: 46.9227\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 12s 62ms/step - loss: 46.2753 - mse: 46.2912\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 45.3478 - mse: 45.3512\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 44.5213 - mse: 44.5113\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 10s 51ms/step - loss: 46.3728 - mse: 46.3947\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 8s 43ms/step - loss: 45.1882 - mse: 45.1973\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 47.2910 - mse: 47.3105\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 45.5095 - mse: 45.5244\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 44.2199 - mse: 44.1981\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 13s 70ms/step - loss: 45.2863 - mse: 45.2849\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 12s 62ms/step - loss: 51.5943 - mse: 51.6140\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 13s 71ms/step - loss: 43.2796 - mse: 43.2885\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 12s 63ms/step - loss: 43.2771 - mse: 43.2882\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 14s 72ms/step - loss: 44.5045 - mse: 44.5020\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 12s 61ms/step - loss: 45.0531 - mse: 45.0598\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 14s 74ms/step - loss: 47.0899 - mse: 47.0995\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 43.7012 - mse: 43.6887\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 14s 75ms/step - loss: 45.2337 - mse: 45.2586\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 13s 70ms/step - loss: 46.0239 - mse: 46.0272\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 12s 62ms/step - loss: 43.3320 - mse: 43.3300\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 47.8682 - mse: 47.8839\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 12s 64ms/step - loss: 43.3045 - mse: 43.3135\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 44.7657 - mse: 44.7620\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 12s 64ms/step - loss: 45.0461 - mse: 45.0520\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 14s 72ms/step - loss: 43.6121 - mse: 43.6139\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 11s 60ms/step - loss: 44.8861 - mse: 44.8760\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 14s 73ms/step - loss: 45.3700 - mse: 45.3979\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 46.7641 - mse: 46.7859\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 14s 72ms/step - loss: 43.2933 - mse: 43.2976\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 11s 58ms/step - loss: 44.4541 - mse: 44.4589\n",
      "2-256-Epochs=50-TIME=1586477567\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 12s 61ms/step - loss: 2090.7212 - mse: 2096.1848\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 12s 64ms/step - loss: 8.5401 - mse: 8.5402\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 11s 60ms/step - loss: 29.2453 - mse: 29.3158\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 7.3924 - mse: 7.4067\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 11s 60ms/step - loss: 7.3544 - mse: 7.3711\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 12s 65ms/step - loss: 3.1405 - mse: 3.1454\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 8.2325 - mse: 8.2528\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 6.2057 - mse: 6.2125\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 12s 61ms/step - loss: 5.6549 - mse: 5.6664\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 32.6257 - mse: 32.7112\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 2.9050 - mse: 2.9125\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 12s 65ms/step - loss: 13.7109 - mse: 13.7395\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 1292798.1250 - mse: 1288681.7500\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 12s 65ms/step - loss: 92970.0391 - mse: 93190.1172\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 2022.0018 - mse: 2027.0886\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 12s 65ms/step - loss: 100.2789 - mse: 100.3435\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 71.0482 - mse: 71.0542\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 54.9737 - mse: 54.9995\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 44.0300 - mse: 44.0405\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 36.0847 - mse: 36.0876\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 11s 59ms/step - loss: 29.9004 - mse: 29.9104\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 12s 64ms/step - loss: 25.1776 - mse: 25.1976\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 21.3906 - mse: 21.3927\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 18.1473 - mse: 18.1454\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 15.5745 - mse: 15.5786\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 13.3957 - mse: 13.4013\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 11.6220 - mse: 11.6217\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 10.0741 - mse: 10.0837\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 8.7982 - mse: 8.8058\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 13s 68ms/step - loss: 7.7295 - mse: 7.7279\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 6.8214 - mse: 6.8204\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 13s 67ms/step - loss: 6.0638 - mse: 6.0607\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 5.4152 - mse: 5.4123\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 13s 68ms/step - loss: 4.8469 - mse: 4.8403\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 4.4112 - mse: 4.4147\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 246.6219 - mse: 247.2604\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 11s 56ms/step - loss: 3.9204 - mse: 3.9219\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 3.4219 - mse: 3.4249\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 11s 57ms/step - loss: 3.0527 - mse: 3.0545\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 13s 70ms/step - loss: 2.7604 - mse: 2.7630\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 10s 55ms/step - loss: 2.5272 - mse: 2.5265\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 61.0592 - mse: 60.8834\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 10s 55ms/step - loss: 5.9645 - mse: 5.9763\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 2.2182 - mse: 2.2188\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 11s 55ms/step - loss: 28.4698 - mse: 28.5413\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 75.2764 - mse: 75.4570\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 11s 56ms/step - loss: 11.0612 - mse: 11.0881\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 13s 70ms/step - loss: 1.3557 - mse: 1.3518\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 10s 54ms/step - loss: 24.4303 - mse: 24.4912\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 13s 69ms/step - loss: 1.1230 - mse: 1.1236\n",
      "2-512-Epochs=50-TIME=1586478169\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 801.7486 - mse: 803.7477\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 36s 191ms/step - loss: 42.8141 - mse: 42.8172\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 38s 198ms/step - loss: 42.6246 - mse: 42.5802\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 42.7460 - mse: 42.7491\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 42s 219ms/step - loss: 42.6076 - mse: 42.6110\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 49.1269 - mse: 49.1624\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 44s 229ms/step - loss: 49.9957 - mse: 50.0146\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 44s 229ms/step - loss: 45.3102 - mse: 45.1839\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 55.6330 - mse: 55.6634\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 46.6921 - mse: 46.7037\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 47s 245ms/step - loss: 51.2646 - mse: 51.2782\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 45s 236ms/step - loss: 50.1328 - mse: 50.1708\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 44s 229ms/step - loss: 50.2467 - mse: 50.2440\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 44s 230ms/step - loss: 69.0912 - mse: 69.1513\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 43s 225ms/step - loss: 137.6770 - mse: 137.9343\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 40s 211ms/step - loss: 42.5588 - mse: 42.5445\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 42.5747 - mse: 42.5562\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 42.5685 - mse: 42.5659\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 42s 221ms/step - loss: 42.5729 - mse: 42.5511\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 42s 218ms/step - loss: 42.5366 - mse: 42.5405\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 44s 228ms/step - loss: 42.5588 - mse: 42.5673\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 45.0728 - mse: 45.0642\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 43.7289 - mse: 43.7112\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 44.0611 - mse: 44.0836\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 41s 216ms/step - loss: 45.6647 - mse: 45.6679\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 47.1089 - mse: 47.0279\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 44s 228ms/step - loss: 43.4203 - mse: 43.4304\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 46.1670 - mse: 46.1841\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 41s 214ms/step - loss: 49.5121 - mse: 49.5345\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 42.7879 - mse: 42.7891\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 44s 228ms/step - loss: 45.1883 - mse: 45.2079\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 44s 230ms/step - loss: 52.6123 - mse: 52.6270\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 43s 223ms/step - loss: 42.6160 - mse: 42.6279\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 45.5963 - mse: 45.5977\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 40s 210ms/step - loss: 44.0413 - mse: 44.0265\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 46.9800 - mse: 46.9911\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 43.8217 - mse: 43.8358\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 41s 216ms/step - loss: 45.8077 - mse: 45.8154\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 42s 221ms/step - loss: 45.7235 - mse: 45.7392\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 48.0009 - mse: 48.0329\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 43s 224ms/step - loss: 42.5647 - mse: 42.5473\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 41s 216ms/step - loss: 42.8336 - mse: 42.8162\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 44.9766 - mse: 44.9889\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 43s 225ms/step - loss: 44.3916 - mse: 44.3775\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 46.3277 - mse: 46.3503\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 43s 226ms/step - loss: 44.7474 - mse: 44.7616\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 42s 218ms/step - loss: 44.2333 - mse: 44.2515\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 43s 227ms/step - loss: 47.6756 - mse: 47.6981\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 41s 216ms/step - loss: 45.2580 - mse: 45.2540\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 40s 212ms/step - loss: 43.0829 - mse: 43.0742\n",
      "2-512-Epochs=50-TIME=1586480304\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 40s 212ms/step - loss: 9173.0566 - mse: 9197.1025\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 40s 209ms/step - loss: 28.2046 - mse: 28.2624\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 38s 200ms/step - loss: 18.9097 - mse: 18.9526\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 43s 223ms/step - loss: 2.0039 - mse: 2.0064\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 42s 218ms/step - loss: 0.9784 - mse: 0.9795\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 41s 216ms/step - loss: 2.9627 - mse: 2.9667\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 40s 207ms/step - loss: 8.5105 - mse: 8.5327\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 42s 221ms/step - loss: 0.2351 - mse: 0.2288\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 40s 208ms/step - loss: 0.6496 - mse: 0.6463\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 40s 207ms/step - loss: 1838758656.0000 - mse: 1843583616.0000\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 42s 217ms/step - loss: 236263.3438 - mse: 236485.6406\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 41s 217ms/step - loss: 107806.6406 - mse: 107875.9141\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 39s 205ms/step - loss: 75015.4844 - mse: 75084.5234\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 43s 223ms/step - loss: 59070.0625 - mse: 59027.2930\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 42s 222ms/step - loss: 48625.9375 - mse: 48637.1602\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 41s 214ms/step - loss: 41351.8125 - mse: 41140.0820\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 40s 209ms/step - loss: 35331.0508 - mse: 35348.7305\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 30688.1699 - mse: 30708.6562\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 41s 212ms/step - loss: 26797.1895 - mse: 26803.5488\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 40s 208ms/step - loss: 23393.4238 - mse: 23404.4512\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 43s 223ms/step - loss: 20361.6855 - mse: 20373.7148\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 42s 221ms/step - loss: 17629.6738 - mse: 17624.9434\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 40s 209ms/step - loss: 15128.1777 - mse: 15132.6309\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 40s 211ms/step - loss: 12871.2256 - mse: 12872.2051\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 41s 213ms/step - loss: 10865.5361 - mse: 10862.9463\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 42s 219ms/step - loss: 9105.3037 - mse: 9105.7490\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 40s 211ms/step - loss: 7649.4673 - mse: 7608.5112\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 6348.5112 - mse: 6351.0083\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 41s 217ms/step - loss: 5334.8755 - mse: 5331.1357\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 40s 207ms/step - loss: 4506.3721 - mse: 4507.3784\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 42s 220ms/step - loss: 3841.8499 - mse: 3843.5334\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 42s 222ms/step - loss: 3307.3464 - mse: 3310.0793\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 40s 212ms/step - loss: 2875.6055 - mse: 2877.4067\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 38s 197ms/step - loss: 2512.2170 - mse: 2512.9353\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 2206.6418 - mse: 2208.3533\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 30s 160ms/step - loss: 1944.1362 - mse: 1946.1488\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 28s 148ms/step - loss: 1717.6569 - mse: 1716.4612\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 28s 147ms/step - loss: 1517.2261 - mse: 1515.0549\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 1338.0033 - mse: 1338.6871\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 1183.3527 - mse: 1184.1609\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 31s 161ms/step - loss: 1042.4927 - mse: 1043.8148\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 28s 148ms/step - loss: 920.1775 - mse: 920.8352\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 811.9163 - mse: 812.5101\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 715.6623 - mse: 715.6717\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 30s 156ms/step - loss: 629.9005 - mse: 630.6525\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 29s 149ms/step - loss: 555.9800 - mse: 556.2719\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 28s 147ms/step - loss: 488.5998 - mse: 489.1913\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 29s 150ms/step - loss: 431.3241 - mse: 431.7834\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 32s 167ms/step - loss: 380.0706 - mse: 380.3894\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 32s 166ms/step - loss: 335.2867 - mse: 335.4629\n",
      "2-1024-Epochs=50-TIME=1586482171\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 119s 625ms/step - loss: 353.3131 - mse: 354.0833\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 119s 624ms/step - loss: 65.0338 - mse: 65.0803\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 122s 641ms/step - loss: 54.5190 - mse: 54.5139\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 125s 653ms/step - loss: 59.7740 - mse: 59.8242\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 129s 676ms/step - loss: 64.6164 - mse: 64.6788\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 119s 625ms/step - loss: 48.3183 - mse: 48.3174\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 137s 716ms/step - loss: 65.4433 - mse: 65.5034\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 140s 735ms/step - loss: 55.6762 - mse: 54.7222\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 152s 798ms/step - loss: 49.3802 - mse: 49.4091\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 155s 811ms/step - loss: 53.4747 - mse: 53.4831\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 152s 798ms/step - loss: 60.4442 - mse: 60.4486\n",
      "Epoch 12/50\n",
      " 40/191 [=====>........................] - ETA: 2:11 - loss: 44.0920 - mse: 44.0920"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-80254107eff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs/AE/{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLOGNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mae_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumLayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#             result = compareClasifiers (ae_model, X_train, y_train, X_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    782\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "writer = pd.ExcelWriter('output/results_AE_test1.xlsx', engine='xlsxwriter')\n",
    "\n",
    "NUM_LAYERS = [1,2,3,4,5,6]\n",
    "NUM_BASE_NODES = [16,32,64,128,256,512,1024]\n",
    "ACTS = ['relu','linear']\n",
    "\n",
    "\n",
    "for numLayers in NUM_LAYERS:\n",
    "    for numNodes in NUM_BASE_NODES:\n",
    "        for ac in ACTS:\n",
    "            LOGNAME = \"{}-{}-Epochs={}-TIME={}\".format(numLayers, numNodes , EPOCHS, int(time.time()) )\n",
    "            print(LOGNAME)\n",
    "            tensorboard = TensorBoard(log_dir='logs/AE/{}/{}'.format(ac,LOGNAME))\n",
    "            ae_model = build_autoencoder(X, num_hidden_layers = numLayers, base_nodes = numNodes, act = ac)\n",
    "            ae_model.fit(X, X, epochs = EPOCHS, batch_size = BATCH_SIZE, callbacks = [tensorboard])\n",
    "            \n",
    "            result = compareClasifiers (ae_model, X_train, y_train, X_test, y_test)\n",
    "            sheetName = '{}-{}-{}'.format(ac,numLayers, numNodes)\n",
    "            result.to_excel(writer, sheet_name = sheetName)\n",
    "                    \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs of each architecture are recorded using the tensorboard callback and can be accessed by running the below shell command and accessing the provided link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir logs/AE/test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of test 1 reveal that too many layers and nodes decreased the performance of the autoencoder. Most of the models tested had similar performance when looking at the loss and mse curves on tensorboard. As such, the model was chosen based on computational efficiency and smoothness of the curves.  \n",
    "\n",
    "The model chosen has 2 hidden layers with a base number of nodes to 16. The number of layers here refers to the number of layers in the encoder, which match the number of layers in the decoder due to symmetry. This means that the actual model has 4 hidden layers of 16-32-32-16 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test 2: Larger Networks\n",
    "The first test of autoencoder models reveals that larger networks are neccessary and they must be trained for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_LAYERS = [2,3,4,5,6]\n",
    "NUM_BASE_NODES = [64,128,256,512,1024]\n",
    "ACTS = ['tanh','relu']\n",
    "\n",
    "\n",
    "for numLayers in NUM_LAYERS:\n",
    "    for numNodes in NUM_BASE_NODES:\n",
    "        for ac in ACTS:\n",
    "            LOGNAME = \"{}-{}-Epochs={}-TIME={}\".format(numLayers, numNodes , EPOCHS, int(time.time()) )\n",
    "            print(LOGNAME)\n",
    "            tensorboard = TensorBoard(log_dir='logs/AE/{}/{}'.format(ac,LOGNAME))\n",
    "            ae_model = build_autoencoder(X, num_hidden_layers = numLayers, base_nodes = numNodes, act = ac)\n",
    "            ae_model.fit(X, X, epochs = EPOCHS, batch_size = BATCH_SIZE, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test 3: Batch Sizes and Epochs\n",
    "Now we will test for different batch sizes, and we will use a larger number of epochs to see if performance can improve. To save time, we can use an early stop callback which stops the training when a specific metric reaches a specific goal. In this case, we can stop the training if the MSE does not drop for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='mse',\n",
    "                                                      min_delta=0.0001,\n",
    "                                                      patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The model chosen from test 1:\n",
    "NUM_LAYERS = 2\n",
    "NUM_NODES = 16\n",
    "\n",
    "BATCH_SIZES = [8,16,32,64,128,256,512,1024,2048]\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "for batchSize in BATCH_SIZES:\n",
    "    LOGNAME = \"Batch={}--TIME={}\".format(batchSize , int(time.time()) )\n",
    "    print(LOGNAME)\n",
    "    tensorboard = TensorBoard(log_dir='logs/AE/test2/{}'.format(LOGNAME))\n",
    "    ae_model = build_autoencoder(X, num_hidden_layers = NUM_LAYERS, base_nodes = NUM_NODES)\n",
    "    ae_model.fit(X_train, X_train, \n",
    "        epochs = EPOCHS,\n",
    "        batch_size = batchSize,\n",
    "                callbacks = [tensorboard, earlystop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the test results by running the below shell command. These results show that a batch size of 1024 had the best performance, measured by the MSE, smoothness of the loss curve, and the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir logs/AE/test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Test 3: Retesting different architectures with classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Combining Autoencoder with Classifiers\n",
    "Now that we have an autoencoder with tuned parameters, we can test the effectiveness of this autoencoder by observing the MSE of different classifiers with and without the autoencoder. The top three classifiers, determined and tuned in the previous notebook, are defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_final = RandomForestRegressor(n_estimators=50)\n",
    "ridge_final = Ridge(alpha=5)\n",
    "huber_final = HuberRegressor(alpha=10, epsilon=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-define the final autoencoder model, train it, and get the new representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGNAME = \"FinalAE-TIME={}\".format(batchSize , int(time.time()) )\n",
    "tensorboard = TensorBoard(log_dir='logs/final/{}'.format(LOGNAME))\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "NUM_NODES = 16\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 500\n",
    "\n",
    "ae_model = build_autoencoder(X, num_hidden_layers = NUM_LAYERS, base_nodes = NUM_NODES)\n",
    "ae_model.fit(X_train, X_train, \n",
    "             epochs = EPOCHS,\n",
    "             batch_size = BATCH_SIZE,\n",
    "             callbacks = [tensorboard, earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New representations:\n",
    "X_train2 = ae_model.predict(X_train)\n",
    "X_test2 = ae_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "randomForest_final.fit(X_train,y_train)\n",
    "rf_y = randomForest_final.predict(X_test)\n",
    "rf_result = mean_squared_error(y_test, rf_y)\n",
    "\n",
    "randomForest_final.fit(X_train2,y_train)\n",
    "rf_y2 = randomForest_final.predict(X_test2)\n",
    "rf_result2 = mean_squared_error(y_test, rf_y2)\n",
    "\n",
    "print(\"Random Forest: {}\".format(rf_result))\n",
    "print(\"Random Forest with Autoencoder: {}\".format(rf_result2))\n",
    "\n",
    "\n",
    "# Ridge\n",
    "ridge_final.fit(X_train,y_train)\n",
    "ridge_y = ridge_final.predict(X_test)\n",
    "ridge_result = mean_squared_error(y_test, ridge_y)\n",
    "\n",
    "ridge_final.fit(X_train2,y_train)\n",
    "ridge_y2 = ridge_final.predict(X_test2)\n",
    "ridge_result2 = mean_squared_error(y_test, ridge_y2)\n",
    "\n",
    "print(\"Ridge : {}\".format(ridge_result))\n",
    "print(\"Ridge with Autoencoder: {}\".format(ridge_result2))\n",
    "\n",
    "# Huber\n",
    "huber_final.fit(X_train,y_train)\n",
    "huber_y = huber_final.predict(X_test)\n",
    "huber_result = mean_squared_error(y_test,huber_y)\n",
    "\n",
    "huber_final.fit(X_train2,y_train)\n",
    "huber_y2 = huber_final.predict(X_test2)\n",
    "huber_result2 = mean_squared_error(y_test,huber_y2)\n",
    "\n",
    "print(\"Huber: {}\".format(huber_result))\n",
    "print(\"Huber with Autoencoder: {}\".format(huber_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb-env",
   "language": "python",
   "name": "airbnb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
