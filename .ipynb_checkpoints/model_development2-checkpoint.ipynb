{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNN (data, num_hidden_layers = 2, hidden_nodes = 256, act = 'relu', loss_function = 'mean_absolute_error'):\n",
    "    \n",
    "    NN_model = Sequential()\n",
    "    \n",
    "    # The Input Layer :\n",
    "    input_layer= Input(shape=(data.shape[1],))\n",
    "    NN_model.add(input_layer)\n",
    "    \n",
    "    # The Hidden Layers :\n",
    "    for i in range(num_hidden_layers):\n",
    "        NN_model.add(Dense(hidden_nodes, kernel_initializer='normal',activation=act))\n",
    "\n",
    "    # The Output Layer :\n",
    "    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    # Compile the network :\n",
    "    NN_model.compile(loss= loss_function, optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    \n",
    "    return NN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNN_adv (data, num_hidden_layers = 2, hidden_nodes = 256, act = 'relu', do = 0.2, regularizer = True,\n",
    "                loss_function = 'mean_absolute_error'):\n",
    "    \n",
    "    if regularizer:\n",
    "        reg = tf.keras.regularizers.l2(l=0.01)\n",
    "    else:\n",
    "        reg = None\n",
    "        \n",
    "    NN_model = Sequential()\n",
    "    \n",
    "    # The Input Layer :\n",
    "    input_layer= Input(shape=(data.shape[1],))\n",
    "    NN_model.add(input_layer)\n",
    "\n",
    "    # The Hidden Layers :\n",
    "    for i in range(num_hidden_layers):\n",
    "        NN_model.add(Dense(hidden_nodes, kernel_initializer='normal',activation=act, kernel_regularizer = reg))\n",
    "        NN_model.add(Dropout(do))\n",
    "\n",
    "    # The Output Layer :\n",
    "    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    # Compile the network :\n",
    "    NN_model.compile(loss= loss_function, optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    \n",
    "    return NN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel (model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mse = mean_squared_error(y,y_pred)\n",
    "    r2 = r2_score(y,y_pred)\n",
    "    mae = mean_absolute_error(y,y_pred)\n",
    "    \n",
    "    return mse, r2, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>all_year_avail</th>\n",
       "      <th>low_avail</th>\n",
       "      <th>...</th>\n",
       "      <th>neighbourhood_Williamsburg</th>\n",
       "      <th>neighbourhood_Willowbrook</th>\n",
       "      <th>neighbourhood_Windsor Terrace</th>\n",
       "      <th>neighbourhood_Woodhaven</th>\n",
       "      <th>neighbourhood_Woodlawn</th>\n",
       "      <th>neighbourhood_Woodrow</th>\n",
       "      <th>neighbourhood_Woodside</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2976</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>3021</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2793</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude     price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237  5.010635               1                  9   \n",
       "1  40.75362  -73.98377  5.420535               1                 45   \n",
       "2  40.80902  -73.94190  5.017280               3                  0   \n",
       "3  40.68514  -73.95976  4.499810               1                270   \n",
       "4  40.79851  -73.94399  4.394449              10                  9   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0         2762               0.21                               6   \n",
       "1         2976               0.38                               2   \n",
       "2            0               0.00                               1   \n",
       "3         3021               4.64                               1   \n",
       "4         2793               0.10                               1   \n",
       "\n",
       "   all_year_avail  low_avail  ...  neighbourhood_Williamsburg  \\\n",
       "0            True      False  ...                           0   \n",
       "1            True      False  ...                           0   \n",
       "2            True      False  ...                           0   \n",
       "3           False      False  ...                           0   \n",
       "4           False       True  ...                           0   \n",
       "\n",
       "   neighbourhood_Willowbrook  neighbourhood_Windsor Terrace  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   neighbourhood_Woodhaven  neighbourhood_Woodlawn  neighbourhood_Woodrow  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "\n",
       "   neighbourhood_Woodside  room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                       0                          0                       1   \n",
       "1                       0                          1                       0   \n",
       "2                       0                          0                       1   \n",
       "3                       0                          1                       0   \n",
       "4                       0                          1                       0   \n",
       "\n",
       "   room_type_Shared room  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/processed_data_nyc.csv', index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.price\n",
    "data = data.drop(['price'], axis=1)\n",
    "\n",
    "X = np.asarray(data).astype(np.float32)\n",
    "y = np.asarray(y).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: (39014, 239)\n",
      "Testing Dataset: (9754, 239)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Dataset: {}\".format(X_train.shape))\n",
    "print(\"Testing Dataset: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Testing Neural Network Architectures\n",
    "\n",
    "### 3.1 Basic Architectures and Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh-1-8-Epochs=30-TIME=1586773609\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 4.2386 - mean_absolute_error: 4.2386 - mean_squared_error: 18.6184 - val_loss: 3.5087 - val_mean_absolute_error: 3.5087 - val_mean_squared_error: 12.8940\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 18us/sample - loss: 2.7087 - mean_absolute_error: 2.7087 - mean_squared_error: 8.1476 - val_loss: 1.9351 - val_mean_absolute_error: 1.9351 - val_mean_squared_error: 4.3350\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 0s 15us/sample - loss: 1.2784 - mean_absolute_error: 1.2784 - mean_squared_error: 2.2918 - val_loss: 0.7788 - val_mean_absolute_error: 0.7788 - val_mean_squared_error: 0.9796\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 0s 15us/sample - loss: 0.6512 - mean_absolute_error: 0.6512 - mean_squared_error: 0.6927 - val_loss: 0.5902 - val_mean_absolute_error: 0.5902 - val_mean_squared_error: 0.5511\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 17us/sample - loss: 0.5839 - mean_absolute_error: 0.5839 - mean_squared_error: 0.5344 - val_loss: 0.5712 - val_mean_absolute_error: 0.5712 - val_mean_squared_error: 0.5093\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5708 - mean_absolute_error: 0.5708 - mean_squared_error: 0.5090 - val_loss: 0.5618 - val_mean_absolute_error: 0.5618 - val_mean_squared_error: 0.4933\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 20us/sample - loss: 0.5622 - mean_absolute_error: 0.5622 - mean_squared_error: 0.4950 - val_loss: 0.5544 - val_mean_absolute_error: 0.5544 - val_mean_squared_error: 0.4819\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 3s 86us/sample - loss: 0.5548 - mean_absolute_error: 0.5548 - mean_squared_error: 0.4837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c57d92582369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             nn_model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, \n\u001b[1;32m     24\u001b[0m \u001b[0;31m#                          callbacks = [tensorboard],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         validation_split = 0.2)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}-{}-{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumLayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumNodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     with training_context.on_batch(\n\u001b[0;32m--> 126\u001b[0;31m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0m\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    779\u001b[0m       \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m       self.callbacks._call_batch_hook(\n\u001b[0;32m--> 781\u001b[0;31m           mode, 'begin', step, batch_logs)\n\u001b[0m\u001b[1;32m    782\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    244\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \"\"\"\n\u001b[1;32m   3494\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3495\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3548\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3335\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "NUM_LAYERS = [1,2,4,6]\n",
    "NUM_BASE_NODES = [8,32,128,512]\n",
    "ACTS = ['tanh','relu']\n",
    "\n",
    "\n",
    "mse_final = []\n",
    "mae_final = []\n",
    "r2_final = []\n",
    "names = []\n",
    "\n",
    "for numLayers in NUM_LAYERS:\n",
    "    for numNodes in NUM_BASE_NODES:\n",
    "        for act in ACTS:\n",
    "            LOGNAME = \"{}-{}-{}-Epochs={}-TIME={}\".format(act,numLayers, numNodes , EPOCHS, int(time.time()) )\n",
    "            print(LOGNAME)\n",
    "            tensorboard = TensorBoard(log_dir='logs/NN/basic/{}'.format(LOGNAME))\n",
    "            nn_model = buildNN(X, num_hidden_layers = numLayers, \n",
    "                               hidden_nodes = numNodes,\n",
    "                               act = act)\n",
    "            nn_model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "#                          callbacks = [tensorboard],\n",
    "                        validation_split = 0.2)\n",
    "\n",
    "            modelName = \"{}-{}-{}\".format(act,numLayers, numNodes)\n",
    "            mse, r2, mae = evaluateModel(nn_model, X_test, y_test)\n",
    "\n",
    "            print('RESULTS:')\n",
    "            print('MSE = {}, MAE = {}, R2 = {}'.format(mse,mae,r2))\n",
    "\n",
    "            names.append(modelName)\n",
    "            mse_final.append(mse)\n",
    "            mae_final.append(mae)\n",
    "            r2_final.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'Model': names,\n",
    "    'MSE': mse_final,\n",
    "    'MAE': mae_final,\n",
    "    'R2': r2_final\n",
    "})\n",
    "\n",
    "result_df.to_csv('output/results_NN_basic_architectures.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tanh-4-128</td>\n",
       "      <td>0.181480</td>\n",
       "      <td>0.310069</td>\n",
       "      <td>0.601654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tanh-2-128</td>\n",
       "      <td>0.182446</td>\n",
       "      <td>0.310460</td>\n",
       "      <td>0.599534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh-1-32</td>\n",
       "      <td>0.182522</td>\n",
       "      <td>0.309438</td>\n",
       "      <td>0.599366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh-1-512</td>\n",
       "      <td>0.182922</td>\n",
       "      <td>0.314254</td>\n",
       "      <td>0.598489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu-2-8</td>\n",
       "      <td>0.183030</td>\n",
       "      <td>0.312841</td>\n",
       "      <td>0.598251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tanh-2-512</td>\n",
       "      <td>0.184014</td>\n",
       "      <td>0.315050</td>\n",
       "      <td>0.596092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh-1-128</td>\n",
       "      <td>0.184298</td>\n",
       "      <td>0.310319</td>\n",
       "      <td>0.595468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu-1-32</td>\n",
       "      <td>0.185012</td>\n",
       "      <td>0.314980</td>\n",
       "      <td>0.593901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relu-6-32</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>0.317924</td>\n",
       "      <td>0.593715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu-1-8</td>\n",
       "      <td>0.185293</td>\n",
       "      <td>0.313316</td>\n",
       "      <td>0.593284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>relu-6-512</td>\n",
       "      <td>0.186283</td>\n",
       "      <td>0.313402</td>\n",
       "      <td>0.591111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu-1-128</td>\n",
       "      <td>0.186783</td>\n",
       "      <td>0.314995</td>\n",
       "      <td>0.590014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>relu-4-512</td>\n",
       "      <td>0.187695</td>\n",
       "      <td>0.313570</td>\n",
       "      <td>0.588012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tanh-4-512</td>\n",
       "      <td>0.187741</td>\n",
       "      <td>0.314745</td>\n",
       "      <td>0.587910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh-2-32</td>\n",
       "      <td>0.188614</td>\n",
       "      <td>0.317316</td>\n",
       "      <td>0.585996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>relu-2-128</td>\n",
       "      <td>0.188876</td>\n",
       "      <td>0.318086</td>\n",
       "      <td>0.585420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tanh-6-128</td>\n",
       "      <td>0.189228</td>\n",
       "      <td>0.325139</td>\n",
       "      <td>0.584647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tanh-6-512</td>\n",
       "      <td>0.189326</td>\n",
       "      <td>0.316130</td>\n",
       "      <td>0.584431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>relu-6-8</td>\n",
       "      <td>0.190529</td>\n",
       "      <td>0.315479</td>\n",
       "      <td>0.581791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>relu-4-32</td>\n",
       "      <td>0.192488</td>\n",
       "      <td>0.315862</td>\n",
       "      <td>0.577491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu-2-32</td>\n",
       "      <td>0.193258</td>\n",
       "      <td>0.320392</td>\n",
       "      <td>0.575802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>relu-4-128</td>\n",
       "      <td>0.194255</td>\n",
       "      <td>0.318423</td>\n",
       "      <td>0.573612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>relu-2-512</td>\n",
       "      <td>0.196265</td>\n",
       "      <td>0.324071</td>\n",
       "      <td>0.569200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relu-4-8</td>\n",
       "      <td>0.197940</td>\n",
       "      <td>0.324703</td>\n",
       "      <td>0.565525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu-1-512</td>\n",
       "      <td>0.202205</td>\n",
       "      <td>0.322361</td>\n",
       "      <td>0.556163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh-1-8</td>\n",
       "      <td>0.202693</td>\n",
       "      <td>0.327613</td>\n",
       "      <td>0.555092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>relu-6-128</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.329475</td>\n",
       "      <td>0.541129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tanh-6-32</td>\n",
       "      <td>0.456288</td>\n",
       "      <td>0.541791</td>\n",
       "      <td>-0.001545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tanh-6-8</td>\n",
       "      <td>0.456723</td>\n",
       "      <td>0.541668</td>\n",
       "      <td>-0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tanh-4-8</td>\n",
       "      <td>0.457138</td>\n",
       "      <td>0.541589</td>\n",
       "      <td>-0.003411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tanh-4-32</td>\n",
       "      <td>0.457968</td>\n",
       "      <td>0.541473</td>\n",
       "      <td>-0.005234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh-2-8</td>\n",
       "      <td>0.458938</td>\n",
       "      <td>0.541344</td>\n",
       "      <td>-0.007363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model       MSE       MAE        R2\n",
       "20  tanh-4-128  0.181480  0.310069  0.601654\n",
       "12  tanh-2-128  0.182446  0.310460  0.599534\n",
       "2    tanh-1-32  0.182522  0.309438  0.599366\n",
       "6   tanh-1-512  0.182922  0.314254  0.598489\n",
       "9     relu-2-8  0.183030  0.312841  0.598251\n",
       "14  tanh-2-512  0.184014  0.315050  0.596092\n",
       "4   tanh-1-128  0.184298  0.310319  0.595468\n",
       "3    relu-1-32  0.185012  0.314980  0.593901\n",
       "27   relu-6-32  0.185097  0.317924  0.593715\n",
       "1     relu-1-8  0.185293  0.313316  0.593284\n",
       "31  relu-6-512  0.186283  0.313402  0.591111\n",
       "5   relu-1-128  0.186783  0.314995  0.590014\n",
       "23  relu-4-512  0.187695  0.313570  0.588012\n",
       "22  tanh-4-512  0.187741  0.314745  0.587910\n",
       "10   tanh-2-32  0.188614  0.317316  0.585996\n",
       "13  relu-2-128  0.188876  0.318086  0.585420\n",
       "28  tanh-6-128  0.189228  0.325139  0.584647\n",
       "30  tanh-6-512  0.189326  0.316130  0.584431\n",
       "25    relu-6-8  0.190529  0.315479  0.581791\n",
       "19   relu-4-32  0.192488  0.315862  0.577491\n",
       "11   relu-2-32  0.193258  0.320392  0.575802\n",
       "21  relu-4-128  0.194255  0.318423  0.573612\n",
       "15  relu-2-512  0.196265  0.324071  0.569200\n",
       "17    relu-4-8  0.197940  0.324703  0.565525\n",
       "7   relu-1-512  0.202205  0.322361  0.556163\n",
       "0     tanh-1-8  0.202693  0.327613  0.555092\n",
       "29  relu-6-128  0.209054  0.329475  0.541129\n",
       "26   tanh-6-32  0.456288  0.541791 -0.001545\n",
       "24    tanh-6-8  0.456723  0.541668 -0.002501\n",
       "16    tanh-4-8  0.457138  0.541589 -0.003411\n",
       "18   tanh-4-32  0.457968  0.541473 -0.005234\n",
       "8     tanh-2-8  0.458938  0.541344 -0.007363"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['MSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 Basic Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1 = buildNN(X, num_hidden_layers = 4, \n",
    "               hidden_nodes = 128,\n",
    "               act = 'tanh')\n",
    "NN2 = buildNN(X, num_hidden_layers = 2, \n",
    "               hidden_nodes = 128,\n",
    "               act = 'tanh')\n",
    "NN3 = buildNN(X, num_hidden_layers = 1, \n",
    "               hidden_nodes = 32,\n",
    "               act = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Advanced Architectures: Dropout and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1_adv = buildNN_adv(X, num_hidden_layers = 4, \n",
    "               hidden_nodes = 128,\n",
    "               act = 'tanh')\n",
    "NN2_adv = buildNN_adv(X, num_hidden_layers = 2, \n",
    "               hidden_nodes = 128,\n",
    "               act = 'tanh')\n",
    "NN3_adv = buildNN_adv(X, num_hidden_layers = 1, \n",
    "               hidden_nodes = 32,\n",
    "               act = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compare the effects of dropout and l2 regularization on the best 3 neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1-TIME=1586773950\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 6s 177us/sample - loss: 0.9497 - mean_absolute_error: 0.9497 - mean_squared_error: 2.2444 - val_loss: 0.5386 - val_mean_absolute_error: 0.5386 - val_mean_squared_error: 0.4622\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 106us/sample - loss: 0.4836 - mean_absolute_error: 0.4836 - mean_squared_error: 0.3934 - val_loss: 0.3631 - val_mean_absolute_error: 0.3631 - val_mean_squared_error: 0.2528\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 94us/sample - loss: 0.3354 - mean_absolute_error: 0.3354 - mean_squared_error: 0.2153 - val_loss: 0.3326 - val_mean_absolute_error: 0.3326 - val_mean_squared_error: 0.2189\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 93us/sample - loss: 0.3249 - mean_absolute_error: 0.3249 - mean_squared_error: 0.2023 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.2003\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 99us/sample - loss: 0.3237 - mean_absolute_error: 0.3237 - mean_squared_error: 0.2008 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2154\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 4s 113us/sample - loss: 0.3203 - mean_absolute_error: 0.3203 - mean_squared_error: 0.1974 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.1948\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 3s 98us/sample - loss: 0.3182 - mean_absolute_error: 0.3182 - mean_squared_error: 0.1965 - val_loss: 0.3201 - val_mean_absolute_error: 0.3201 - val_mean_squared_error: 0.1983\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.3184 - mean_absolute_error: 0.3184 - mean_squared_error: 0.1959 - val_loss: 0.3176 - val_mean_absolute_error: 0.3176 - val_mean_squared_error: 0.1985\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3176 - mean_absolute_error: 0.3176 - mean_squared_error: 0.1952 - val_loss: 0.3188 - val_mean_absolute_error: 0.3188 - val_mean_squared_error: 0.1917\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3157 - mean_absolute_error: 0.3157 - mean_squared_error: 0.1937 - val_loss: 0.3161 - val_mean_absolute_error: 0.3161 - val_mean_squared_error: 0.1922\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.3173 - mean_absolute_error: 0.3173 - mean_squared_error: 0.1947 - val_loss: 0.3196 - val_mean_absolute_error: 0.3196 - val_mean_squared_error: 0.1989\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3145 - mean_absolute_error: 0.3145 - mean_squared_error: 0.1931 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198 - val_mean_squared_error: 0.1941\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.3146 - mean_absolute_error: 0.3146 - mean_squared_error: 0.1926 - val_loss: 0.3179 - val_mean_absolute_error: 0.3179 - val_mean_squared_error: 0.1923\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.3144 - mean_absolute_error: 0.3144 - mean_squared_error: 0.1925 - val_loss: 0.3143 - val_mean_absolute_error: 0.3143 - val_mean_squared_error: 0.1927\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.3135 - mean_absolute_error: 0.3135 - mean_squared_error: 0.1917 - val_loss: 0.3221 - val_mean_absolute_error: 0.3221 - val_mean_squared_error: 0.1923\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.3120 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1907 - val_loss: 0.3182 - val_mean_absolute_error: 0.3182 - val_mean_squared_error: 0.1965\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.3111 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1893 - val_loss: 0.3159 - val_mean_absolute_error: 0.3159 - val_mean_squared_error: 0.1968\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 60us/sample - loss: 0.3113 - mean_absolute_error: 0.3113 - mean_squared_error: 0.1900 - val_loss: 0.3143 - val_mean_absolute_error: 0.3143 - val_mean_squared_error: 0.1929\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3116 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1899 - val_loss: 0.3176 - val_mean_absolute_error: 0.3176 - val_mean_squared_error: 0.1922\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.3109 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1893 - val_loss: 0.3156 - val_mean_absolute_error: 0.3156 - val_mean_squared_error: 0.1957\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3107 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1893 - val_loss: 0.3141 - val_mean_absolute_error: 0.3141 - val_mean_squared_error: 0.1890\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.3099 - mean_absolute_error: 0.3099 - mean_squared_error: 0.1882 - val_loss: 0.3146 - val_mean_absolute_error: 0.3146 - val_mean_squared_error: 0.1921\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.3094 - mean_absolute_error: 0.3094 - mean_squared_error: 0.1885 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157 - val_mean_squared_error: 0.1942\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 63us/sample - loss: 0.3092 - mean_absolute_error: 0.3092 - mean_squared_error: 0.1876 - val_loss: 0.3126 - val_mean_absolute_error: 0.3126 - val_mean_squared_error: 0.1916\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.3080 - mean_absolute_error: 0.3080 - mean_squared_error: 0.1865 - val_loss: 0.3189 - val_mean_absolute_error: 0.3189 - val_mean_squared_error: 0.2005\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.3079 - mean_absolute_error: 0.3079 - mean_squared_error: 0.1863 - val_loss: 0.3149 - val_mean_absolute_error: 0.3149 - val_mean_squared_error: 0.1908\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3078 - mean_absolute_error: 0.3078 - mean_squared_error: 0.1865 - val_loss: 0.3141 - val_mean_absolute_error: 0.3141 - val_mean_squared_error: 0.1887\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3080 - mean_absolute_error: 0.3080 - mean_squared_error: 0.1867 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1883\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.3077 - mean_absolute_error: 0.3077 - mean_squared_error: 0.1862 - val_loss: 0.3159 - val_mean_absolute_error: 0.3159 - val_mean_squared_error: 0.1991\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3066 - mean_absolute_error: 0.3066 - mean_squared_error: 0.1855 - val_loss: 0.3186 - val_mean_absolute_error: 0.3186 - val_mean_squared_error: 0.2019\n",
      "RESULTS:\n",
      "MSE = 0.19260457558358632, MAE = 0.3162628533534541, R2 = 0.5772355825586251\n",
      "NN1_adv-TIME=1586774018\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 146us/sample - loss: 2.0161 - mean_absolute_error: 1.0654 - mean_squared_error: 2.6315 - val_loss: 0.8922 - val_mean_absolute_error: 0.5103 - val_mean_squared_error: 0.4341\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.7164 - mean_absolute_error: 0.4772 - mean_squared_error: 0.3923 - val_loss: 0.4909 - val_mean_absolute_error: 0.3416 - val_mean_squared_error: 0.2219\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 99us/sample - loss: 0.5564 - mean_absolute_error: 0.4400 - mean_squared_error: 0.3356 - val_loss: 0.4447 - val_mean_absolute_error: 0.3464 - val_mean_squared_error: 0.2166\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 96us/sample - loss: 0.5106 - mean_absolute_error: 0.4278 - mean_squared_error: 0.3195 - val_loss: 0.4133 - val_mean_absolute_error: 0.3404 - val_mean_squared_error: 0.2219\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 3s 95us/sample - loss: 0.4819 - mean_absolute_error: 0.4159 - mean_squared_error: 0.3079 - val_loss: 0.4303 - val_mean_absolute_error: 0.3715 - val_mean_squared_error: 0.2685\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.4675 - mean_absolute_error: 0.4111 - mean_squared_error: 0.2991 - val_loss: 0.3903 - val_mean_absolute_error: 0.3370 - val_mean_squared_error: 0.2168\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 3s 98us/sample - loss: 0.4520 - mean_absolute_error: 0.4026 - mean_squared_error: 0.2882 - val_loss: 0.3869 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.2279\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.4440 - mean_absolute_error: 0.3984 - mean_squared_error: 0.2831 - val_loss: 0.3816 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.2187\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.4392 - mean_absolute_error: 0.3960 - mean_squared_error: 0.2801 - val_loss: 0.3826 - val_mean_absolute_error: 0.3400 - val_mean_squared_error: 0.2254\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 3s 111us/sample - loss: 0.4352 - mean_absolute_error: 0.3931 - mean_squared_error: 0.2767 - val_loss: 0.3866 - val_mean_absolute_error: 0.3453 - val_mean_squared_error: 0.2357\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.4347 - mean_absolute_error: 0.3938 - mean_squared_error: 0.2806 - val_loss: 0.3909 - val_mean_absolute_error: 0.3505 - val_mean_squared_error: 0.2195\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.4269 - mean_absolute_error: 0.3866 - mean_squared_error: 0.2689 - val_loss: 0.3787 - val_mean_absolute_error: 0.3390 - val_mean_squared_error: 0.2263\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 98us/sample - loss: 0.4269 - mean_absolute_error: 0.3874 - mean_squared_error: 0.2710 - val_loss: 0.3773 - val_mean_absolute_error: 0.3376 - val_mean_squared_error: 0.2168\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 4s 134us/sample - loss: 0.4258 - mean_absolute_error: 0.3870 - mean_squared_error: 0.2709 - val_loss: 0.3830 - val_mean_absolute_error: 0.3453 - val_mean_squared_error: 0.2272\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 107us/sample - loss: 0.4234 - mean_absolute_error: 0.3849 - mean_squared_error: 0.2674 - val_loss: 0.3847 - val_mean_absolute_error: 0.3465 - val_mean_squared_error: 0.2362\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 4s 114us/sample - loss: 0.4248 - mean_absolute_error: 0.3865 - mean_squared_error: 0.2682 - val_loss: 0.3951 - val_mean_absolute_error: 0.3554 - val_mean_squared_error: 0.2181\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 3s 109us/sample - loss: 0.4211 - mean_absolute_error: 0.3835 - mean_squared_error: 0.2642 - val_loss: 0.3833 - val_mean_absolute_error: 0.3466 - val_mean_squared_error: 0.2322\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 3s 107us/sample - loss: 0.4202 - mean_absolute_error: 0.3829 - mean_squared_error: 0.2644 - val_loss: 0.3801 - val_mean_absolute_error: 0.3430 - val_mean_squared_error: 0.2302\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.4169 - mean_absolute_error: 0.3797 - mean_squared_error: 0.2621 - val_loss: 0.3821 - val_mean_absolute_error: 0.3439 - val_mean_squared_error: 0.2316\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.4165 - mean_absolute_error: 0.3796 - mean_squared_error: 0.2614 - val_loss: 0.3709 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2166\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 3s 98us/sample - loss: 0.4169 - mean_absolute_error: 0.3804 - mean_squared_error: 0.2628 - val_loss: 0.3725 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.2125\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 3s 101us/sample - loss: 0.4174 - mean_absolute_error: 0.3813 - mean_squared_error: 0.2630 - val_loss: 0.3697 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2154\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.4181 - mean_absolute_error: 0.3818 - mean_squared_error: 0.2630 - val_loss: 0.3828 - val_mean_absolute_error: 0.3448 - val_mean_squared_error: 0.2318\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 3s 111us/sample - loss: 0.4139 - mean_absolute_error: 0.3778 - mean_squared_error: 0.2587 - val_loss: 0.3735 - val_mean_absolute_error: 0.3357 - val_mean_squared_error: 0.2096\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.4134 - mean_absolute_error: 0.3777 - mean_squared_error: 0.2590 - val_loss: 0.3715 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.2171\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 4s 114us/sample - loss: 0.4130 - mean_absolute_error: 0.3773 - mean_squared_error: 0.2582 - val_loss: 0.3704 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.2141\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 3s 98us/sample - loss: 0.4107 - mean_absolute_error: 0.3754 - mean_squared_error: 0.2562 - val_loss: 0.3880 - val_mean_absolute_error: 0.3522 - val_mean_squared_error: 0.2159\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 3s 111us/sample - loss: 0.4137 - mean_absolute_error: 0.3787 - mean_squared_error: 0.2605 - val_loss: 0.3680 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2106\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 3s 108us/sample - loss: 0.4133 - mean_absolute_error: 0.3782 - mean_squared_error: 0.2615 - val_loss: 0.3713 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.2123\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 3s 99us/sample - loss: 0.4094 - mean_absolute_error: 0.3745 - mean_squared_error: 0.2560 - val_loss: 0.3679 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2165\n",
      "RESULTS:\n",
      "MSE = 0.20837192699587964, MAE = 0.3324996028482298, R2 = 0.5426264611802039\n",
      "NN2-TIME=1586774117\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 1.2722 - mean_absolute_error: 1.2722 - mean_squared_error: 3.4184 - val_loss: 0.5001 - val_mean_absolute_error: 0.5001 - val_mean_squared_error: 0.4169\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.3810 - mean_absolute_error: 0.3810 - mean_squared_error: 0.2722 - val_loss: 0.3333 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.2165\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.3286 - mean_absolute_error: 0.3286 - mean_squared_error: 0.2075 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_mean_squared_error: 0.1997\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3246 - mean_absolute_error: 0.3246 - mean_squared_error: 0.2027 - val_loss: 0.3256 - val_mean_absolute_error: 0.3256 - val_mean_squared_error: 0.2091\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 58us/sample - loss: 0.3213 - mean_absolute_error: 0.3213 - mean_squared_error: 0.1994 - val_loss: 0.3191 - val_mean_absolute_error: 0.3191 - val_mean_squared_error: 0.1990\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 60us/sample - loss: 0.3198 - mean_absolute_error: 0.3198 - mean_squared_error: 0.1977 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.1953\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.3193 - mean_absolute_error: 0.3193 - mean_squared_error: 0.1975 - val_loss: 0.3168 - val_mean_absolute_error: 0.3168 - val_mean_squared_error: 0.1970\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 60us/sample - loss: 0.3171 - mean_absolute_error: 0.3171 - mean_squared_error: 0.1947 - val_loss: 0.3163 - val_mean_absolute_error: 0.3163 - val_mean_squared_error: 0.1954\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3169 - mean_absolute_error: 0.3169 - mean_squared_error: 0.1946 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_mean_squared_error: 0.1919\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.3146 - mean_absolute_error: 0.3146 - mean_squared_error: 0.1928 - val_loss: 0.3197 - val_mean_absolute_error: 0.3197 - val_mean_squared_error: 0.1898\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3142 - mean_absolute_error: 0.3142 - mean_squared_error: 0.1922 - val_loss: 0.3170 - val_mean_absolute_error: 0.3170 - val_mean_squared_error: 0.1893\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.3141 - mean_absolute_error: 0.3141 - mean_squared_error: 0.1920 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1904\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3140 - mean_absolute_error: 0.3140 - mean_squared_error: 0.1920 - val_loss: 0.3146 - val_mean_absolute_error: 0.3146 - val_mean_squared_error: 0.1921\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.3128 - mean_absolute_error: 0.3128 - mean_squared_error: 0.1910 - val_loss: 0.3207 - val_mean_absolute_error: 0.3207 - val_mean_squared_error: 0.2037\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.3145 - mean_absolute_error: 0.3145 - mean_squared_error: 0.1925 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_mean_squared_error: 0.1962\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.3121 - mean_absolute_error: 0.3121 - mean_squared_error: 0.1905 - val_loss: 0.3179 - val_mean_absolute_error: 0.3179 - val_mean_squared_error: 0.1895\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.3108 - mean_absolute_error: 0.3108 - mean_squared_error: 0.1891 - val_loss: 0.3156 - val_mean_absolute_error: 0.3156 - val_mean_squared_error: 0.1898\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3110 - mean_absolute_error: 0.3110 - mean_squared_error: 0.1889 - val_loss: 0.3132 - val_mean_absolute_error: 0.3132 - val_mean_squared_error: 0.1896\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.3110 - mean_absolute_error: 0.3110 - mean_squared_error: 0.1896 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157 - val_mean_squared_error: 0.1933\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3103 - mean_absolute_error: 0.3103 - mean_squared_error: 0.1893 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1889\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3100 - mean_absolute_error: 0.3100 - mean_squared_error: 0.1882 - val_loss: 0.3142 - val_mean_absolute_error: 0.3142 - val_mean_squared_error: 0.1960\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.3094 - mean_absolute_error: 0.3094 - mean_squared_error: 0.1881 - val_loss: 0.3169 - val_mean_absolute_error: 0.3169 - val_mean_squared_error: 0.1891\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.3084 - mean_absolute_error: 0.3084 - mean_squared_error: 0.1875 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_mean_squared_error: 0.1978\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3079 - mean_absolute_error: 0.3079 - mean_squared_error: 0.1871 - val_loss: 0.3168 - val_mean_absolute_error: 0.3168 - val_mean_squared_error: 0.1876\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3077 - mean_absolute_error: 0.3077 - mean_squared_error: 0.1862 - val_loss: 0.3144 - val_mean_absolute_error: 0.3144 - val_mean_squared_error: 0.1947\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3072 - mean_absolute_error: 0.3072 - mean_squared_error: 0.1859 - val_loss: 0.3140 - val_mean_absolute_error: 0.3140 - val_mean_squared_error: 0.1885\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.3063 - mean_absolute_error: 0.3063 - mean_squared_error: 0.1855 - val_loss: 0.3140 - val_mean_absolute_error: 0.3140 - val_mean_squared_error: 0.1941\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.3078 - mean_absolute_error: 0.3078 - mean_squared_error: 0.1861 - val_loss: 0.3127 - val_mean_absolute_error: 0.3127 - val_mean_squared_error: 0.1901\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.3060 - mean_absolute_error: 0.3060 - mean_squared_error: 0.1851 - val_loss: 0.3131 - val_mean_absolute_error: 0.3131 - val_mean_squared_error: 0.1914\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.3068 - mean_absolute_error: 0.3068 - mean_squared_error: 0.1853 - val_loss: 0.3135 - val_mean_absolute_error: 0.3135 - val_mean_squared_error: 0.1882\n",
      "RESULTS:\n",
      "MSE = 0.18112915257794046, MAE = 0.31085316332978036, R2 = 0.6024239796004691\n",
      "NN2_adv-TIME=1586774163\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 3s 86us/sample - loss: 1.9499 - mean_absolute_error: 1.3565 - mean_squared_error: 3.6395 - val_loss: 0.8418 - val_mean_absolute_error: 0.5249 - val_mean_squared_error: 0.4614\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.6936 - mean_absolute_error: 0.4779 - mean_squared_error: 0.3960 - val_loss: 0.4824 - val_mean_absolute_error: 0.3442 - val_mean_squared_error: 0.2291\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.5332 - mean_absolute_error: 0.4292 - mean_squared_error: 0.3245 - val_loss: 0.4336 - val_mean_absolute_error: 0.3562 - val_mean_squared_error: 0.2481\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.4731 - mean_absolute_error: 0.4096 - mean_squared_error: 0.3006 - val_loss: 0.3996 - val_mean_absolute_error: 0.3488 - val_mean_squared_error: 0.2402\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4456 - mean_absolute_error: 0.4018 - mean_squared_error: 0.2903 - val_loss: 0.3839 - val_mean_absolute_error: 0.3446 - val_mean_squared_error: 0.2127\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.4239 - mean_absolute_error: 0.3913 - mean_squared_error: 0.2773 - val_loss: 0.3608 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2103\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.4181 - mean_absolute_error: 0.3915 - mean_squared_error: 0.2764 - val_loss: 0.3546 - val_mean_absolute_error: 0.3302 - val_mean_squared_error: 0.2122\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4097 - mean_absolute_error: 0.3867 - mean_squared_error: 0.2687 - val_loss: 0.3677 - val_mean_absolute_error: 0.3458 - val_mean_squared_error: 0.2297\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4052 - mean_absolute_error: 0.3844 - mean_squared_error: 0.2670 - val_loss: 0.3678 - val_mean_absolute_error: 0.3475 - val_mean_squared_error: 0.2336\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4064 - mean_absolute_error: 0.3864 - mean_squared_error: 0.2700 - val_loss: 0.3537 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.2178\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.3997 - mean_absolute_error: 0.3806 - mean_squared_error: 0.2631 - val_loss: 0.3546 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.2205\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.4022 - mean_absolute_error: 0.3836 - mean_squared_error: 0.2654 - val_loss: 0.3548 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.2190\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.3989 - mean_absolute_error: 0.3804 - mean_squared_error: 0.2615 - val_loss: 0.3544 - val_mean_absolute_error: 0.3366 - val_mean_squared_error: 0.2205\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3964 - mean_absolute_error: 0.3783 - mean_squared_error: 0.2606 - val_loss: 0.3583 - val_mean_absolute_error: 0.3404 - val_mean_squared_error: 0.2180\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.3996 - mean_absolute_error: 0.3812 - mean_squared_error: 0.2648 - val_loss: 0.3592 - val_mean_absolute_error: 0.3412 - val_mean_squared_error: 0.2221\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.3983 - mean_absolute_error: 0.3801 - mean_squared_error: 0.2617 - val_loss: 0.3499 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.2134\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.3950 - mean_absolute_error: 0.3773 - mean_squared_error: 0.2581 - val_loss: 0.3568 - val_mean_absolute_error: 0.3392 - val_mean_squared_error: 0.2154\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.3955 - mean_absolute_error: 0.3778 - mean_squared_error: 0.2597 - val_loss: 0.3496 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.2115\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.3959 - mean_absolute_error: 0.3786 - mean_squared_error: 0.2613 - val_loss: 0.3568 - val_mean_absolute_error: 0.3388 - val_mean_squared_error: 0.2152\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.3932 - mean_absolute_error: 0.3758 - mean_squared_error: 0.2581 - val_loss: 0.3554 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.2134\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.3938 - mean_absolute_error: 0.3768 - mean_squared_error: 0.2581 - val_loss: 0.3553 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.2231\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.3974 - mean_absolute_error: 0.3799 - mean_squared_error: 0.2655 - val_loss: 0.3490 - val_mean_absolute_error: 0.3314 - val_mean_squared_error: 0.2084\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 58us/sample - loss: 0.3899 - mean_absolute_error: 0.3730 - mean_squared_error: 0.2551 - val_loss: 0.3480 - val_mean_absolute_error: 0.3315 - val_mean_squared_error: 0.2114\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.3919 - mean_absolute_error: 0.3751 - mean_squared_error: 0.2571 - val_loss: 0.3496 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.2168\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.3927 - mean_absolute_error: 0.3762 - mean_squared_error: 0.2563 - val_loss: 0.3562 - val_mean_absolute_error: 0.3383 - val_mean_squared_error: 0.2129\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.3924 - mean_absolute_error: 0.3752 - mean_squared_error: 0.2565 - val_loss: 0.3531 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.2200\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.3904 - mean_absolute_error: 0.3738 - mean_squared_error: 0.2552 - val_loss: 0.3495 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.2058\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 58us/sample - loss: 0.3880 - mean_absolute_error: 0.3717 - mean_squared_error: 0.2528 - val_loss: 0.3483 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.2105\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3866 - mean_absolute_error: 0.3702 - mean_squared_error: 0.2511 - val_loss: 0.3490 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2153\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.3879 - mean_absolute_error: 0.3713 - mean_squared_error: 0.2522 - val_loss: 0.3514 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.2068\n",
      "RESULTS:\n",
      "MSE = 0.20070513411848306, MAE = 0.33248236251305063, R2 = 0.5594549670172816\n",
      "NN3-TIME=1586774225\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 3.0588 - mean_absolute_error: 3.0588 - mean_squared_error: 11.7157 - val_loss: 1.0814 - val_mean_absolute_error: 1.0814 - val_mean_squared_error: 1.9050\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.8952 - mean_absolute_error: 0.8952 - mean_squared_error: 1.2803 - val_loss: 0.7648 - val_mean_absolute_error: 0.7648 - val_mean_squared_error: 0.9312\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.6870 - mean_absolute_error: 0.6870 - mean_squared_error: 0.7630 - val_loss: 0.5984 - val_mean_absolute_error: 0.5984 - val_mean_squared_error: 0.5873\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.5175 - mean_absolute_error: 0.5175 - mean_squared_error: 0.4605 - val_loss: 0.4348 - val_mean_absolute_error: 0.4348 - val_mean_squared_error: 0.3397\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 22us/sample - loss: 0.3929 - mean_absolute_error: 0.3929 - mean_squared_error: 0.2857 - val_loss: 0.3603 - val_mean_absolute_error: 0.3603 - val_mean_squared_error: 0.2462\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.3474 - mean_absolute_error: 0.3474 - mean_squared_error: 0.2296 - val_loss: 0.3371 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.2152\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.3329 - mean_absolute_error: 0.3329 - mean_squared_error: 0.2133 - val_loss: 0.3284 - val_mean_absolute_error: 0.3284 - val_mean_squared_error: 0.2115\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.3275 - mean_absolute_error: 0.3275 - mean_squared_error: 0.2065 - val_loss: 0.3250 - val_mean_absolute_error: 0.3250 - val_mean_squared_error: 0.2048\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.3247 - mean_absolute_error: 0.3247 - mean_squared_error: 0.2035 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_mean_squared_error: 0.2044\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.3222 - mean_absolute_error: 0.3222 - mean_squared_error: 0.2006 - val_loss: 0.3223 - val_mean_absolute_error: 0.3223 - val_mean_squared_error: 0.2038\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.3204 - mean_absolute_error: 0.3204 - mean_squared_error: 0.1990 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.1966\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.3185 - mean_absolute_error: 0.3185 - mean_squared_error: 0.1971 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205 - val_mean_squared_error: 0.2003\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.3178 - mean_absolute_error: 0.3178 - mean_squared_error: 0.1963 - val_loss: 0.3189 - val_mean_absolute_error: 0.3189 - val_mean_squared_error: 0.1984\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.3162 - mean_absolute_error: 0.3162 - mean_squared_error: 0.1950 - val_loss: 0.3176 - val_mean_absolute_error: 0.3176 - val_mean_squared_error: 0.1959\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.3156 - mean_absolute_error: 0.3156 - mean_squared_error: 0.1942 - val_loss: 0.3190 - val_mean_absolute_error: 0.3190 - val_mean_squared_error: 0.1956\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.3147 - mean_absolute_error: 0.3147 - mean_squared_error: 0.1933 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_mean_squared_error: 0.1952\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.3141 - mean_absolute_error: 0.3141 - mean_squared_error: 0.1930 - val_loss: 0.3172 - val_mean_absolute_error: 0.3172 - val_mean_squared_error: 0.1951\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.3134 - mean_absolute_error: 0.3134 - mean_squared_error: 0.1922 - val_loss: 0.3160 - val_mean_absolute_error: 0.3160 - val_mean_squared_error: 0.1931\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.3127 - mean_absolute_error: 0.3127 - mean_squared_error: 0.1914 - val_loss: 0.3160 - val_mean_absolute_error: 0.3160 - val_mean_squared_error: 0.1927\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.3121 - mean_absolute_error: 0.3121 - mean_squared_error: 0.1909 - val_loss: 0.3166 - val_mean_absolute_error: 0.3166 - val_mean_squared_error: 0.1927\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.3120 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1907 - val_loss: 0.3159 - val_mean_absolute_error: 0.3159 - val_mean_squared_error: 0.1913\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.3111 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1900 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157 - val_mean_squared_error: 0.1917\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.3102 - mean_absolute_error: 0.3102 - mean_squared_error: 0.1894 - val_loss: 0.3150 - val_mean_absolute_error: 0.3150 - val_mean_squared_error: 0.1940\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.3101 - mean_absolute_error: 0.3101 - mean_squared_error: 0.1887 - val_loss: 0.3149 - val_mean_absolute_error: 0.3149 - val_mean_squared_error: 0.1951\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.3096 - mean_absolute_error: 0.3096 - mean_squared_error: 0.1887 - val_loss: 0.3147 - val_mean_absolute_error: 0.3147 - val_mean_squared_error: 0.1930\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.3096 - mean_absolute_error: 0.3096 - mean_squared_error: 0.1885 - val_loss: 0.3153 - val_mean_absolute_error: 0.3153 - val_mean_squared_error: 0.1960\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.3092 - mean_absolute_error: 0.3092 - mean_squared_error: 0.1881 - val_loss: 0.3158 - val_mean_absolute_error: 0.3158 - val_mean_squared_error: 0.1892\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.3085 - mean_absolute_error: 0.3085 - mean_squared_error: 0.1876 - val_loss: 0.3141 - val_mean_absolute_error: 0.3141 - val_mean_squared_error: 0.1912\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.3081 - mean_absolute_error: 0.3081 - mean_squared_error: 0.1875 - val_loss: 0.3150 - val_mean_absolute_error: 0.3150 - val_mean_squared_error: 0.1902\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.3083 - mean_absolute_error: 0.3083 - mean_squared_error: 0.1872 - val_loss: 0.3137 - val_mean_absolute_error: 0.3137 - val_mean_squared_error: 0.1926\n",
      "RESULTS:\n",
      "MSE = 0.1844786588446908, MAE = 0.3106689152576532, R2 = 0.5950718590120129\n",
      "NN3_adv-TIME=1586774258\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 3.2327 - mean_absolute_error: 3.1290 - mean_squared_error: 12.0922 - val_loss: 1.3009 - val_mean_absolute_error: 1.1632 - val_mean_squared_error: 2.2016\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 1.1802 - mean_absolute_error: 1.0499 - mean_squared_error: 1.7403 - val_loss: 0.9932 - val_mean_absolute_error: 0.8698 - val_mean_squared_error: 1.2034\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.9701 - mean_absolute_error: 0.8536 - mean_squared_error: 1.1648 - val_loss: 0.7925 - val_mean_absolute_error: 0.6820 - val_mean_squared_error: 0.7642\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.7906 - mean_absolute_error: 0.6859 - mean_squared_error: 0.7706 - val_loss: 0.5968 - val_mean_absolute_error: 0.4993 - val_mean_squared_error: 0.4421\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.6579 - mean_absolute_error: 0.5681 - mean_squared_error: 0.5389 - val_loss: 0.4760 - val_mean_absolute_error: 0.3966 - val_mean_squared_error: 0.2955\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.5846 - mean_absolute_error: 0.5144 - mean_squared_error: 0.4495 - val_loss: 0.4150 - val_mean_absolute_error: 0.3552 - val_mean_squared_error: 0.2402\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.5357 - mean_absolute_error: 0.4847 - mean_squared_error: 0.4036 - val_loss: 0.3854 - val_mean_absolute_error: 0.3424 - val_mean_squared_error: 0.2240\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5149 - mean_absolute_error: 0.4785 - mean_squared_error: 0.3925 - val_loss: 0.3673 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.2214\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.4978 - mean_absolute_error: 0.4712 - mean_squared_error: 0.3800 - val_loss: 0.3569 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.2124\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.4878 - mean_absolute_error: 0.4680 - mean_squared_error: 0.3757 - val_loss: 0.3485 - val_mean_absolute_error: 0.3311 - val_mean_squared_error: 0.2104\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 22us/sample - loss: 0.4813 - mean_absolute_error: 0.4659 - mean_squared_error: 0.3736 - val_loss: 0.3558 - val_mean_absolute_error: 0.3416 - val_mean_squared_error: 0.2219\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.4744 - mean_absolute_error: 0.4615 - mean_squared_error: 0.3669 - val_loss: 0.3433 - val_mean_absolute_error: 0.3312 - val_mean_squared_error: 0.2107\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.4736 - mean_absolute_error: 0.4622 - mean_squared_error: 0.3692 - val_loss: 0.3491 - val_mean_absolute_error: 0.3385 - val_mean_squared_error: 0.2137\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.4722 - mean_absolute_error: 0.4618 - mean_squared_error: 0.3662 - val_loss: 0.3391 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.2094\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.4631 - mean_absolute_error: 0.4537 - mean_squared_error: 0.3541 - val_loss: 0.3415 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2093\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4639 - mean_absolute_error: 0.4551 - mean_squared_error: 0.3583 - val_loss: 0.3431 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.2155\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4623 - mean_absolute_error: 0.4537 - mean_squared_error: 0.3543 - val_loss: 0.3384 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2099\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.4616 - mean_absolute_error: 0.4527 - mean_squared_error: 0.3538 - val_loss: 0.3417 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2171\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4595 - mean_absolute_error: 0.4512 - mean_squared_error: 0.3520 - val_loss: 0.3394 - val_mean_absolute_error: 0.3309 - val_mean_squared_error: 0.2096\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.4532 - mean_absolute_error: 0.4450 - mean_squared_error: 0.3450 - val_loss: 0.3459 - val_mean_absolute_error: 0.3378 - val_mean_squared_error: 0.2126\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.4564 - mean_absolute_error: 0.4479 - mean_squared_error: 0.3467 - val_loss: 0.3411 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.2083\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.4529 - mean_absolute_error: 0.4446 - mean_squared_error: 0.3448 - val_loss: 0.3389 - val_mean_absolute_error: 0.3309 - val_mean_squared_error: 0.2123\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.4501 - mean_absolute_error: 0.4419 - mean_squared_error: 0.3408 - val_loss: 0.3387 - val_mean_absolute_error: 0.3307 - val_mean_squared_error: 0.2125\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.4475 - mean_absolute_error: 0.4394 - mean_squared_error: 0.3341 - val_loss: 0.3368 - val_mean_absolute_error: 0.3296 - val_mean_squared_error: 0.2107\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.4453 - mean_absolute_error: 0.4373 - mean_squared_error: 0.3342 - val_loss: 0.3400 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2110\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.4436 - mean_absolute_error: 0.4354 - mean_squared_error: 0.3320 - val_loss: 0.3451 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.2144\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.4435 - mean_absolute_error: 0.4352 - mean_squared_error: 0.3293 - val_loss: 0.3443 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.2221\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.4383 - mean_absolute_error: 0.4299 - mean_squared_error: 0.3246 - val_loss: 0.3393 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2112\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.4351 - mean_absolute_error: 0.4266 - mean_squared_error: 0.3214 - val_loss: 0.3408 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.2064\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.4335 - mean_absolute_error: 0.4251 - mean_squared_error: 0.3158 - val_loss: 0.3381 - val_mean_absolute_error: 0.3298 - val_mean_squared_error: 0.2136\n",
      "RESULTS:\n",
      "MSE = 0.2051648487192946, MAE = 0.3286172350264903, R2 = 0.5496659542721059\n"
     ]
    }
   ],
   "source": [
    "models = [NN1, NN1_adv, NN2, NN2_adv, NN3, NN3_adv]\n",
    "modelNames = ['NN1', 'NN1_adv', 'NN2', 'NN2_adv', 'NN3', 'NN3_adv']\n",
    "\n",
    "i = 0\n",
    "mse_final = []\n",
    "mae_final = []\n",
    "r2_final = []\n",
    "\n",
    "for model in models:\n",
    "    LOGNAME = \"{}-TIME={}\".format( modelNames[i] , int(time.time()) )\n",
    "    print(LOGNAME)\n",
    "    tensorboard = TensorBoard(log_dir='logs/NN/l2+dropout/{}'.format(LOGNAME))\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "                         callbacks = [tensorboard],\n",
    "                validation_split = 0.2)\n",
    "\n",
    "    mse, r2, mae = evaluateModel(model, X_test, y_test)\n",
    "\n",
    "    print('RESULTS:')\n",
    "    print('MSE = {}, MAE = {}, R2 = {}'.format(mse,mae,r2))\n",
    "\n",
    "    mse_final.append(mse)\n",
    "    mae_final.append(mae)\n",
    "    r2_final.append(r2)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df2 = pd.DataFrame({\n",
    "    'Model': modelNames,\n",
    "    'MSE': mse_final,\n",
    "    'MAE': mae_final,\n",
    "    'R2': r2_final\n",
    "})\n",
    "\n",
    "result_df2.to_csv('output/results_NN_l2dropout.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN1</td>\n",
       "      <td>0.192605</td>\n",
       "      <td>0.316263</td>\n",
       "      <td>0.577236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN1_adv</td>\n",
       "      <td>0.208372</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.542626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN2</td>\n",
       "      <td>0.181129</td>\n",
       "      <td>0.310853</td>\n",
       "      <td>0.602424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN2_adv</td>\n",
       "      <td>0.200705</td>\n",
       "      <td>0.332482</td>\n",
       "      <td>0.559455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN3</td>\n",
       "      <td>0.184479</td>\n",
       "      <td>0.310669</td>\n",
       "      <td>0.595072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN3_adv</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.328617</td>\n",
       "      <td>0.549666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model       MSE       MAE        R2\n",
       "0      NN1  0.192605  0.316263  0.577236\n",
       "1  NN1_adv  0.208372  0.332500  0.542626\n",
       "2      NN2  0.181129  0.310853  0.602424\n",
       "3  NN2_adv  0.200705  0.332482  0.559455\n",
       "4      NN3  0.184479  0.310669  0.595072\n",
       "5  NN3_adv  0.205165  0.328617  0.549666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like adding both l2 regularization and dropout lowered the performance of the neural networks. So now we will test 1 network with each on their own. It is also worth noting that the performance of the the same neural networks changed slightly, and NN1 is no longer the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1_do = buildNN_adv(X, num_hidden_layers = 4, \n",
    "               hidden_nodes = 128,\n",
    "                regularizer=False,\n",
    "               act = 'tanh')\n",
    "NN1_l2 = buildNN_adv(X, num_hidden_layers = 4, \n",
    "               hidden_nodes = 128,\n",
    "                     do = 0,\n",
    "               act = 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 1.0218 - mean_absolute_error: 1.0218 - mean_squared_error: 2.4459 - val_loss: 0.5248 - val_mean_absolute_error: 0.5248 - val_mean_squared_error: 0.4379\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 6s 208us/sample - loss: 0.4675 - mean_absolute_error: 0.4675 - mean_squared_error: 0.3759 - val_loss: 0.3379 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.2147\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 5s 160us/sample - loss: 0.4055 - mean_absolute_error: 0.4055 - mean_squared_error: 0.2888 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2063\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 6s 197us/sample - loss: 0.3938 - mean_absolute_error: 0.3938 - mean_squared_error: 0.2744 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2097\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 106us/sample - loss: 0.3879 - mean_absolute_error: 0.3879 - mean_squared_error: 0.2686 - val_loss: 0.3305 - val_mean_absolute_error: 0.3305 - val_mean_squared_error: 0.2061\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 7s 209us/sample - loss: 0.3834 - mean_absolute_error: 0.3834 - mean_squared_error: 0.2624 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260 - val_mean_squared_error: 0.2023\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 5s 153us/sample - loss: 0.3817 - mean_absolute_error: 0.3817 - mean_squared_error: 0.2615 - val_loss: 0.3230 - val_mean_absolute_error: 0.3230 - val_mean_squared_error: 0.1969\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 4s 141us/sample - loss: 0.3775 - mean_absolute_error: 0.3775 - mean_squared_error: 0.2571 - val_loss: 0.3209 - val_mean_absolute_error: 0.3209 - val_mean_squared_error: 0.1971\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 4s 133us/sample - loss: 0.3772 - mean_absolute_error: 0.3772 - mean_squared_error: 0.2563 - val_loss: 0.3210 - val_mean_absolute_error: 0.3210 - val_mean_squared_error: 0.1996\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 5s 171us/sample - loss: 0.3794 - mean_absolute_error: 0.3794 - mean_squared_error: 0.2582 - val_loss: 0.3336 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.1990\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3794 - mean_absolute_error: 0.3794 - mean_squared_error: 0.2579 - val_loss: 0.3330 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1982\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 60us/sample - loss: 0.3762 - mean_absolute_error: 0.3762 - mean_squared_error: 0.2550 - val_loss: 0.3203 - val_mean_absolute_error: 0.3203 - val_mean_squared_error: 0.1974\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 4s 117us/sample - loss: 0.3748 - mean_absolute_error: 0.3748 - mean_squared_error: 0.2529 - val_loss: 0.3201 - val_mean_absolute_error: 0.3201 - val_mean_squared_error: 0.1993\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 7s 209us/sample - loss: 0.3733 - mean_absolute_error: 0.3733 - mean_squared_error: 0.2508 - val_loss: 0.3294 - val_mean_absolute_error: 0.3294 - val_mean_squared_error: 0.1978\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 5s 176us/sample - loss: 0.3736 - mean_absolute_error: 0.3736 - mean_squared_error: 0.2517 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198 - val_mean_squared_error: 0.1973\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 5s 157us/sample - loss: 0.3713 - mean_absolute_error: 0.3713 - mean_squared_error: 0.2495 - val_loss: 0.3197 - val_mean_absolute_error: 0.3197 - val_mean_squared_error: 0.2014\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 4s 141us/sample - loss: 0.3743 - mean_absolute_error: 0.3743 - mean_squared_error: 0.2520 - val_loss: 0.3306 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.1966\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.3701 - mean_absolute_error: 0.3701 - mean_squared_error: 0.2477 - val_loss: 0.3296 - val_mean_absolute_error: 0.3296 - val_mean_squared_error: 0.1977\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3702 - mean_absolute_error: 0.3702 - mean_squared_error: 0.2483 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205 - val_mean_squared_error: 0.1952\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3715 - mean_absolute_error: 0.3715 - mean_squared_error: 0.2488 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205 - val_mean_squared_error: 0.1949\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.3693 - mean_absolute_error: 0.3693 - mean_squared_error: 0.2483 - val_loss: 0.3310 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.1979\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 7s 214us/sample - loss: 0.3685 - mean_absolute_error: 0.3685 - mean_squared_error: 0.2457 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198 - val_mean_squared_error: 0.1985\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 7s 215us/sample - loss: 0.3673 - mean_absolute_error: 0.3673 - mean_squared_error: 0.2453 - val_loss: 0.3218 - val_mean_absolute_error: 0.3218 - val_mean_squared_error: 0.2014\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 4s 136us/sample - loss: 0.3680 - mean_absolute_error: 0.3680 - mean_squared_error: 0.2454 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_mean_squared_error: 0.2009\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 5s 170us/sample - loss: 0.3686 - mean_absolute_error: 0.3686 - mean_squared_error: 0.2463 - val_loss: 0.3207 - val_mean_absolute_error: 0.3207 - val_mean_squared_error: 0.1923\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 7s 209us/sample - loss: 0.3679 - mean_absolute_error: 0.3679 - mean_squared_error: 0.2444 - val_loss: 0.3197 - val_mean_absolute_error: 0.3197 - val_mean_squared_error: 0.1939\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 4s 123us/sample - loss: 0.3659 - mean_absolute_error: 0.3659 - mean_squared_error: 0.2421 - val_loss: 0.3216 - val_mean_absolute_error: 0.3216 - val_mean_squared_error: 0.1943\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 5s 155us/sample - loss: 0.3667 - mean_absolute_error: 0.3667 - mean_squared_error: 0.2434 - val_loss: 0.3207 - val_mean_absolute_error: 0.3207 - val_mean_squared_error: 0.1940\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 5s 150us/sample - loss: 0.3634 - mean_absolute_error: 0.3634 - mean_squared_error: 0.2396 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200 - val_mean_squared_error: 0.1944\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 5s 163us/sample - loss: 0.3652 - mean_absolute_error: 0.3652 - mean_squared_error: 0.2412 - val_loss: 0.3195 - val_mean_absolute_error: 0.3195 - val_mean_squared_error: 0.1944\n",
      "RESULTS:\n",
      "MSE = 0.18845448716784619, MAE = 0.3180876454741099, R2 = 0.5863449700490024\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 9s 276us/sample - loss: 1.9553 - mean_absolute_error: 1.0145 - mean_squared_error: 2.5036 - val_loss: 0.8815 - val_mean_absolute_error: 0.5095 - val_mean_squared_error: 0.4357\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 4s 141us/sample - loss: 0.6031 - mean_absolute_error: 0.3753 - mean_squared_error: 0.2650 - val_loss: 0.4802 - val_mean_absolute_error: 0.3380 - val_mean_squared_error: 0.2227\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 128us/sample - loss: 0.4530 - mean_absolute_error: 0.3383 - mean_squared_error: 0.2204 - val_loss: 0.4296 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.2175\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 106us/sample - loss: 0.4221 - mean_absolute_error: 0.3381 - mean_squared_error: 0.2184 - val_loss: 0.4181 - val_mean_absolute_error: 0.3417 - val_mean_squared_error: 0.2101\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 3s 96us/sample - loss: 0.4096 - mean_absolute_error: 0.3399 - mean_squared_error: 0.2201 - val_loss: 0.4127 - val_mean_absolute_error: 0.3489 - val_mean_squared_error: 0.2431\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.4019 - mean_absolute_error: 0.3403 - mean_squared_error: 0.2200 - val_loss: 0.4591 - val_mean_absolute_error: 0.4033 - val_mean_squared_error: 0.3061\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.3926 - mean_absolute_error: 0.3363 - mean_squared_error: 0.2165 - val_loss: 0.3832 - val_mean_absolute_error: 0.3294 - val_mean_squared_error: 0.2101\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3887 - mean_absolute_error: 0.3367 - mean_squared_error: 0.2160 - val_loss: 0.3848 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.2174\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3850 - mean_absolute_error: 0.3360 - mean_squared_error: 0.2162 - val_loss: 0.3899 - val_mean_absolute_error: 0.3414 - val_mean_squared_error: 0.2085\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3846 - mean_absolute_error: 0.3377 - mean_squared_error: 0.2167 - val_loss: 0.3784 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.2100\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.3804 - mean_absolute_error: 0.3352 - mean_squared_error: 0.2162 - val_loss: 0.3850 - val_mean_absolute_error: 0.3418 - val_mean_squared_error: 0.2310\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3788 - mean_absolute_error: 0.3352 - mean_squared_error: 0.2152 - val_loss: 0.3740 - val_mean_absolute_error: 0.3305 - val_mean_squared_error: 0.2137\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3776 - mean_absolute_error: 0.3348 - mean_squared_error: 0.2141 - val_loss: 0.3772 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.2235\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.3753 - mean_absolute_error: 0.3339 - mean_squared_error: 0.2134 - val_loss: 0.3939 - val_mean_absolute_error: 0.3535 - val_mean_squared_error: 0.2476\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.3782 - mean_absolute_error: 0.3374 - mean_squared_error: 0.2168 - val_loss: 0.3717 - val_mean_absolute_error: 0.3312 - val_mean_squared_error: 0.2121\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 63us/sample - loss: 0.3747 - mean_absolute_error: 0.3343 - mean_squared_error: 0.2139 - val_loss: 0.3739 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.2045\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3771 - mean_absolute_error: 0.3377 - mean_squared_error: 0.2168 - val_loss: 0.3733 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.2110\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.3739 - mean_absolute_error: 0.3349 - mean_squared_error: 0.2144 - val_loss: 0.3695 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.2087\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.3696 - mean_absolute_error: 0.3312 - mean_squared_error: 0.2107 - val_loss: 0.3683 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2091\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.3743 - mean_absolute_error: 0.3360 - mean_squared_error: 0.2153 - val_loss: 0.3713 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2160\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.3719 - mean_absolute_error: 0.3339 - mean_squared_error: 0.2131 - val_loss: 0.3739 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.2242\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.3721 - mean_absolute_error: 0.3346 - mean_squared_error: 0.2142 - val_loss: 0.3834 - val_mean_absolute_error: 0.3466 - val_mean_squared_error: 0.2384\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.3710 - mean_absolute_error: 0.3339 - mean_squared_error: 0.2129 - val_loss: 0.3713 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.2170\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.3709 - mean_absolute_error: 0.3339 - mean_squared_error: 0.2132 - val_loss: 0.3690 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.2163\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.3686 - mean_absolute_error: 0.3320 - mean_squared_error: 0.2111 - val_loss: 0.3734 - val_mean_absolute_error: 0.3376 - val_mean_squared_error: 0.2063\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 79us/sample - loss: 0.3696 - mean_absolute_error: 0.3334 - mean_squared_error: 0.2124 - val_loss: 0.3650 - val_mean_absolute_error: 0.3289 - val_mean_squared_error: 0.2091\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3666 - mean_absolute_error: 0.3308 - mean_squared_error: 0.2106 - val_loss: 0.3635 - val_mean_absolute_error: 0.3279 - val_mean_squared_error: 0.2074\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.3679 - mean_absolute_error: 0.3323 - mean_squared_error: 0.2110 - val_loss: 0.3647 - val_mean_absolute_error: 0.3298 - val_mean_squared_error: 0.2097\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.3678 - mean_absolute_error: 0.3322 - mean_squared_error: 0.2111 - val_loss: 0.3644 - val_mean_absolute_error: 0.3292 - val_mean_squared_error: 0.2098\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3644 - mean_absolute_error: 0.3295 - mean_squared_error: 0.2088 - val_loss: 0.3645 - val_mean_absolute_error: 0.3307 - val_mean_squared_error: 0.2102\n",
      "RESULTS:\n",
      "MSE = 0.20368741874053162, MAE = 0.3292267543637823, R2 = 0.5529088929322576\n",
      "--------- RESULTS -------\n",
      "Dropout Only: MSE = 0.18845448716784619, MAE = 0.3180876454741099, R2 = 0.5863449700490024\n",
      "L2 Regularization Only: MSE = 0.20368741874053162, MAE = 0.3292267543637823, R2 = 0.5529088929322576\n"
     ]
    }
   ],
   "source": [
    "models = [NN1_do, NN1_l2]\n",
    "\n",
    "\n",
    "mse_final = []\n",
    "mae_final = []\n",
    "r2_final = []\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "                validation_split = 0.2)\n",
    "\n",
    "    mse, r2, mae = evaluateModel(model, X_test, y_test)\n",
    "\n",
    "    print('RESULTS:')\n",
    "    print('MSE = {}, MAE = {}, R2 = {}'.format(mse,mae,r2))\n",
    "\n",
    "    mse_final.append(mse)\n",
    "    mae_final.append(mae)\n",
    "    r2_final.append(r2)\n",
    "\n",
    "\n",
    "print(\"--------- RESULTS -------\")\n",
    "print('Dropout Only: MSE = {}, MAE = {}, R2 = {}'.format(mse_final[0],mae_final[0],r2_final[0]))\n",
    "print('L2 Regularization Only: MSE = {}, MAE = {}, R2 = {}'.format(mse_final[1],mae_final[1],r2_final[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, dropout alone is better than l2 regularization alone. Also, with l2 regularization, the validation loss seems to fluctuate more with training; this might indicate inability to converge.  \n",
    "\n",
    "Now we will test different percentage of dropout with the top 3 neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1-Epochs=30-TIME=1586776356\n",
      "NN1 dropout=0.1\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 6s 176us/sample - loss: 0.9749 - mean_absolute_error: 0.9749 - mean_squared_error: 2.2651 - val_loss: 0.4849 - val_mean_absolute_error: 0.4849 - val_mean_squared_error: 0.3903\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 4s 142us/sample - loss: 0.4081 - mean_absolute_error: 0.4081 - mean_squared_error: 0.2978 - val_loss: 0.3492 - val_mean_absolute_error: 0.3492 - val_mean_squared_error: 0.2125\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 135us/sample - loss: 0.3733 - mean_absolute_error: 0.3733 - mean_squared_error: 0.2517 - val_loss: 0.3257 - val_mean_absolute_error: 0.3257 - val_mean_squared_error: 0.2020\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 4s 122us/sample - loss: 0.3663 - mean_absolute_error: 0.3663 - mean_squared_error: 0.2432 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.1981\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 4s 113us/sample - loss: 0.3604 - mean_absolute_error: 0.3604 - mean_squared_error: 0.2372 - val_loss: 0.3302 - val_mean_absolute_error: 0.3302 - val_mean_squared_error: 0.2056\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 4s 112us/sample - loss: 0.3586 - mean_absolute_error: 0.3586 - mean_squared_error: 0.2355 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_mean_squared_error: 0.1962\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 7s 209us/sample - loss: 0.3551 - mean_absolute_error: 0.3551 - mean_squared_error: 0.2327 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.1960\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 5s 150us/sample - loss: 0.3500 - mean_absolute_error: 0.3500 - mean_squared_error: 0.2265 - val_loss: 0.3239 - val_mean_absolute_error: 0.3239 - val_mean_squared_error: 0.1958\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 4s 129us/sample - loss: 0.3519 - mean_absolute_error: 0.3519 - mean_squared_error: 0.2286 - val_loss: 0.3209 - val_mean_absolute_error: 0.3209 - val_mean_squared_error: 0.2029\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 5s 153us/sample - loss: 0.3503 - mean_absolute_error: 0.3503 - mean_squared_error: 0.2268 - val_loss: 0.3187 - val_mean_absolute_error: 0.3187 - val_mean_squared_error: 0.1978\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 7s 223us/sample - loss: 0.3473 - mean_absolute_error: 0.3473 - mean_squared_error: 0.2239 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1986\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 6s 183us/sample - loss: 0.3478 - mean_absolute_error: 0.3478 - mean_squared_error: 0.2250 - val_loss: 0.3168 - val_mean_absolute_error: 0.3168 - val_mean_squared_error: 0.1979\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 5s 164us/sample - loss: 0.3460 - mean_absolute_error: 0.3460 - mean_squared_error: 0.2222 - val_loss: 0.3201 - val_mean_absolute_error: 0.3201 - val_mean_squared_error: 0.1930\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 5s 149us/sample - loss: 0.3448 - mean_absolute_error: 0.3448 - mean_squared_error: 0.2217 - val_loss: 0.3192 - val_mean_absolute_error: 0.3192 - val_mean_squared_error: 0.2031\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 4s 129us/sample - loss: 0.3446 - mean_absolute_error: 0.3446 - mean_squared_error: 0.2207 - val_loss: 0.3185 - val_mean_absolute_error: 0.3185 - val_mean_squared_error: 0.2003\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 6s 201us/sample - loss: 0.3459 - mean_absolute_error: 0.3459 - mean_squared_error: 0.2222 - val_loss: 0.3201 - val_mean_absolute_error: 0.3201 - val_mean_squared_error: 0.2023\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 5s 154us/sample - loss: 0.3443 - mean_absolute_error: 0.3443 - mean_squared_error: 0.2200 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_mean_squared_error: 0.1937\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 5s 174us/sample - loss: 0.3435 - mean_absolute_error: 0.3435 - mean_squared_error: 0.2193 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.1954\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 4s 140us/sample - loss: 0.3449 - mean_absolute_error: 0.3449 - mean_squared_error: 0.2213 - val_loss: 0.3167 - val_mean_absolute_error: 0.3167 - val_mean_squared_error: 0.1946\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 6s 192us/sample - loss: 0.3433 - mean_absolute_error: 0.3433 - mean_squared_error: 0.2195 - val_loss: 0.3208 - val_mean_absolute_error: 0.3208 - val_mean_squared_error: 0.1938\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 5s 145us/sample - loss: 0.3436 - mean_absolute_error: 0.3436 - mean_squared_error: 0.2183 - val_loss: 0.3309 - val_mean_absolute_error: 0.3309 - val_mean_squared_error: 0.1965\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 5s 158us/sample - loss: 0.3421 - mean_absolute_error: 0.3421 - mean_squared_error: 0.2181 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_mean_squared_error: 0.1935\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 4s 137us/sample - loss: 0.3427 - mean_absolute_error: 0.3427 - mean_squared_error: 0.2188 - val_loss: 0.3197 - val_mean_absolute_error: 0.3197 - val_mean_squared_error: 0.1993\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 5s 146us/sample - loss: 0.3402 - mean_absolute_error: 0.3402 - mean_squared_error: 0.2156 - val_loss: 0.3158 - val_mean_absolute_error: 0.3158 - val_mean_squared_error: 0.1965\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 7s 237us/sample - loss: 0.3406 - mean_absolute_error: 0.3406 - mean_squared_error: 0.2167 - val_loss: 0.3154 - val_mean_absolute_error: 0.3154 - val_mean_squared_error: 0.1937\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 5s 157us/sample - loss: 0.3402 - mean_absolute_error: 0.3402 - mean_squared_error: 0.2164 - val_loss: 0.3166 - val_mean_absolute_error: 0.3166 - val_mean_squared_error: 0.1926\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 5s 169us/sample - loss: 0.3394 - mean_absolute_error: 0.3394 - mean_squared_error: 0.2167 - val_loss: 0.3168 - val_mean_absolute_error: 0.3168 - val_mean_squared_error: 0.1924\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 4s 122us/sample - loss: 0.3399 - mean_absolute_error: 0.3399 - mean_squared_error: 0.2161 - val_loss: 0.3152 - val_mean_absolute_error: 0.3152 - val_mean_squared_error: 0.1919\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 6s 183us/sample - loss: 0.3390 - mean_absolute_error: 0.3390 - mean_squared_error: 0.2157 - val_loss: 0.3162 - val_mean_absolute_error: 0.3162 - val_mean_squared_error: 0.1958\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 5s 154us/sample - loss: 0.3380 - mean_absolute_error: 0.3380 - mean_squared_error: 0.2149 - val_loss: 0.3150 - val_mean_absolute_error: 0.3150 - val_mean_squared_error: 0.1942\n",
      "NN2 dropout=0.1\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 151us/sample - loss: 1.3021 - mean_absolute_error: 1.3021 - mean_squared_error: 3.5763 - val_loss: 0.4971 - val_mean_absolute_error: 0.4971 - val_mean_squared_error: 0.4076\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 103us/sample - loss: 0.4134 - mean_absolute_error: 0.4134 - mean_squared_error: 0.3088 - val_loss: 0.3353 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.2195\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 99us/sample - loss: 0.3673 - mean_absolute_error: 0.3673 - mean_squared_error: 0.2455 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2130\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.3592 - mean_absolute_error: 0.3592 - mean_squared_error: 0.2374 - val_loss: 0.3248 - val_mean_absolute_error: 0.3248 - val_mean_squared_error: 0.2057\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 4s 142us/sample - loss: 0.3562 - mean_absolute_error: 0.3562 - mean_squared_error: 0.2336 - val_loss: 0.3237 - val_mean_absolute_error: 0.3237 - val_mean_squared_error: 0.2037\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.3521 - mean_absolute_error: 0.3521 - mean_squared_error: 0.2292 - val_loss: 0.3241 - val_mean_absolute_error: 0.3241 - val_mean_squared_error: 0.2081\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 3s 97us/sample - loss: 0.3513 - mean_absolute_error: 0.3513 - mean_squared_error: 0.2284 - val_loss: 0.3228 - val_mean_absolute_error: 0.3228 - val_mean_squared_error: 0.1979\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 3s 92us/sample - loss: 0.3488 - mean_absolute_error: 0.3488 - mean_squared_error: 0.2262 - val_loss: 0.3206 - val_mean_absolute_error: 0.3206 - val_mean_squared_error: 0.1986\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 3s 85us/sample - loss: 0.3502 - mean_absolute_error: 0.3502 - mean_squared_error: 0.2260 - val_loss: 0.3194 - val_mean_absolute_error: 0.3194 - val_mean_squared_error: 0.1990\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.3474 - mean_absolute_error: 0.3474 - mean_squared_error: 0.2243 - val_loss: 0.3187 - val_mean_absolute_error: 0.3187 - val_mean_squared_error: 0.1948\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.3454 - mean_absolute_error: 0.3454 - mean_squared_error: 0.2214 - val_loss: 0.3255 - val_mean_absolute_error: 0.3255 - val_mean_squared_error: 0.1944\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.3459 - mean_absolute_error: 0.3459 - mean_squared_error: 0.2218 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1964\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - mean_squared_error: 0.2221 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200 - val_mean_squared_error: 0.2019\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.3456 - mean_absolute_error: 0.3456 - mean_squared_error: 0.2224 - val_loss: 0.3192 - val_mean_absolute_error: 0.3192 - val_mean_squared_error: 0.2011\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.3428 - mean_absolute_error: 0.3428 - mean_squared_error: 0.2199 - val_loss: 0.3181 - val_mean_absolute_error: 0.3181 - val_mean_squared_error: 0.1971\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.3442 - mean_absolute_error: 0.3442 - mean_squared_error: 0.2212 - val_loss: 0.3211 - val_mean_absolute_error: 0.3211 - val_mean_squared_error: 0.1908\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.3444 - mean_absolute_error: 0.3444 - mean_squared_error: 0.2191 - val_loss: 0.3174 - val_mean_absolute_error: 0.3174 - val_mean_squared_error: 0.1913\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 5s 154us/sample - loss: 0.3426 - mean_absolute_error: 0.3426 - mean_squared_error: 0.2182 - val_loss: 0.3166 - val_mean_absolute_error: 0.3166 - val_mean_squared_error: 0.1978\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 3s 90us/sample - loss: 0.3413 - mean_absolute_error: 0.3413 - mean_squared_error: 0.2176 - val_loss: 0.3248 - val_mean_absolute_error: 0.3248 - val_mean_squared_error: 0.1936\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.3420 - mean_absolute_error: 0.3420 - mean_squared_error: 0.2173 - val_loss: 0.3163 - val_mean_absolute_error: 0.3163 - val_mean_squared_error: 0.1923\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3398 - mean_absolute_error: 0.3398 - mean_squared_error: 0.2162 - val_loss: 0.3171 - val_mean_absolute_error: 0.3171 - val_mean_squared_error: 0.2006\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.3410 - mean_absolute_error: 0.3410 - mean_squared_error: 0.2167 - val_loss: 0.3169 - val_mean_absolute_error: 0.3169 - val_mean_squared_error: 0.1994\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.3395 - mean_absolute_error: 0.3395 - mean_squared_error: 0.2154 - val_loss: 0.3176 - val_mean_absolute_error: 0.3176 - val_mean_squared_error: 0.1921\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 3s 92us/sample - loss: 0.3387 - mean_absolute_error: 0.3387 - mean_squared_error: 0.2148 - val_loss: 0.3163 - val_mean_absolute_error: 0.3163 - val_mean_squared_error: 0.1898\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.3404 - mean_absolute_error: 0.3404 - mean_squared_error: 0.2151 - val_loss: 0.3150 - val_mean_absolute_error: 0.3150 - val_mean_squared_error: 0.1899\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3395 - mean_absolute_error: 0.3395 - mean_squared_error: 0.2159 - val_loss: 0.3151 - val_mean_absolute_error: 0.3151 - val_mean_squared_error: 0.1927\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3383 - mean_absolute_error: 0.3383 - mean_squared_error: 0.2146 - val_loss: 0.3140 - val_mean_absolute_error: 0.3140 - val_mean_squared_error: 0.1920\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.3385 - mean_absolute_error: 0.3385 - mean_squared_error: 0.2133 - val_loss: 0.3162 - val_mean_absolute_error: 0.3162 - val_mean_squared_error: 0.1902\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3375 - mean_absolute_error: 0.3375 - mean_squared_error: 0.2136 - val_loss: 0.3158 - val_mean_absolute_error: 0.3158 - val_mean_squared_error: 0.1996\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3363 - mean_absolute_error: 0.3363 - mean_squared_error: 0.2123 - val_loss: 0.3142 - val_mean_absolute_error: 0.3142 - val_mean_squared_error: 0.1908\n",
      "NN3 dropout=0.1\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 4s 132us/sample - loss: 3.0958 - mean_absolute_error: 3.0958 - mean_squared_error: 11.9343 - val_loss: 1.0819 - val_mean_absolute_error: 1.0819 - val_mean_squared_error: 1.9006\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.9288 - mean_absolute_error: 0.9288 - mean_squared_error: 1.3608 - val_loss: 0.7734 - val_mean_absolute_error: 0.7734 - val_mean_squared_error: 0.9459\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.7380 - mean_absolute_error: 0.7380 - mean_squared_error: 0.8664 - val_loss: 0.6293 - val_mean_absolute_error: 0.6293 - val_mean_squared_error: 0.6391\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.6036 - mean_absolute_error: 0.6036 - mean_squared_error: 0.6005 - val_loss: 0.4823 - val_mean_absolute_error: 0.4823 - val_mean_squared_error: 0.3992\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.4857 - mean_absolute_error: 0.4857 - mean_squared_error: 0.4074 - val_loss: 0.3816 - val_mean_absolute_error: 0.3816 - val_mean_squared_error: 0.2694\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4329 - mean_absolute_error: 0.4329 - mean_squared_error: 0.3276 - val_loss: 0.3454 - val_mean_absolute_error: 0.3454 - val_mean_squared_error: 0.2295\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4164 - mean_absolute_error: 0.4164 - mean_squared_error: 0.3049 - val_loss: 0.3333 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.2157\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4094 - mean_absolute_error: 0.4094 - mean_squared_error: 0.2948 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275 - val_mean_squared_error: 0.2073\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.4066 - mean_absolute_error: 0.4066 - mean_squared_error: 0.2895 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.2075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4011 - mean_absolute_error: 0.4011 - mean_squared_error: 0.2848 - val_loss: 0.3259 - val_mean_absolute_error: 0.3259 - val_mean_squared_error: 0.2054\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4007 - mean_absolute_error: 0.4007 - mean_squared_error: 0.2831 - val_loss: 0.3237 - val_mean_absolute_error: 0.3237 - val_mean_squared_error: 0.2046\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3962 - mean_absolute_error: 0.3962 - mean_squared_error: 0.2782 - val_loss: 0.3231 - val_mean_absolute_error: 0.3231 - val_mean_squared_error: 0.1998\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.3965 - mean_absolute_error: 0.3965 - mean_squared_error: 0.2783 - val_loss: 0.3216 - val_mean_absolute_error: 0.3216 - val_mean_squared_error: 0.2006\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.3963 - mean_absolute_error: 0.3963 - mean_squared_error: 0.2797 - val_loss: 0.3215 - val_mean_absolute_error: 0.3215 - val_mean_squared_error: 0.2008\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.3939 - mean_absolute_error: 0.3939 - mean_squared_error: 0.2759 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.2020\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 4s 135us/sample - loss: 0.3918 - mean_absolute_error: 0.3918 - mean_squared_error: 0.2740 - val_loss: 0.3230 - val_mean_absolute_error: 0.3230 - val_mean_squared_error: 0.2060olute_error:\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.3932 - mean_absolute_error: 0.3932 - mean_squared_error: 0.2741 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_mean_squared_error: 0.2049\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.3887 - mean_absolute_error: 0.3887 - mean_squared_error: 0.2706 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2133\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3889 - mean_absolute_error: 0.3889 - mean_squared_error: 0.2696 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200 - val_mean_squared_error: 0.1970\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.3851 - mean_absolute_error: 0.3851 - mean_squared_error: 0.2659 - val_loss: 0.3195 - val_mean_absolute_error: 0.3195 - val_mean_squared_error: 0.2008\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3863 - mean_absolute_error: 0.3863 - mean_squared_error: 0.2665 - val_loss: 0.3196 - val_mean_absolute_error: 0.3196 - val_mean_squared_error: 0.1953\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3880 - mean_absolute_error: 0.3880 - mean_squared_error: 0.2669 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198 - val_mean_squared_error: 0.1964\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.3848 - mean_absolute_error: 0.3848 - mean_squared_error: 0.2647 - val_loss: 0.3202 - val_mean_absolute_error: 0.3202 - val_mean_squared_error: 0.1998\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3847 - mean_absolute_error: 0.3847 - mean_squared_error: 0.2635 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.2104\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.3829 - mean_absolute_error: 0.3829 - mean_squared_error: 0.2625 - val_loss: 0.3193 - val_mean_absolute_error: 0.3193 - val_mean_squared_error: 0.2006\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3825 - mean_absolute_error: 0.3825 - mean_squared_error: 0.2617 - val_loss: 0.3212 - val_mean_absolute_error: 0.3212 - val_mean_squared_error: 0.2010\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.3809 - mean_absolute_error: 0.3809 - mean_squared_error: 0.2609 - val_loss: 0.3210 - val_mean_absolute_error: 0.3210 - val_mean_squared_error: 0.1956\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3802 - mean_absolute_error: 0.3802 - mean_squared_error: 0.2586 - val_loss: 0.3196 - val_mean_absolute_error: 0.3196 - val_mean_squared_error: 0.1964\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.3763 - mean_absolute_error: 0.3763 - mean_squared_error: 0.2559 - val_loss: 0.3202 - val_mean_absolute_error: 0.3202 - val_mean_squared_error: 0.1975\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 22us/sample - loss: 0.3778 - mean_absolute_error: 0.3778 - mean_squared_error: 0.2582 - val_loss: 0.3184 - val_mean_absolute_error: 0.3184 - val_mean_squared_error: 0.1988\n",
      "RESULTS ----- Dropout = 0.1-------\n",
      "NN1: MSE = 0.1880881084410151, MAE = 0.3140476840918303, R2 = 0.587149166359201\n",
      "NN2: MSE = 0.18459147497035439, MAE = 0.31788237468492214, R2 = 0.5948242291543128\n",
      "NN3: MSE = 0.19288633668887217, MAE = 0.31788237468492214, R2 = 0.5766171207740445\n",
      "0.2-Epochs=30-TIME=1586776634\n",
      "NN1 dropout=0.2\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 175us/sample - loss: 0.9992 - mean_absolute_error: 0.9992 - mean_squared_error: 2.3334 - val_loss: 0.5399 - val_mean_absolute_error: 0.5399 - val_mean_squared_error: 0.4545\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 4s 132us/sample - loss: 0.5390 - mean_absolute_error: 0.5390 - mean_squared_error: 0.4800 - val_loss: 0.3622 - val_mean_absolute_error: 0.3622 - val_mean_squared_error: 0.2441\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 143us/sample - loss: 0.4137 - mean_absolute_error: 0.4137 - mean_squared_error: 0.3006 - val_loss: 0.3351 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.2071\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 4s 118us/sample - loss: 0.3988 - mean_absolute_error: 0.3988 - mean_squared_error: 0.2819 - val_loss: 0.3341 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2072\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 6s 179us/sample - loss: 0.3917 - mean_absolute_error: 0.3917 - mean_squared_error: 0.2727 - val_loss: 0.3279 - val_mean_absolute_error: 0.3279 - val_mean_squared_error: 0.2098\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 4s 144us/sample - loss: 0.3852 - mean_absolute_error: 0.3852 - mean_squared_error: 0.2648 - val_loss: 0.3372 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.2020\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 4s 144us/sample - loss: 0.3833 - mean_absolute_error: 0.3833 - mean_squared_error: 0.2621 - val_loss: 0.3231 - val_mean_absolute_error: 0.3231 - val_mean_squared_error: 0.1983\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 5s 155us/sample - loss: 0.3799 - mean_absolute_error: 0.3799 - mean_squared_error: 0.2586 - val_loss: 0.3377 - val_mean_absolute_error: 0.3377 - val_mean_squared_error: 0.2242\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 4s 137us/sample - loss: 0.3811 - mean_absolute_error: 0.3811 - mean_squared_error: 0.2595 - val_loss: 0.3216 - val_mean_absolute_error: 0.3216 - val_mean_squared_error: 0.2034\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.3797 - mean_absolute_error: 0.3797 - mean_squared_error: 0.2596 - val_loss: 0.3227 - val_mean_absolute_error: 0.3227 - val_mean_squared_error: 0.2038\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3793 - mean_absolute_error: 0.3793 - mean_squared_error: 0.2571 - val_loss: 0.3207 - val_mean_absolute_error: 0.3207 - val_mean_squared_error: 0.2028\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.3774 - mean_absolute_error: 0.3774 - mean_squared_error: 0.2560 - val_loss: 0.3323 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.1990\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3756 - mean_absolute_error: 0.3756 - mean_squared_error: 0.2543 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264 - val_mean_squared_error: 0.1971\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.3747 - mean_absolute_error: 0.3747 - mean_squared_error: 0.2524 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.1945\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3754 - mean_absolute_error: 0.3754 - mean_squared_error: 0.2526 - val_loss: 0.3270 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.1964\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.3740 - mean_absolute_error: 0.3740 - mean_squared_error: 0.2511 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.2025\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3743 - mean_absolute_error: 0.3743 - mean_squared_error: 0.2522 - val_loss: 0.3229 - val_mean_absolute_error: 0.3229 - val_mean_squared_error: 0.1956\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3715 - mean_absolute_error: 0.3715 - mean_squared_error: 0.2487 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249 - val_mean_squared_error: 0.2036\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.3721 - mean_absolute_error: 0.3721 - mean_squared_error: 0.2506 - val_loss: 0.3210 - val_mean_absolute_error: 0.3210 - val_mean_squared_error: 0.2009\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3696 - mean_absolute_error: 0.3696 - mean_squared_error: 0.2468 - val_loss: 0.3225 - val_mean_absolute_error: 0.3225 - val_mean_squared_error: 0.1936\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3698 - mean_absolute_error: 0.3698 - mean_squared_error: 0.2476 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.1942\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.3705 - mean_absolute_error: 0.3705 - mean_squared_error: 0.2480 - val_loss: 0.3182 - val_mean_absolute_error: 0.3182 - val_mean_squared_error: 0.1940\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.3689 - mean_absolute_error: 0.3689 - mean_squared_error: 0.2463 - val_loss: 0.3293 - val_mean_absolute_error: 0.3293 - val_mean_squared_error: 0.1979\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3674 - mean_absolute_error: 0.3674 - mean_squared_error: 0.2439 - val_loss: 0.3225 - val_mean_absolute_error: 0.3225 - val_mean_squared_error: 0.1932\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.3691 - mean_absolute_error: 0.3691 - mean_squared_error: 0.2460 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205 - val_mean_squared_error: 0.1935\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.3672 - mean_absolute_error: 0.3672 - mean_squared_error: 0.2427 - val_loss: 0.3226 - val_mean_absolute_error: 0.3226 - val_mean_squared_error: 0.1926\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3649 - mean_absolute_error: 0.3649 - mean_squared_error: 0.2417 - val_loss: 0.3187 - val_mean_absolute_error: 0.3187 - val_mean_squared_error: 0.1933\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 3s 89us/sample - loss: 0.3661 - mean_absolute_error: 0.3661 - mean_squared_error: 0.2430 - val_loss: 0.3168 - val_mean_absolute_error: 0.3168 - val_mean_squared_error: 0.1956\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.3640 - mean_absolute_error: 0.3640 - mean_squared_error: 0.2411 - val_loss: 0.3246 - val_mean_absolute_error: 0.3246 - val_mean_squared_error: 0.2066\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3673 - mean_absolute_error: 0.3673 - mean_squared_error: 0.2442 - val_loss: 0.3173 - val_mean_absolute_error: 0.3173 - val_mean_squared_error: 0.1929\n",
      "NN2 dropout=0.2\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 6s 208us/sample - loss: 1.3124 - mean_absolute_error: 1.3124 - mean_squared_error: 3.5484 - val_loss: 0.4563 - val_mean_absolute_error: 0.4563 - val_mean_squared_error: 0.3552\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 111us/sample - loss: 0.4406 - mean_absolute_error: 0.4406 - mean_squared_error: 0.3404 - val_loss: 0.3372 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.2232\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 113us/sample - loss: 0.4025 - mean_absolute_error: 0.4025 - mean_squared_error: 0.2877 - val_loss: 0.3284 - val_mean_absolute_error: 0.3284 - val_mean_squared_error: 0.2093\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 104us/sample - loss: 0.3908 - mean_absolute_error: 0.3908 - mean_squared_error: 0.2722 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264 - val_mean_squared_error: 0.2025\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.3852 - mean_absolute_error: 0.3852 - mean_squared_error: 0.2656 - val_loss: 0.3351 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.2238\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3805 - mean_absolute_error: 0.3805 - mean_squared_error: 0.2607 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264 - val_mean_squared_error: 0.1985\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.3806 - mean_absolute_error: 0.3806 - mean_squared_error: 0.2606 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.1991\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.3770 - mean_absolute_error: 0.3770 - mean_squared_error: 0.2564 - val_loss: 0.3231 - val_mean_absolute_error: 0.3231 - val_mean_squared_error: 0.2033\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.3776 - mean_absolute_error: 0.3776 - mean_squared_error: 0.2560 - val_loss: 0.3241 - val_mean_absolute_error: 0.3241 - val_mean_squared_error: 0.2017\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 4s 143us/sample - loss: 0.3749 - mean_absolute_error: 0.3749 - mean_squared_error: 0.2525 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.2116\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.3748 - mean_absolute_error: 0.3748 - mean_squared_error: 0.2528 - val_loss: 0.3274 - val_mean_absolute_error: 0.3274 - val_mean_squared_error: 0.2117\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 3s 96us/sample - loss: 0.3722 - mean_absolute_error: 0.3722 - mean_squared_error: 0.2515 - val_loss: 0.3239 - val_mean_absolute_error: 0.3239 - val_mean_squared_error: 0.1981\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 107us/sample - loss: 0.3727 - mean_absolute_error: 0.3727 - mean_squared_error: 0.2499 - val_loss: 0.3217 - val_mean_absolute_error: 0.3217 - val_mean_squared_error: 0.1997\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 3s 93us/sample - loss: 0.3731 - mean_absolute_error: 0.3731 - mean_squared_error: 0.2508 - val_loss: 0.3228 - val_mean_absolute_error: 0.3228 - val_mean_squared_error: 0.1960\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.3724 - mean_absolute_error: 0.3724 - mean_squared_error: 0.2493 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.1972\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 62us/sample - loss: 0.3706 - mean_absolute_error: 0.3706 - mean_squared_error: 0.2472 - val_loss: 0.3245 - val_mean_absolute_error: 0.3245 - val_mean_squared_error: 0.2106\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3689 - mean_absolute_error: 0.3689 - mean_squared_error: 0.2458 - val_loss: 0.3267 - val_mean_absolute_error: 0.3267 - val_mean_squared_error: 0.1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 4s 137us/sample - loss: 0.3666 - mean_absolute_error: 0.3666 - mean_squared_error: 0.2450 - val_loss: 0.3261 - val_mean_absolute_error: 0.3261 - val_mean_squared_error: 0.2113\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3673 - mean_absolute_error: 0.3673 - mean_squared_error: 0.2461 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200 - val_mean_squared_error: 0.1976\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 79us/sample - loss: 0.3670 - mean_absolute_error: 0.3670 - mean_squared_error: 0.2443 - val_loss: 0.3207 - val_mean_absolute_error: 0.3207 - val_mean_squared_error: 0.1938\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.3643 - mean_absolute_error: 0.3643 - mean_squared_error: 0.2429 - val_loss: 0.3171 - val_mean_absolute_error: 0.3171 - val_mean_squared_error: 0.1962\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.3657 - mean_absolute_error: 0.3657 - mean_squared_error: 0.2417 - val_loss: 0.3178 - val_mean_absolute_error: 0.3178 - val_mean_squared_error: 0.1991\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3663 - mean_absolute_error: 0.3663 - mean_squared_error: 0.2436 - val_loss: 0.3189 - val_mean_absolute_error: 0.3189 - val_mean_squared_error: 0.1983\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3650 - mean_absolute_error: 0.3650 - mean_squared_error: 0.2425 - val_loss: 0.3193 - val_mean_absolute_error: 0.3193 - val_mean_squared_error: 0.2016\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3619 - mean_absolute_error: 0.3619 - mean_squared_error: 0.2395 - val_loss: 0.3191 - val_mean_absolute_error: 0.3191 - val_mean_squared_error: 0.1935\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.3614 - mean_absolute_error: 0.3614 - mean_squared_error: 0.2376 - val_loss: 0.3215 - val_mean_absolute_error: 0.3215 - val_mean_squared_error: 0.1925\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.3612 - mean_absolute_error: 0.3612 - mean_squared_error: 0.2373 - val_loss: 0.3202 - val_mean_absolute_error: 0.3202 - val_mean_squared_error: 0.1901\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 4s 139us/sample - loss: 0.3650 - mean_absolute_error: 0.3650 - mean_squared_error: 0.2408 - val_loss: 0.3174 - val_mean_absolute_error: 0.3174 - val_mean_squared_error: 0.1987\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.3590 - mean_absolute_error: 0.3590 - mean_squared_error: 0.2345 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157 - val_mean_squared_error: 0.1929\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.3590 - mean_absolute_error: 0.3590 - mean_squared_error: 0.2348 - val_loss: 0.3166 - val_mean_absolute_error: 0.3166 - val_mean_squared_error: 0.1909\n",
      "NN3 dropout=0.2\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 3.1172 - mean_absolute_error: 3.1172 - mean_squared_error: 12.0501 - val_loss: 1.0810 - val_mean_absolute_error: 1.0810 - val_mean_squared_error: 1.9145\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.9600 - mean_absolute_error: 0.9600 - mean_squared_error: 1.4495 - val_loss: 0.7728 - val_mean_absolute_error: 0.7728 - val_mean_squared_error: 0.9460\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.7780 - mean_absolute_error: 0.7780 - mean_squared_error: 0.9581 - val_loss: 0.6245 - val_mean_absolute_error: 0.6245 - val_mean_squared_error: 0.6259\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.6497 - mean_absolute_error: 0.6497 - mean_squared_error: 0.6900 - val_loss: 0.4806 - val_mean_absolute_error: 0.4806 - val_mean_squared_error: 0.3962\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.5605 - mean_absolute_error: 0.5605 - mean_squared_error: 0.5207 - val_loss: 0.3955 - val_mean_absolute_error: 0.3955 - val_mean_squared_error: 0.2839\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.5188 - mean_absolute_error: 0.5188 - mean_squared_error: 0.4514 - val_loss: 0.3604 - val_mean_absolute_error: 0.3604 - val_mean_squared_error: 0.2465\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.4976 - mean_absolute_error: 0.4976 - mean_squared_error: 0.4165 - val_loss: 0.3448 - val_mean_absolute_error: 0.3448 - val_mean_squared_error: 0.2298\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.4849 - mean_absolute_error: 0.4849 - mean_squared_error: 0.3975 - val_loss: 0.3341 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2195\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.4768 - mean_absolute_error: 0.4768 - mean_squared_error: 0.3838 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2124\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.4744 - mean_absolute_error: 0.4744 - mean_squared_error: 0.3839 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2116\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.4657 - mean_absolute_error: 0.4657 - mean_squared_error: 0.3701 - val_loss: 0.3271 - val_mean_absolute_error: 0.3271 - val_mean_squared_error: 0.2039\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.4637 - mean_absolute_error: 0.4637 - mean_squared_error: 0.3651 - val_loss: 0.3297 - val_mean_absolute_error: 0.3297 - val_mean_squared_error: 0.2161\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 107us/sample - loss: 0.4570 - mean_absolute_error: 0.4570 - mean_squared_error: 0.3582 - val_loss: 0.3262 - val_mean_absolute_error: 0.3262 - val_mean_squared_error: 0.2079\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.4578 - mean_absolute_error: 0.4578 - mean_squared_error: 0.3604 - val_loss: 0.3251 - val_mean_absolute_error: 0.3251 - val_mean_squared_error: 0.2050\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.4533 - mean_absolute_error: 0.4533 - mean_squared_error: 0.3529 - val_loss: 0.3241 - val_mean_absolute_error: 0.3241 - val_mean_squared_error: 0.2045\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4545 - mean_absolute_error: 0.4545 - mean_squared_error: 0.3535 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_mean_squared_error: 0.2013\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4496 - mean_absolute_error: 0.4496 - mean_squared_error: 0.3464 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2082\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.4467 - mean_absolute_error: 0.4467 - mean_squared_error: 0.3426 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249 - val_mean_squared_error: 0.2030\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4447 - mean_absolute_error: 0.4447 - mean_squared_error: 0.3427 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_mean_squared_error: 0.2083\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.4452 - mean_absolute_error: 0.4452 - mean_squared_error: 0.3392 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_mean_squared_error: 0.2060\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.4416 - mean_absolute_error: 0.4416 - mean_squared_error: 0.3365 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275 - val_mean_squared_error: 0.2129\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4367 - mean_absolute_error: 0.4367 - mean_squared_error: 0.3291 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224 - val_mean_squared_error: 0.2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.4396 - mean_absolute_error: 0.4396 - mean_squared_error: 0.3330 - val_loss: 0.3245 - val_mean_absolute_error: 0.3245 - val_mean_squared_error: 0.2030\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4337 - mean_absolute_error: 0.4337 - mean_squared_error: 0.3248 - val_loss: 0.3227 - val_mean_absolute_error: 0.3227 - val_mean_squared_error: 0.2010\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4312 - mean_absolute_error: 0.4312 - mean_squared_error: 0.3227 - val_loss: 0.3252 - val_mean_absolute_error: 0.3252 - val_mean_squared_error: 0.2083\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.4291 - mean_absolute_error: 0.4291 - mean_squared_error: 0.3201 - val_loss: 0.3212 - val_mean_absolute_error: 0.3212 - val_mean_squared_error: 0.1982\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.4251 - mean_absolute_error: 0.4251 - mean_squared_error: 0.3158 - val_loss: 0.3263 - val_mean_absolute_error: 0.3263 - val_mean_squared_error: 0.2134\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.4207 - mean_absolute_error: 0.4207 - mean_squared_error: 0.3089 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234 - val_mean_squared_error: 0.2036\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.4224 - mean_absolute_error: 0.4224 - mean_squared_error: 0.3127 - val_loss: 0.3210 - val_mean_absolute_error: 0.3210 - val_mean_squared_error: 0.1989\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 3s 112us/sample - loss: 0.4151 - mean_absolute_error: 0.4151 - mean_squared_error: 0.3013 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214 - val_mean_squared_error: 0.1969s: 0.4\n",
      "RESULTS ----- Dropout = 0.2-------\n",
      "NN1: MSE = 0.1885248733093264, MAE = 0.3174293793349413, R2 = 0.5861904734280958\n",
      "NN2: MSE = 0.18636597289479961, MAE = 0.32060306689598633, R2 = 0.5909292304036031\n",
      "NN3: MSE = 0.1918593821416436, MAE = 0.32060306689598633, R2 = 0.5788712720037459\n",
      "0.3-Epochs=30-TIME=1586776851\n",
      "NN1 dropout=0.3\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 167us/sample - loss: 1.0371 - mean_absolute_error: 1.0371 - mean_squared_error: 2.4600 - val_loss: 0.5310 - val_mean_absolute_error: 0.5310 - val_mean_squared_error: 0.4451\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 97us/sample - loss: 0.5211 - mean_absolute_error: 0.5211 - mean_squared_error: 0.4544 - val_loss: 0.3440 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.2253\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 112us/sample - loss: 0.4440 - mean_absolute_error: 0.4440 - mean_squared_error: 0.3408 - val_loss: 0.3406 - val_mean_absolute_error: 0.3406 - val_mean_squared_error: 0.2170\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 112us/sample - loss: 0.4281 - mean_absolute_error: 0.4281 - mean_squared_error: 0.3184 - val_loss: 0.3317 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2098\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 7s 216us/sample - loss: 0.4210 - mean_absolute_error: 0.4210 - mean_squared_error: 0.3081 - val_loss: 0.3345 - val_mean_absolute_error: 0.3345 - val_mean_squared_error: 0.2097\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 5s 170us/sample - loss: 0.4160 - mean_absolute_error: 0.4160 - mean_squared_error: 0.3031 - val_loss: 0.3258 - val_mean_absolute_error: 0.3258 - val_mean_squared_error: 0.2057\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 5s 147us/sample - loss: 0.4140 - mean_absolute_error: 0.4140 - mean_squared_error: 0.3004 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2043\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 5s 148us/sample - loss: 0.4128 - mean_absolute_error: 0.4128 - mean_squared_error: 0.2977 - val_loss: 0.3294 - val_mean_absolute_error: 0.3294 - val_mean_squared_error: 0.2012\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 3s 104us/sample - loss: 0.4135 - mean_absolute_error: 0.4135 - mean_squared_error: 0.2979 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260 - val_mean_squared_error: 0.2045\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.4092 - mean_absolute_error: 0.4092 - mean_squared_error: 0.2928 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234 - val_mean_squared_error: 0.1991\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4070 - mean_absolute_error: 0.4070 - mean_squared_error: 0.2906 - val_loss: 0.3270 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.1975\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.4047 - mean_absolute_error: 0.4047 - mean_squared_error: 0.2865 - val_loss: 0.3226 - val_mean_absolute_error: 0.3226 - val_mean_squared_error: 0.2023\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4047 - mean_absolute_error: 0.4047 - mean_squared_error: 0.2873 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_mean_squared_error: 0.1996\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.4037 - mean_absolute_error: 0.4037 - mean_squared_error: 0.2877 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264 - val_mean_squared_error: 0.1975\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.4020 - mean_absolute_error: 0.4020 - mean_squared_error: 0.2843 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.1989\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.4033 - mean_absolute_error: 0.4033 - mean_squared_error: 0.2858 - val_loss: 0.3274 - val_mean_absolute_error: 0.3274 - val_mean_squared_error: 0.2052\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.4028 - mean_absolute_error: 0.4028 - mean_squared_error: 0.2869 - val_loss: 0.3215 - val_mean_absolute_error: 0.3215 - val_mean_squared_error: 0.2026\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3987 - mean_absolute_error: 0.3987 - mean_squared_error: 0.2806 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200 - val_mean_squared_error: 0.1970\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.4002 - mean_absolute_error: 0.4002 - mean_squared_error: 0.2821 - val_loss: 0.3220 - val_mean_absolute_error: 0.3220 - val_mean_squared_error: 0.1967\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.3971 - mean_absolute_error: 0.3971 - mean_squared_error: 0.2791 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.1969\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.3942 - mean_absolute_error: 0.3942 - mean_squared_error: 0.2748 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.1967\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.3994 - mean_absolute_error: 0.3994 - mean_squared_error: 0.2810 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260 - val_mean_squared_error: 0.1970\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.3963 - mean_absolute_error: 0.3963 - mean_squared_error: 0.2769 - val_loss: 0.3252 - val_mean_absolute_error: 0.3252 - val_mean_squared_error: 0.1965\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.3939 - mean_absolute_error: 0.3939 - mean_squared_error: 0.2740 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.1992\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.3904 - mean_absolute_error: 0.3904 - mean_squared_error: 0.2706 - val_loss: 0.3240 - val_mean_absolute_error: 0.3240 - val_mean_squared_error: 0.1956\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.3927 - mean_absolute_error: 0.3927 - mean_squared_error: 0.2737 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.1956\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.3877 - mean_absolute_error: 0.3877 - mean_squared_error: 0.2678 - val_loss: 0.3209 - val_mean_absolute_error: 0.3209 - val_mean_squared_error: 0.1964\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 63us/sample - loss: 0.3905 - mean_absolute_error: 0.3905 - mean_squared_error: 0.2696 - val_loss: 0.3320 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.2013\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 58us/sample - loss: 0.3891 - mean_absolute_error: 0.3891 - mean_squared_error: 0.2691 - val_loss: 0.3183 - val_mean_absolute_error: 0.3183 - val_mean_squared_error: 0.1953\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 72us/sample - loss: 0.3864 - mean_absolute_error: 0.3864 - mean_squared_error: 0.2641 - val_loss: 0.3348 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1999\n",
      "NN2 dropout=0.3\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 1.3021 - mean_absolute_error: 1.3021 - mean_squared_error: 3.3865 - val_loss: 0.4638 - val_mean_absolute_error: 0.4638 - val_mean_squared_error: 0.3615\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4845 - mean_absolute_error: 0.4845 - mean_squared_error: 0.4013 - val_loss: 0.3407 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.2216\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.4367 - mean_absolute_error: 0.4367 - mean_squared_error: 0.3310 - val_loss: 0.3353 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.2187\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.4231 - mean_absolute_error: 0.4231 - mean_squared_error: 0.3109 - val_loss: 0.3358 - val_mean_absolute_error: 0.3358 - val_mean_squared_error: 0.2248\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.4138 - mean_absolute_error: 0.4138 - mean_squared_error: 0.3011 - val_loss: 0.3310 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2083\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.4134 - mean_absolute_error: 0.4134 - mean_squared_error: 0.2996 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275 - val_mean_squared_error: 0.2045\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.4080 - mean_absolute_error: 0.4080 - mean_squared_error: 0.2939 - val_loss: 0.3315 - val_mean_absolute_error: 0.3315 - val_mean_squared_error: 0.2032\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.4091 - mean_absolute_error: 0.4091 - mean_squared_error: 0.2948 - val_loss: 0.3271 - val_mean_absolute_error: 0.3271 - val_mean_squared_error: 0.2039\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.4055 - mean_absolute_error: 0.4055 - mean_squared_error: 0.2896 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303 - val_mean_squared_error: 0.2167\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.4036 - mean_absolute_error: 0.4036 - mean_squared_error: 0.2863 - val_loss: 0.3259 - val_mean_absolute_error: 0.3259 - val_mean_squared_error: 0.2007\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.4030 - mean_absolute_error: 0.4030 - mean_squared_error: 0.2862 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249 - val_mean_squared_error: 0.2059\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.4016 - mean_absolute_error: 0.4016 - mean_squared_error: 0.2848 - val_loss: 0.3236 - val_mean_absolute_error: 0.3236 - val_mean_squared_error: 0.2016\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.4010 - mean_absolute_error: 0.4010 - mean_squared_error: 0.2857 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2026\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.3989 - mean_absolute_error: 0.3989 - mean_squared_error: 0.2814 - val_loss: 0.3252 - val_mean_absolute_error: 0.3252 - val_mean_squared_error: 0.1993\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.3957 - mean_absolute_error: 0.3957 - mean_squared_error: 0.2776 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2087\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3980 - mean_absolute_error: 0.3980 - mean_squared_error: 0.2790 - val_loss: 0.3264 - val_mean_absolute_error: 0.3264 - val_mean_squared_error: 0.1975\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.3940 - mean_absolute_error: 0.3940 - mean_squared_error: 0.2740 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224 - val_mean_squared_error: 0.2021\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.3947 - mean_absolute_error: 0.3947 - mean_squared_error: 0.2770 - val_loss: 0.3219 - val_mean_absolute_error: 0.3219 - val_mean_squared_error: 0.2002\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.3956 - mean_absolute_error: 0.3956 - mean_squared_error: 0.2775 - val_loss: 0.3418 - val_mean_absolute_error: 0.3418 - val_mean_squared_error: 0.2040\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.3937 - mean_absolute_error: 0.3937 - mean_squared_error: 0.2739 - val_loss: 0.3254 - val_mean_absolute_error: 0.3254 - val_mean_squared_error: 0.1986\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.3906 - mean_absolute_error: 0.3906 - mean_squared_error: 0.2701 - val_loss: 0.3231 - val_mean_absolute_error: 0.3231 - val_mean_squared_error: 0.2032\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3887 - mean_absolute_error: 0.3887 - mean_squared_error: 0.2686 - val_loss: 0.3202 - val_mean_absolute_error: 0.3202 - val_mean_squared_error: 0.1977\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3888 - mean_absolute_error: 0.3888 - mean_squared_error: 0.2697 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224 - val_mean_squared_error: 0.2054\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.3887 - mean_absolute_error: 0.3887 - mean_squared_error: 0.2688 - val_loss: 0.3211 - val_mean_absolute_error: 0.3211 - val_mean_squared_error: 0.1984\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.3867 - mean_absolute_error: 0.3867 - mean_squared_error: 0.2659 - val_loss: 0.3213 - val_mean_absolute_error: 0.3213 - val_mean_squared_error: 0.2026\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.3848 - mean_absolute_error: 0.3848 - mean_squared_error: 0.2653 - val_loss: 0.3192 - val_mean_absolute_error: 0.3192 - val_mean_squared_error: 0.1990\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.3842 - mean_absolute_error: 0.3842 - mean_squared_error: 0.2646 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.1949\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.3819 - mean_absolute_error: 0.3819 - mean_squared_error: 0.2613 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.1948\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.3793 - mean_absolute_error: 0.3793 - mean_squared_error: 0.2585 - val_loss: 0.3306 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.1959\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 56us/sample - loss: 0.3822 - mean_absolute_error: 0.3822 - mean_squared_error: 0.2600 - val_loss: 0.3182 - val_mean_absolute_error: 0.3182 - val_mean_squared_error: 0.1960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3 dropout=0.3\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 3.0480 - mean_absolute_error: 3.0480 - mean_squared_error: 11.6335 - val_loss: 1.1061 - val_mean_absolute_error: 1.1061 - val_mean_squared_error: 1.9771\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 1.0193 - mean_absolute_error: 1.0193 - mean_squared_error: 1.6240 - val_loss: 0.7936 - val_mean_absolute_error: 0.7936 - val_mean_squared_error: 0.9970\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.8366 - mean_absolute_error: 0.8366 - mean_squared_error: 1.1046 - val_loss: 0.6291 - val_mean_absolute_error: 0.6291 - val_mean_squared_error: 0.6397\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.7063 - mean_absolute_error: 0.7063 - mean_squared_error: 0.8079 - val_loss: 0.4795 - val_mean_absolute_error: 0.4795 - val_mean_squared_error: 0.3996\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.6290 - mean_absolute_error: 0.6290 - mean_squared_error: 0.6445 - val_loss: 0.4018 - val_mean_absolute_error: 0.4018 - val_mean_squared_error: 0.2975\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5851 - mean_absolute_error: 0.5851 - mean_squared_error: 0.5615 - val_loss: 0.3639 - val_mean_absolute_error: 0.3639 - val_mean_squared_error: 0.2577\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.5685 - mean_absolute_error: 0.5685 - mean_squared_error: 0.5363 - val_loss: 0.3467 - val_mean_absolute_error: 0.3467 - val_mean_squared_error: 0.2313\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5547 - mean_absolute_error: 0.5547 - mean_squared_error: 0.5081 - val_loss: 0.3395 - val_mean_absolute_error: 0.3395 - val_mean_squared_error: 0.2259\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5475 - mean_absolute_error: 0.5475 - mean_squared_error: 0.4978 - val_loss: 0.3363 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.2217\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5444 - mean_absolute_error: 0.5444 - mean_squared_error: 0.4908 - val_loss: 0.3369 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.2252\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5371 - mean_absolute_error: 0.5371 - mean_squared_error: 0.4816 - val_loss: 0.3305 - val_mean_absolute_error: 0.3305 - val_mean_squared_error: 0.2157\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.5324 - mean_absolute_error: 0.5324 - mean_squared_error: 0.4724 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.2167\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.5267 - mean_absolute_error: 0.5267 - mean_squared_error: 0.4617 - val_loss: 0.3306 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.2135\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5208 - mean_absolute_error: 0.5208 - mean_squared_error: 0.4566 - val_loss: 0.3276 - val_mean_absolute_error: 0.3276 - val_mean_squared_error: 0.2126\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.5184 - mean_absolute_error: 0.5184 - mean_squared_error: 0.4497 - val_loss: 0.3308 - val_mean_absolute_error: 0.3308 - val_mean_squared_error: 0.2173\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5162 - mean_absolute_error: 0.5162 - mean_squared_error: 0.4484 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249 - val_mean_squared_error: 0.2040\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.5117 - mean_absolute_error: 0.5117 - mean_squared_error: 0.4381 - val_loss: 0.3284 - val_mean_absolute_error: 0.3284 - val_mean_squared_error: 0.2124\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.5033 - mean_absolute_error: 0.5033 - mean_squared_error: 0.4266 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2097\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.5005 - mean_absolute_error: 0.5005 - mean_squared_error: 0.4216 - val_loss: 0.3282 - val_mean_absolute_error: 0.3282 - val_mean_squared_error: 0.2080\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.4987 - mean_absolute_error: 0.4987 - mean_squared_error: 0.4187 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2014\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.4917 - mean_absolute_error: 0.4917 - mean_squared_error: 0.4084 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2126\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.4873 - mean_absolute_error: 0.4873 - mean_squared_error: 0.4027 - val_loss: 0.3256 - val_mean_absolute_error: 0.3256 - val_mean_squared_error: 0.2053\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.4826 - mean_absolute_error: 0.4826 - mean_squared_error: 0.3977 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2087\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.4760 - mean_absolute_error: 0.4760 - mean_squared_error: 0.3856 - val_loss: 0.3267 - val_mean_absolute_error: 0.3267 - val_mean_squared_error: 0.2105\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.4754 - mean_absolute_error: 0.4754 - mean_squared_error: 0.3845 - val_loss: 0.3270 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.2126\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.4673 - mean_absolute_error: 0.4673 - mean_squared_error: 0.3730 - val_loss: 0.3230 - val_mean_absolute_error: 0.3230 - val_mean_squared_error: 0.1983\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.4668 - mean_absolute_error: 0.4668 - mean_squared_error: 0.3719 - val_loss: 0.3243 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2063\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.4628 - mean_absolute_error: 0.4628 - mean_squared_error: 0.3676 - val_loss: 0.3236 - val_mean_absolute_error: 0.3236 - val_mean_squared_error: 0.2022\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.4527 - mean_absolute_error: 0.4527 - mean_squared_error: 0.3546 - val_loss: 0.3244 - val_mean_absolute_error: 0.3244 - val_mean_squared_error: 0.2061\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.4505 - mean_absolute_error: 0.4505 - mean_squared_error: 0.3517 - val_loss: 0.3212 - val_mean_absolute_error: 0.3212 - val_mean_squared_error: 0.2017\n",
      "RESULTS ----- Dropout = 0.3-------\n",
      "NN1: MSE = 0.19620074078008468, MAE = 0.33484609216488503, R2 = 0.5693420489823119\n",
      "NN2: MSE = 0.19061858778834131, MAE = 0.32149725063490636, R2 = 0.581594798692294\n",
      "NN3: MSE = 0.1960316656850898, MAE = 0.32149725063490636, R2 = 0.5697131665106612\n",
      "0.4-Epochs=30-TIME=1586777016\n",
      "NN1 dropout=0.4\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 3s 93us/sample - loss: 1.0632 - mean_absolute_error: 1.0632 - mean_squared_error: 2.5158 - val_loss: 0.5363 - val_mean_absolute_error: 0.5363 - val_mean_squared_error: 0.4493\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.5660 - mean_absolute_error: 0.5660 - mean_squared_error: 0.5291 - val_loss: 0.3592 - val_mean_absolute_error: 0.3592 - val_mean_squared_error: 0.2375\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4852 - mean_absolute_error: 0.4852 - mean_squared_error: 0.3966 - val_loss: 0.3581 - val_mean_absolute_error: 0.3581 - val_mean_squared_error: 0.2252\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.4647 - mean_absolute_error: 0.4647 - mean_squared_error: 0.3679 - val_loss: 0.3447 - val_mean_absolute_error: 0.3447 - val_mean_squared_error: 0.2179\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 72us/sample - loss: 0.4649 - mean_absolute_error: 0.4649 - mean_squared_error: 0.3683 - val_loss: 0.3395 - val_mean_absolute_error: 0.3395 - val_mean_squared_error: 0.2180\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.4588 - mean_absolute_error: 0.4588 - mean_squared_error: 0.3598 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.2184\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.4547 - mean_absolute_error: 0.4547 - mean_squared_error: 0.3486 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.2073\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.4518 - mean_absolute_error: 0.4518 - mean_squared_error: 0.3469 - val_loss: 0.3388 - val_mean_absolute_error: 0.3388 - val_mean_squared_error: 0.2073\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.4487 - mean_absolute_error: 0.4487 - mean_squared_error: 0.3430 - val_loss: 0.3301 - val_mean_absolute_error: 0.3301 - val_mean_squared_error: 0.2028\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4502 - mean_absolute_error: 0.4502 - mean_squared_error: 0.3446 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303 - val_mean_squared_error: 0.2095\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4469 - mean_absolute_error: 0.4469 - mean_squared_error: 0.3428 - val_loss: 0.3276 - val_mean_absolute_error: 0.3276 - val_mean_squared_error: 0.2074\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.4442 - mean_absolute_error: 0.4442 - mean_squared_error: 0.3376 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.2053\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.4443 - mean_absolute_error: 0.4443 - mean_squared_error: 0.3359 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2007\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.4411 - mean_absolute_error: 0.4411 - mean_squared_error: 0.3340 - val_loss: 0.3295 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.2134\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.4387 - mean_absolute_error: 0.4387 - mean_squared_error: 0.3305 - val_loss: 0.3294 - val_mean_absolute_error: 0.3294 - val_mean_squared_error: 0.2037\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4340 - mean_absolute_error: 0.4340 - mean_squared_error: 0.3241 - val_loss: 0.3346 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.2182\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.4359 - mean_absolute_error: 0.4359 - mean_squared_error: 0.3265 - val_loss: 0.3289 - val_mean_absolute_error: 0.3289 - val_mean_squared_error: 0.2086\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.4324 - mean_absolute_error: 0.4324 - mean_squared_error: 0.3218 - val_loss: 0.3258 - val_mean_absolute_error: 0.3258 - val_mean_squared_error: 0.2005\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.4281 - mean_absolute_error: 0.4281 - mean_squared_error: 0.3168 - val_loss: 0.3247 - val_mean_absolute_error: 0.3247 - val_mean_squared_error: 0.2045\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.4274 - mean_absolute_error: 0.4274 - mean_squared_error: 0.3187 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_mean_squared_error: 0.2100\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.4256 - mean_absolute_error: 0.4256 - mean_squared_error: 0.3141 - val_loss: 0.3252 - val_mean_absolute_error: 0.3252 - val_mean_squared_error: 0.1993\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4250 - mean_absolute_error: 0.4250 - mean_squared_error: 0.3138 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.2125\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.4247 - mean_absolute_error: 0.4247 - mean_squared_error: 0.3131 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.1980\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.4231 - mean_absolute_error: 0.4231 - mean_squared_error: 0.3114 - val_loss: 0.3276 - val_mean_absolute_error: 0.3276 - val_mean_squared_error: 0.2103\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.4216 - mean_absolute_error: 0.4216 - mean_squared_error: 0.3067 - val_loss: 0.3232 - val_mean_absolute_error: 0.3232 - val_mean_squared_error: 0.2035\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 72us/sample - loss: 0.4173 - mean_absolute_error: 0.4173 - mean_squared_error: 0.3030 - val_loss: 0.3241 - val_mean_absolute_error: 0.3241 - val_mean_squared_error: 0.1999\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 72us/sample - loss: 0.4168 - mean_absolute_error: 0.4168 - mean_squared_error: 0.3040 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_mean_squared_error: 0.2057\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.4141 - mean_absolute_error: 0.4141 - mean_squared_error: 0.2989 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2109\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.4125 - mean_absolute_error: 0.4125 - mean_squared_error: 0.2967 - val_loss: 0.3240 - val_mean_absolute_error: 0.3240 - val_mean_squared_error: 0.2010\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.4124 - mean_absolute_error: 0.4124 - mean_squared_error: 0.2961 - val_loss: 0.3248 - val_mean_absolute_error: 0.3248 - val_mean_squared_error: 0.1981\n",
      "NN2 dropout=0.4\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 1.3730 - mean_absolute_error: 1.3730 - mean_squared_error: 3.6861 - val_loss: 0.4490 - val_mean_absolute_error: 0.4490 - val_mean_squared_error: 0.3570\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.5263 - mean_absolute_error: 0.5263 - mean_squared_error: 0.4645 - val_loss: 0.3473 - val_mean_absolute_error: 0.3473 - val_mean_squared_error: 0.2201\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 58us/sample - loss: 0.4733 - mean_absolute_error: 0.4733 - mean_squared_error: 0.3827 - val_loss: 0.3356 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.2115\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.4571 - mean_absolute_error: 0.4571 - mean_squared_error: 0.3588 - val_loss: 0.3346 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.2106\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.4502 - mean_absolute_error: 0.4502 - mean_squared_error: 0.3480 - val_loss: 0.3394 - val_mean_absolute_error: 0.3394 - val_mean_squared_error: 0.2130\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.4466 - mean_absolute_error: 0.4466 - mean_squared_error: 0.3432 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_mean_squared_error: 0.2052\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 55us/sample - loss: 0.4439 - mean_absolute_error: 0.4439 - mean_squared_error: 0.3384 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2050\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.4416 - mean_absolute_error: 0.4416 - mean_squared_error: 0.3355 - val_loss: 0.3310 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4383 - mean_absolute_error: 0.4383 - mean_squared_error: 0.3314 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2147\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4370 - mean_absolute_error: 0.4370 - mean_squared_error: 0.3327 - val_loss: 0.3262 - val_mean_absolute_error: 0.3262 - val_mean_squared_error: 0.2066\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4355 - mean_absolute_error: 0.4355 - mean_squared_error: 0.3264 - val_loss: 0.3280 - val_mean_absolute_error: 0.3280 - val_mean_squared_error: 0.2103\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4346 - mean_absolute_error: 0.4346 - mean_squared_error: 0.3250 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2061\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4315 - mean_absolute_error: 0.4315 - mean_squared_error: 0.3227 - val_loss: 0.3349 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.2042\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.4295 - mean_absolute_error: 0.4295 - mean_squared_error: 0.3195 - val_loss: 0.3250 - val_mean_absolute_error: 0.3250 - val_mean_squared_error: 0.2045\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4267 - mean_absolute_error: 0.4267 - mean_squared_error: 0.3155 - val_loss: 0.3256 - val_mean_absolute_error: 0.3256 - val_mean_squared_error: 0.2095\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.4268 - mean_absolute_error: 0.4268 - mean_squared_error: 0.3165 - val_loss: 0.3329 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2009\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4229 - mean_absolute_error: 0.4229 - mean_squared_error: 0.3118 - val_loss: 0.3322 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.2002\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.4219 - mean_absolute_error: 0.4219 - mean_squared_error: 0.3106 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2106\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4214 - mean_absolute_error: 0.4214 - mean_squared_error: 0.3090 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2101\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.4191 - mean_absolute_error: 0.4191 - mean_squared_error: 0.3067 - val_loss: 0.3285 - val_mean_absolute_error: 0.3285 - val_mean_squared_error: 0.2058\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4144 - mean_absolute_error: 0.4144 - mean_squared_error: 0.3025 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_mean_squared_error: 0.2026\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4139 - mean_absolute_error: 0.4139 - mean_squared_error: 0.2999 - val_loss: 0.3252 - val_mean_absolute_error: 0.3252 - val_mean_squared_error: 0.1984\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.4155 - mean_absolute_error: 0.4155 - mean_squared_error: 0.3002 - val_loss: 0.3226 - val_mean_absolute_error: 0.3226 - val_mean_squared_error: 0.2006\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.4106 - mean_absolute_error: 0.4106 - mean_squared_error: 0.2967 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234 - val_mean_squared_error: 0.2056\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.4100 - mean_absolute_error: 0.4100 - mean_squared_error: 0.2957 - val_loss: 0.3237 - val_mean_absolute_error: 0.3237 - val_mean_squared_error: 0.2080\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.4085 - mean_absolute_error: 0.4085 - mean_squared_error: 0.2945 - val_loss: 0.3222 - val_mean_absolute_error: 0.3222 - val_mean_squared_error: 0.2009\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.4050 - mean_absolute_error: 0.4050 - mean_squared_error: 0.2908 - val_loss: 0.3247 - val_mean_absolute_error: 0.3247 - val_mean_squared_error: 0.1988\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4054 - mean_absolute_error: 0.4054 - mean_squared_error: 0.2895 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224 - val_mean_squared_error: 0.2048\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.4057 - mean_absolute_error: 0.4057 - mean_squared_error: 0.2908 - val_loss: 0.3236 - val_mean_absolute_error: 0.3236 - val_mean_squared_error: 0.2002\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.4012 - mean_absolute_error: 0.4012 - mean_squared_error: 0.2846 - val_loss: 0.3357 - val_mean_absolute_error: 0.3357 - val_mean_squared_error: 0.2243\n",
      "NN3 dropout=0.4\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 3.1115 - mean_absolute_error: 3.1115 - mean_squared_error: 11.9799 - val_loss: 1.1071 - val_mean_absolute_error: 1.1071 - val_mean_squared_error: 2.0044\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 1.0675 - mean_absolute_error: 1.0675 - mean_squared_error: 1.7667 - val_loss: 0.7939 - val_mean_absolute_error: 0.7939 - val_mean_squared_error: 0.9949\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.9041 - mean_absolute_error: 0.9041 - mean_squared_error: 1.2828 - val_loss: 0.6575 - val_mean_absolute_error: 0.6575 - val_mean_squared_error: 0.6882\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.7998 - mean_absolute_error: 0.7998 - mean_squared_error: 1.0179 - val_loss: 0.5269 - val_mean_absolute_error: 0.5269 - val_mean_squared_error: 0.4708\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.7195 - mean_absolute_error: 0.7195 - mean_squared_error: 0.8366 - val_loss: 0.4166 - val_mean_absolute_error: 0.4166 - val_mean_squared_error: 0.3166\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.6678 - mean_absolute_error: 0.6678 - mean_squared_error: 0.7266 - val_loss: 0.3734 - val_mean_absolute_error: 0.3734 - val_mean_squared_error: 0.2678\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.6502 - mean_absolute_error: 0.6502 - mean_squared_error: 0.6912 - val_loss: 0.3521 - val_mean_absolute_error: 0.3521 - val_mean_squared_error: 0.2399\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.6318 - mean_absolute_error: 0.6318 - mean_squared_error: 0.6513 - val_loss: 0.3421 - val_mean_absolute_error: 0.3421 - val_mean_squared_error: 0.2241\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.6228 - mean_absolute_error: 0.6228 - mean_squared_error: 0.6344 - val_loss: 0.3390 - val_mean_absolute_error: 0.3390 - val_mean_squared_error: 0.2263\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.6138 - mean_absolute_error: 0.6138 - mean_squared_error: 0.6164 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.2153\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.6071 - mean_absolute_error: 0.6071 - mean_squared_error: 0.6105 - val_loss: 0.3319 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2143\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.6031 - mean_absolute_error: 0.6031 - mean_squared_error: 0.5993 - val_loss: 0.3385 - val_mean_absolute_error: 0.3385 - val_mean_squared_error: 0.2253\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5948 - mean_absolute_error: 0.5948 - mean_squared_error: 0.5860 - val_loss: 0.3292 - val_mean_absolute_error: 0.3292 - val_mean_squared_error: 0.2126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.5883 - mean_absolute_error: 0.5883 - mean_squared_error: 0.5734 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_mean_squared_error: 0.2091\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.5853 - mean_absolute_error: 0.5853 - mean_squared_error: 0.5666 - val_loss: 0.3310 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2142\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5742 - mean_absolute_error: 0.5742 - mean_squared_error: 0.5434 - val_loss: 0.3301 - val_mean_absolute_error: 0.3301 - val_mean_squared_error: 0.2123\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5681 - mean_absolute_error: 0.5681 - mean_squared_error: 0.5351 - val_loss: 0.3317 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2211\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5600 - mean_absolute_error: 0.5600 - mean_squared_error: 0.5230 - val_loss: 0.3296 - val_mean_absolute_error: 0.3296 - val_mean_squared_error: 0.2145\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.5546 - mean_absolute_error: 0.5546 - mean_squared_error: 0.5112 - val_loss: 0.3353 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.2207\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5525 - mean_absolute_error: 0.5525 - mean_squared_error: 0.5084 - val_loss: 0.3266 - val_mean_absolute_error: 0.3266 - val_mean_squared_error: 0.2082\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 22us/sample - loss: 0.5434 - mean_absolute_error: 0.5434 - mean_squared_error: 0.4923 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.2094\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.5386 - mean_absolute_error: 0.5386 - mean_squared_error: 0.4855 - val_loss: 0.3262 - val_mean_absolute_error: 0.3262 - val_mean_squared_error: 0.2079\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.5310 - mean_absolute_error: 0.5310 - mean_squared_error: 0.4721 - val_loss: 0.3266 - val_mean_absolute_error: 0.3266 - val_mean_squared_error: 0.2054\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.5199 - mean_absolute_error: 0.5199 - mean_squared_error: 0.4538 - val_loss: 0.3333 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.2194\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5159 - mean_absolute_error: 0.5159 - mean_squared_error: 0.4472 - val_loss: 0.3253 - val_mean_absolute_error: 0.3253 - val_mean_squared_error: 0.2073\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.5058 - mean_absolute_error: 0.5058 - mean_squared_error: 0.4295 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2138\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 21us/sample - loss: 0.5019 - mean_absolute_error: 0.5019 - mean_squared_error: 0.4254 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2084\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 21us/sample - loss: 0.4959 - mean_absolute_error: 0.4959 - mean_squared_error: 0.4180 - val_loss: 0.3295 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.2161\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.4869 - mean_absolute_error: 0.4869 - mean_squared_error: 0.4034 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2085\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.4800 - mean_absolute_error: 0.4800 - mean_squared_error: 0.3950 - val_loss: 0.3304 - val_mean_absolute_error: 0.3304 - val_mean_squared_error: 0.2159\n",
      "RESULTS ----- Dropout = 0.4-------\n",
      "NN1: MSE = 0.1931543244988066, MAE = 0.3233897626860744, R2 = 0.5760288911849756\n",
      "NN2: MSE = 0.2169428262478494, MAE = 0.3292033624218335, R2 = 0.5238134541774954\n",
      "NN3: MSE = 0.20769122459250147, MAE = 0.3292033624218335, R2 = 0.5441205936749443\n",
      "0.5-Epochs=30-TIME=1586777159\n",
      "NN1 dropout=0.5\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 3s 85us/sample - loss: 1.1305 - mean_absolute_error: 1.1305 - mean_squared_error: 2.7604 - val_loss: 0.5395 - val_mean_absolute_error: 0.5395 - val_mean_squared_error: 0.4549\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.6500 - mean_absolute_error: 0.6500 - mean_squared_error: 0.6795 - val_loss: 0.4743 - val_mean_absolute_error: 0.4743 - val_mean_squared_error: 0.3717\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.5472 - mean_absolute_error: 0.5472 - mean_squared_error: 0.4968 - val_loss: 0.3585 - val_mean_absolute_error: 0.3585 - val_mean_squared_error: 0.2348\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.5169 - mean_absolute_error: 0.5169 - mean_squared_error: 0.4444 - val_loss: 0.3472 - val_mean_absolute_error: 0.3472 - val_mean_squared_error: 0.2264\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.5096 - mean_absolute_error: 0.5096 - mean_squared_error: 0.4347 - val_loss: 0.3435 - val_mean_absolute_error: 0.3435 - val_mean_squared_error: 0.2262\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.5055 - mean_absolute_error: 0.5055 - mean_squared_error: 0.4274 - val_loss: 0.3449 - val_mean_absolute_error: 0.3449 - val_mean_squared_error: 0.2146\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.5004 - mean_absolute_error: 0.5004 - mean_squared_error: 0.4222 - val_loss: 0.3448 - val_mean_absolute_error: 0.3448 - val_mean_squared_error: 0.2263\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.5001 - mean_absolute_error: 0.5001 - mean_squared_error: 0.4200 - val_loss: 0.3395 - val_mean_absolute_error: 0.3395 - val_mean_squared_error: 0.2159\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.4982 - mean_absolute_error: 0.4982 - mean_squared_error: 0.4164 - val_loss: 0.3422 - val_mean_absolute_error: 0.3422 - val_mean_squared_error: 0.2144\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.4899 - mean_absolute_error: 0.4899 - mean_squared_error: 0.4029 - val_loss: 0.3342 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.2116\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.4919 - mean_absolute_error: 0.4919 - mean_squared_error: 0.4061 - val_loss: 0.3414 - val_mean_absolute_error: 0.3414 - val_mean_squared_error: 0.2123\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 2s 64us/sample - loss: 0.4851 - mean_absolute_error: 0.4851 - mean_squared_error: 0.3976 - val_loss: 0.3334 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.2145\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 94us/sample - loss: 0.4802 - mean_absolute_error: 0.4802 - mean_squared_error: 0.3885 - val_loss: 0.3361 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.2201\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.4778 - mean_absolute_error: 0.4778 - mean_squared_error: 0.3841 - val_loss: 0.3366 - val_mean_absolute_error: 0.3366 - val_mean_squared_error: 0.2114\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.4748 - mean_absolute_error: 0.4748 - mean_squared_error: 0.3789 - val_loss: 0.3328 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.2133\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.4714 - mean_absolute_error: 0.4714 - mean_squared_error: 0.3759 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.2222\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4711 - mean_absolute_error: 0.4711 - mean_squared_error: 0.3761 - val_loss: 0.3307 - val_mean_absolute_error: 0.3307 - val_mean_squared_error: 0.2150\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4658 - mean_absolute_error: 0.4658 - mean_squared_error: 0.3681 - val_loss: 0.3417 - val_mean_absolute_error: 0.3417 - val_mean_squared_error: 0.2277\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.4661 - mean_absolute_error: 0.4661 - mean_squared_error: 0.3702 - val_loss: 0.3384 - val_mean_absolute_error: 0.3384 - val_mean_squared_error: 0.2067\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.4586 - mean_absolute_error: 0.4586 - mean_squared_error: 0.3590 - val_loss: 0.3340 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.2065\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.4571 - mean_absolute_error: 0.4571 - mean_squared_error: 0.3573 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.2207\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4530 - mean_absolute_error: 0.4530 - mean_squared_error: 0.3531 - val_loss: 0.3297 - val_mean_absolute_error: 0.3297 - val_mean_squared_error: 0.2021\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 65us/sample - loss: 0.4518 - mean_absolute_error: 0.4518 - mean_squared_error: 0.3487 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2118\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4533 - mean_absolute_error: 0.4533 - mean_squared_error: 0.3525 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2045\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4477 - mean_absolute_error: 0.4477 - mean_squared_error: 0.3455 - val_loss: 0.3291 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2150\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4419 - mean_absolute_error: 0.4419 - mean_squared_error: 0.3358 - val_loss: 0.3282 - val_mean_absolute_error: 0.3282 - val_mean_squared_error: 0.2069\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.4415 - mean_absolute_error: 0.4415 - mean_squared_error: 0.3351 - val_loss: 0.3271 - val_mean_absolute_error: 0.3271 - val_mean_squared_error: 0.2074\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.4360 - mean_absolute_error: 0.4360 - mean_squared_error: 0.3270 - val_loss: 0.3263 - val_mean_absolute_error: 0.3263 - val_mean_squared_error: 0.2069\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4344 - mean_absolute_error: 0.4344 - mean_squared_error: 0.3247 - val_loss: 0.3319 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2176\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.4351 - mean_absolute_error: 0.4351 - mean_squared_error: 0.3264 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2121\n",
      "NN2 dropout=0.5\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 6s 180us/sample - loss: 1.4108 - mean_absolute_error: 1.4108 - mean_squared_error: 3.7934 - val_loss: 0.4853 - val_mean_absolute_error: 0.4853 - val_mean_squared_error: 0.3912\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.5824 - mean_absolute_error: 0.5824 - mean_squared_error: 0.5615 - val_loss: 0.3504 - val_mean_absolute_error: 0.3504 - val_mean_squared_error: 0.2301\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 87us/sample - loss: 0.5182 - mean_absolute_error: 0.5182 - mean_squared_error: 0.4504 - val_loss: 0.3471 - val_mean_absolute_error: 0.3471 - val_mean_squared_error: 0.2178\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.5059 - mean_absolute_error: 0.5059 - mean_squared_error: 0.4297 - val_loss: 0.3397 - val_mean_absolute_error: 0.3397 - val_mean_squared_error: 0.2196\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.4943 - mean_absolute_error: 0.4943 - mean_squared_error: 0.4125 - val_loss: 0.3354 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.2118\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.4899 - mean_absolute_error: 0.4899 - mean_squared_error: 0.4055 - val_loss: 0.3325 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.2086\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4864 - mean_absolute_error: 0.4864 - mean_squared_error: 0.3999 - val_loss: 0.3440 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.2108\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4834 - mean_absolute_error: 0.4834 - mean_squared_error: 0.3960 - val_loss: 0.3293 - val_mean_absolute_error: 0.3293 - val_mean_squared_error: 0.2104\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 4s 136us/sample - loss: 0.4800 - mean_absolute_error: 0.4800 - mean_squared_error: 0.3902 - val_loss: 0.3334 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.2089\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 3s 86us/sample - loss: 0.4792 - mean_absolute_error: 0.4792 - mean_squared_error: 0.3901 - val_loss: 0.3307 - val_mean_absolute_error: 0.3307 - val_mean_squared_error: 0.2113\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.4736 - mean_absolute_error: 0.4736 - mean_squared_error: 0.3801 - val_loss: 0.3291 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2135\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 3s 86us/sample - loss: 0.4743 - mean_absolute_error: 0.4743 - mean_squared_error: 0.3802 - val_loss: 0.3318 - val_mean_absolute_error: 0.3318 - val_mean_squared_error: 0.2153\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.4697 - mean_absolute_error: 0.4697 - mean_squared_error: 0.3754 - val_loss: 0.3336 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.2125\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 80us/sample - loss: 0.4603 - mean_absolute_error: 0.4603 - mean_squared_error: 0.3628 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2045\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.4634 - mean_absolute_error: 0.4634 - mean_squared_error: 0.3674 - val_loss: 0.3298 - val_mean_absolute_error: 0.3298 - val_mean_squared_error: 0.2072\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.4595 - mean_absolute_error: 0.4595 - mean_squared_error: 0.3607 - val_loss: 0.3379 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.2068\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.4543 - mean_absolute_error: 0.4543 - mean_squared_error: 0.3540 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2023\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 5s 152us/sample - loss: 0.4521 - mean_absolute_error: 0.4521 - mean_squared_error: 0.3511 - val_loss: 0.3296 - val_mean_absolute_error: 0.3296 - val_mean_squared_error: 0.2036\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.4517 - mean_absolute_error: 0.4517 - mean_squared_error: 0.3477 - val_loss: 0.3298 - val_mean_absolute_error: 0.3298 - val_mean_squared_error: 0.2059\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 3s 89us/sample - loss: 0.4437 - mean_absolute_error: 0.4437 - mean_squared_error: 0.3409 - val_loss: 0.3407 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.2060\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 3s 85us/sample - loss: 0.4456 - mean_absolute_error: 0.4456 - mean_squared_error: 0.3415 - val_loss: 0.3281 - val_mean_absolute_error: 0.3281 - val_mean_squared_error: 0.2123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4416 - mean_absolute_error: 0.4416 - mean_squared_error: 0.3383 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2106\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.4376 - mean_absolute_error: 0.4376 - mean_squared_error: 0.3313 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2001\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4367 - mean_absolute_error: 0.4367 - mean_squared_error: 0.3313 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2049\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4345 - mean_absolute_error: 0.4345 - mean_squared_error: 0.3257 - val_loss: 0.3293 - val_mean_absolute_error: 0.3293 - val_mean_squared_error: 0.2024\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.4293 - mean_absolute_error: 0.4293 - mean_squared_error: 0.3204 - val_loss: 0.3244 - val_mean_absolute_error: 0.3244 - val_mean_squared_error: 0.2042\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4261 - mean_absolute_error: 0.4261 - mean_squared_error: 0.3156 - val_loss: 0.3266 - val_mean_absolute_error: 0.3266 - val_mean_squared_error: 0.1998\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 35us/sample - loss: 0.4261 - mean_absolute_error: 0.4261 - mean_squared_error: 0.3151 - val_loss: 0.3254 - val_mean_absolute_error: 0.3254 - val_mean_squared_error: 0.2055\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.4221 - mean_absolute_error: 0.4221 - mean_squared_error: 0.3111 - val_loss: 0.3251 - val_mean_absolute_error: 0.3251 - val_mean_squared_error: 0.2008\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.4231 - mean_absolute_error: 0.4231 - mean_squared_error: 0.3127 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2045\n",
      "NN3 dropout=0.5\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 3.0502 - mean_absolute_error: 3.0502 - mean_squared_error: 11.5875 - val_loss: 1.1302 - val_mean_absolute_error: 1.1302 - val_mean_squared_error: 2.0719\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 21us/sample - loss: 1.1454 - mean_absolute_error: 1.1454 - mean_squared_error: 2.0283 - val_loss: 0.8067 - val_mean_absolute_error: 0.8067 - val_mean_squared_error: 1.0336\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 95us/sample - loss: 0.9772 - mean_absolute_error: 0.9772 - mean_squared_error: 1.5012 - val_loss: 0.6632 - val_mean_absolute_error: 0.6632 - val_mean_squared_error: 0.7097\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.8855 - mean_absolute_error: 0.8855 - mean_squared_error: 1.2413 - val_loss: 0.5392 - val_mean_absolute_error: 0.5392 - val_mean_squared_error: 0.4942\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.8149 - mean_absolute_error: 0.8149 - mean_squared_error: 1.0545 - val_loss: 0.4533 - val_mean_absolute_error: 0.4533 - val_mean_squared_error: 0.3699\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.7754 - mean_absolute_error: 0.7754 - mean_squared_error: 0.9632 - val_loss: 0.3978 - val_mean_absolute_error: 0.3978 - val_mean_squared_error: 0.2973\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.7441 - mean_absolute_error: 0.7441 - mean_squared_error: 0.8914 - val_loss: 0.3673 - val_mean_absolute_error: 0.3673 - val_mean_squared_error: 0.2579\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.7251 - mean_absolute_error: 0.7251 - mean_squared_error: 0.8490 - val_loss: 0.3614 - val_mean_absolute_error: 0.3614 - val_mean_squared_error: 0.2548\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.7184 - mean_absolute_error: 0.7184 - mean_squared_error: 0.8325 - val_loss: 0.3481 - val_mean_absolute_error: 0.3481 - val_mean_squared_error: 0.2369\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.7038 - mean_absolute_error: 0.7038 - mean_squared_error: 0.8025 - val_loss: 0.3427 - val_mean_absolute_error: 0.3427 - val_mean_squared_error: 0.2327\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.6927 - mean_absolute_error: 0.6927 - mean_squared_error: 0.7785 - val_loss: 0.3384 - val_mean_absolute_error: 0.3384 - val_mean_squared_error: 0.2263\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.6789 - mean_absolute_error: 0.6789 - mean_squared_error: 0.7488 - val_loss: 0.3407 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.2292\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.6730 - mean_absolute_error: 0.6730 - mean_squared_error: 0.7409 - val_loss: 0.3371 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.2242\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.6633 - mean_absolute_error: 0.6633 - mean_squared_error: 0.7170 - val_loss: 0.3411 - val_mean_absolute_error: 0.3411 - val_mean_squared_error: 0.2311\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.6567 - mean_absolute_error: 0.6567 - mean_squared_error: 0.7044 - val_loss: 0.3372 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.2277\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.6495 - mean_absolute_error: 0.6495 - mean_squared_error: 0.6888 - val_loss: 0.3389 - val_mean_absolute_error: 0.3389 - val_mean_squared_error: 0.2279\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.6341 - mean_absolute_error: 0.6341 - mean_squared_error: 0.6594 - val_loss: 0.3364 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.2243\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.6285 - mean_absolute_error: 0.6285 - mean_squared_error: 0.6495 - val_loss: 0.3323 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.2186\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 19us/sample - loss: 0.6177 - mean_absolute_error: 0.6177 - mean_squared_error: 0.6261 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.2195\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 21us/sample - loss: 0.6087 - mean_absolute_error: 0.6087 - mean_squared_error: 0.6123 - val_loss: 0.3390 - val_mean_absolute_error: 0.3390 - val_mean_squared_error: 0.2290\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.6011 - mean_absolute_error: 0.6011 - mean_squared_error: 0.5952 - val_loss: 0.3359 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.2232\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.5866 - mean_absolute_error: 0.5866 - mean_squared_error: 0.5711 - val_loss: 0.3334 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.2184\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5749 - mean_absolute_error: 0.5749 - mean_squared_error: 0.5476 - val_loss: 0.3341 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2203\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5668 - mean_absolute_error: 0.5668 - mean_squared_error: 0.5368 - val_loss: 0.3321 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.2196\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.5538 - mean_absolute_error: 0.5538 - mean_squared_error: 0.5136 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_mean_squared_error: 0.2072\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5442 - mean_absolute_error: 0.5442 - mean_squared_error: 0.5010 - val_loss: 0.3306 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.2155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.5352 - mean_absolute_error: 0.5352 - mean_squared_error: 0.4852 - val_loss: 0.3321 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.2146\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.5273 - mean_absolute_error: 0.5273 - mean_squared_error: 0.4685 - val_loss: 0.3318 - val_mean_absolute_error: 0.3318 - val_mean_squared_error: 0.2175\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.5178 - mean_absolute_error: 0.5178 - mean_squared_error: 0.4536 - val_loss: 0.3346 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.2214\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.5049 - mean_absolute_error: 0.5049 - mean_squared_error: 0.4376 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_mean_squared_error: 0.2086\n",
      "RESULTS ----- Dropout = 0.5-------\n",
      "NN1: MSE = 0.2052009510812691, MAE = 0.3273631129222319, R2 = 0.5495867100797903\n",
      "NN2: MSE = 0.1979309458446313, MAE = 0.32674108750860487, R2 = 0.5655442724551923\n",
      "NN3: MSE = 0.20297688477292725, MAE = 0.32674108750860487, R2 = 0.554468505303752\n",
      "0.6-Epochs=30-TIME=1586777345\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "NN1 dropout=0.6\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 167us/sample - loss: 1.1975 - mean_absolute_error: 1.1975 - mean_squared_error: 2.9459 - val_loss: 0.5403 - val_mean_absolute_error: 0.5403 - val_mean_squared_error: 0.4591\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 4s 128us/sample - loss: 0.6964 - mean_absolute_error: 0.6964 - mean_squared_error: 0.7734 - val_loss: 0.5342 - val_mean_absolute_error: 0.5342 - val_mean_squared_error: 0.4608\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 118us/sample - loss: 0.6434 - mean_absolute_error: 0.6434 - mean_squared_error: 0.6724 - val_loss: 0.4012 - val_mean_absolute_error: 0.4012 - val_mean_squared_error: 0.2740\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 4s 116us/sample - loss: 0.5879 - mean_absolute_error: 0.5879 - mean_squared_error: 0.5690 - val_loss: 0.3590 - val_mean_absolute_error: 0.3590 - val_mean_squared_error: 0.2391\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 5s 153us/sample - loss: 0.5767 - mean_absolute_error: 0.5767 - mean_squared_error: 0.5449 - val_loss: 0.3744 - val_mean_absolute_error: 0.3744 - val_mean_squared_error: 0.2477\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 4s 136us/sample - loss: 0.5749 - mean_absolute_error: 0.5749 - mean_squared_error: 0.5451 - val_loss: 0.3596 - val_mean_absolute_error: 0.3596 - val_mean_squared_error: 0.2427\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 4s 131us/sample - loss: 0.5601 - mean_absolute_error: 0.5601 - mean_squared_error: 0.5180 - val_loss: 0.3539 - val_mean_absolute_error: 0.3539 - val_mean_squared_error: 0.2316\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 4s 133us/sample - loss: 0.5612 - mean_absolute_error: 0.5612 - mean_squared_error: 0.5215 - val_loss: 0.3524 - val_mean_absolute_error: 0.3524 - val_mean_squared_error: 0.2340\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 4s 117us/sample - loss: 0.5540 - mean_absolute_error: 0.5540 - mean_squared_error: 0.5078 - val_loss: 0.3493 - val_mean_absolute_error: 0.3493 - val_mean_squared_error: 0.2278\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.5498 - mean_absolute_error: 0.5498 - mean_squared_error: 0.5026 - val_loss: 0.3463 - val_mean_absolute_error: 0.3463 - val_mean_squared_error: 0.2277\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 6s 202us/sample - loss: 0.5477 - mean_absolute_error: 0.5477 - mean_squared_error: 0.4954 - val_loss: 0.3498 - val_mean_absolute_error: 0.3498 - val_mean_squared_error: 0.2316\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 4s 136us/sample - loss: 0.5400 - mean_absolute_error: 0.5400 - mean_squared_error: 0.4840 - val_loss: 0.3402 - val_mean_absolute_error: 0.3402 - val_mean_squared_error: 0.2200\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 109us/sample - loss: 0.5344 - mean_absolute_error: 0.5344 - mean_squared_error: 0.4711 - val_loss: 0.3436 - val_mean_absolute_error: 0.3436 - val_mean_squared_error: 0.2237\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 4s 115us/sample - loss: 0.5303 - mean_absolute_error: 0.5303 - mean_squared_error: 0.4692 - val_loss: 0.3496 - val_mean_absolute_error: 0.3496 - val_mean_squared_error: 0.2249\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 4s 124us/sample - loss: 0.5248 - mean_absolute_error: 0.5248 - mean_squared_error: 0.4584 - val_loss: 0.3428 - val_mean_absolute_error: 0.3428 - val_mean_squared_error: 0.2211\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.5246 - mean_absolute_error: 0.5246 - mean_squared_error: 0.4574 - val_loss: 0.3386 - val_mean_absolute_error: 0.3386 - val_mean_squared_error: 0.2168\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 5s 160us/sample - loss: 0.5160 - mean_absolute_error: 0.5160 - mean_squared_error: 0.4480 - val_loss: 0.3400 - val_mean_absolute_error: 0.3400 - val_mean_squared_error: 0.2190\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 4s 133us/sample - loss: 0.5138 - mean_absolute_error: 0.5138 - mean_squared_error: 0.4420 - val_loss: 0.3451 - val_mean_absolute_error: 0.3451 - val_mean_squared_error: 0.2178\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 4s 129us/sample - loss: 0.5042 - mean_absolute_error: 0.5042 - mean_squared_error: 0.4270 - val_loss: 0.3355 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.2118\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 4s 141us/sample - loss: 0.5009 - mean_absolute_error: 0.5009 - mean_squared_error: 0.4198 - val_loss: 0.3391 - val_mean_absolute_error: 0.3391 - val_mean_squared_error: 0.2177\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 4s 125us/sample - loss: 0.5003 - mean_absolute_error: 0.5003 - mean_squared_error: 0.4190 - val_loss: 0.3376 - val_mean_absolute_error: 0.3376 - val_mean_squared_error: 0.2130\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 5s 166us/sample - loss: 0.4925 - mean_absolute_error: 0.4925 - mean_squared_error: 0.4087 - val_loss: 0.3354 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.2178\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 5s 165us/sample - loss: 0.4907 - mean_absolute_error: 0.4907 - mean_squared_error: 0.4059 - val_loss: 0.3484 - val_mean_absolute_error: 0.3484 - val_mean_squared_error: 0.2141\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 5s 153us/sample - loss: 0.4857 - mean_absolute_error: 0.4857 - mean_squared_error: 0.4007 - val_loss: 0.3351 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.2165\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 5s 154us/sample - loss: 0.4805 - mean_absolute_error: 0.4805 - mean_squared_error: 0.3933 - val_loss: 0.3331 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.2096\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 5s 147us/sample - loss: 0.4759 - mean_absolute_error: 0.4759 - mean_squared_error: 0.3814 - val_loss: 0.3341 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 5s 167us/sample - loss: 0.4706 - mean_absolute_error: 0.4706 - mean_squared_error: 0.3765 - val_loss: 0.3401 - val_mean_absolute_error: 0.3401 - val_mean_squared_error: 0.2255\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 4s 130us/sample - loss: 0.4698 - mean_absolute_error: 0.4698 - mean_squared_error: 0.3751 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.2082\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 4s 131us/sample - loss: 0.4632 - mean_absolute_error: 0.4632 - mean_squared_error: 0.3669 - val_loss: 0.3350 - val_mean_absolute_error: 0.3350 - val_mean_squared_error: 0.2196\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 4s 124us/sample - loss: 0.4603 - mean_absolute_error: 0.4603 - mean_squared_error: 0.3625 - val_loss: 0.3380 - val_mean_absolute_error: 0.3380 - val_mean_squared_error: 0.2218\n",
      "NN2 dropout=0.6\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 3s 105us/sample - loss: 1.4734 - mean_absolute_error: 1.4734 - mean_squared_error: 3.9731 - val_loss: 0.5447 - val_mean_absolute_error: 0.5447 - val_mean_squared_error: 0.4852\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.6712 - mean_absolute_error: 0.6712 - mean_squared_error: 0.7317 - val_loss: 0.3796 - val_mean_absolute_error: 0.3796 - val_mean_squared_error: 0.2616\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 5s 148us/sample - loss: 0.5847 - mean_absolute_error: 0.5847 - mean_squared_error: 0.5618 - val_loss: 0.3572 - val_mean_absolute_error: 0.3572 - val_mean_squared_error: 0.2286\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 3s 87us/sample - loss: 0.5668 - mean_absolute_error: 0.5668 - mean_squared_error: 0.5294 - val_loss: 0.3414 - val_mean_absolute_error: 0.3414 - val_mean_squared_error: 0.2233\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 85us/sample - loss: 0.5602 - mean_absolute_error: 0.5602 - mean_squared_error: 0.5207 - val_loss: 0.3395 - val_mean_absolute_error: 0.3395 - val_mean_squared_error: 0.2126\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.5495 - mean_absolute_error: 0.5495 - mean_squared_error: 0.4984 - val_loss: 0.3377 - val_mean_absolute_error: 0.3377 - val_mean_squared_error: 0.2177\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.5425 - mean_absolute_error: 0.5425 - mean_squared_error: 0.4876 - val_loss: 0.3428 - val_mean_absolute_error: 0.3428 - val_mean_squared_error: 0.2163\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.5358 - mean_absolute_error: 0.5358 - mean_squared_error: 0.4765 - val_loss: 0.3445 - val_mean_absolute_error: 0.3445 - val_mean_squared_error: 0.2160\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.5333 - mean_absolute_error: 0.5333 - mean_squared_error: 0.4722 - val_loss: 0.3445 - val_mean_absolute_error: 0.3445 - val_mean_squared_error: 0.2134\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.5281 - mean_absolute_error: 0.5281 - mean_squared_error: 0.4669 - val_loss: 0.3379 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.2221\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 2s 71us/sample - loss: 0.5277 - mean_absolute_error: 0.5277 - mean_squared_error: 0.4652 - val_loss: 0.3368 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.2124\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 4s 142us/sample - loss: 0.5186 - mean_absolute_error: 0.5186 - mean_squared_error: 0.4492 - val_loss: 0.3417 - val_mean_absolute_error: 0.3417 - val_mean_squared_error: 0.2136\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 3s 93us/sample - loss: 0.5147 - mean_absolute_error: 0.5147 - mean_squared_error: 0.4438 - val_loss: 0.3369 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.2212\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.5100 - mean_absolute_error: 0.5100 - mean_squared_error: 0.4360 - val_loss: 0.3319 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2106\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 93us/sample - loss: 0.5053 - mean_absolute_error: 0.5053 - mean_squared_error: 0.4310 - val_loss: 0.3379 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.2088\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 3s 81us/sample - loss: 0.5034 - mean_absolute_error: 0.5034 - mean_squared_error: 0.4269 - val_loss: 0.3482 - val_mean_absolute_error: 0.3482 - val_mean_squared_error: 0.2152\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.4985 - mean_absolute_error: 0.4985 - mean_squared_error: 0.4205 - val_loss: 0.3335 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.2166\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4928 - mean_absolute_error: 0.4928 - mean_squared_error: 0.4097 - val_loss: 0.3285 - val_mean_absolute_error: 0.3285 - val_mean_squared_error: 0.2099\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.4886 - mean_absolute_error: 0.4886 - mean_squared_error: 0.4016 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2058\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.4864 - mean_absolute_error: 0.4864 - mean_squared_error: 0.3995 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2077\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 5s 158us/sample - loss: 0.4820 - mean_absolute_error: 0.4820 - mean_squared_error: 0.3954 - val_loss: 0.3291 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2052\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 3s 102us/sample - loss: 0.4756 - mean_absolute_error: 0.4756 - mean_squared_error: 0.3839 - val_loss: 0.3282 - val_mean_absolute_error: 0.3282 - val_mean_squared_error: 0.2031\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.4732 - mean_absolute_error: 0.4732 - mean_squared_error: 0.3793 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2102\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.4661 - mean_absolute_error: 0.4661 - mean_squared_error: 0.3709 - val_loss: 0.3306 - val_mean_absolute_error: 0.3306 - val_mean_squared_error: 0.2132\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.4680 - mean_absolute_error: 0.4680 - mean_squared_error: 0.3734 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_mean_squared_error: 0.2070\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4596 - mean_absolute_error: 0.4596 - mean_squared_error: 0.3614 - val_loss: 0.3262 - val_mean_absolute_error: 0.3262 - val_mean_squared_error: 0.2031\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 75us/sample - loss: 0.4534 - mean_absolute_error: 0.4534 - mean_squared_error: 0.3543 - val_loss: 0.3291 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2127\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.4495 - mean_absolute_error: 0.4495 - mean_squared_error: 0.3474 - val_loss: 0.3255 - val_mean_absolute_error: 0.3255 - val_mean_squared_error: 0.2022\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 4s 139us/sample - loss: 0.4445 - mean_absolute_error: 0.4445 - mean_squared_error: 0.3419 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275 - val_mean_squared_error: 0.2113\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 3s 96us/sample - loss: 0.4453 - mean_absolute_error: 0.4453 - mean_squared_error: 0.3423 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.2099\n",
      "NN3 dropout=0.6\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 2s 70us/sample - loss: 2.9976 - mean_absolute_error: 2.9976 - mean_squared_error: 11.2614 - val_loss: 1.1315 - val_mean_absolute_error: 1.1315 - val_mean_squared_error: 2.0692\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - ETA: 0s - loss: 1.2453 - mean_absolute_error: 1.2453 - mean_squared_error: 2.38 - 1s 44us/sample - loss: 1.2427 - mean_absolute_error: 1.2427 - mean_squared_error: 2.3765 - val_loss: 0.8385 - val_mean_absolute_error: 0.8385 - val_mean_squared_error: 1.1159\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 1.0956 - mean_absolute_error: 1.0956 - mean_squared_error: 1.8687 - val_loss: 0.6989 - val_mean_absolute_error: 0.6989 - val_mean_squared_error: 0.7796\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 1.0068 - mean_absolute_error: 1.0068 - mean_squared_error: 1.5965 - val_loss: 0.5962 - val_mean_absolute_error: 0.5962 - val_mean_squared_error: 0.5871\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 43us/sample - loss: 0.9522 - mean_absolute_error: 0.9522 - mean_squared_error: 1.4319 - val_loss: 0.4996 - val_mean_absolute_error: 0.4996 - val_mean_squared_error: 0.4334\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 0.8979 - mean_absolute_error: 0.8979 - mean_squared_error: 1.2772 - val_loss: 0.4403 - val_mean_absolute_error: 0.4403 - val_mean_squared_error: 0.3570\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.8616 - mean_absolute_error: 0.8616 - mean_squared_error: 1.1815 - val_loss: 0.4039 - val_mean_absolute_error: 0.4039 - val_mean_squared_error: 0.3091\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 36us/sample - loss: 0.8464 - mean_absolute_error: 0.8464 - mean_squared_error: 1.1437 - val_loss: 0.3772 - val_mean_absolute_error: 0.3772 - val_mean_squared_error: 0.2730\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.8256 - mean_absolute_error: 0.8256 - mean_squared_error: 1.0842 - val_loss: 0.3638 - val_mean_absolute_error: 0.3638 - val_mean_squared_error: 0.2579\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.8112 - mean_absolute_error: 0.8112 - mean_squared_error: 1.0575 - val_loss: 0.3597 - val_mean_absolute_error: 0.3597 - val_mean_squared_error: 0.2553\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.7966 - mean_absolute_error: 0.7966 - mean_squared_error: 1.0235 - val_loss: 0.3695 - val_mean_absolute_error: 0.3695 - val_mean_squared_error: 0.2726\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.7865 - mean_absolute_error: 0.7865 - mean_squared_error: 0.9982 - val_loss: 0.3634 - val_mean_absolute_error: 0.3634 - val_mean_squared_error: 0.2620\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 19us/sample - loss: 0.7675 - mean_absolute_error: 0.7675 - mean_squared_error: 0.9498 - val_loss: 0.3522 - val_mean_absolute_error: 0.3522 - val_mean_squared_error: 0.2474\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 17us/sample - loss: 0.7575 - mean_absolute_error: 0.7575 - mean_squared_error: 0.9288 - val_loss: 0.3605 - val_mean_absolute_error: 0.3605 - val_mean_squared_error: 0.2568\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 4s 118us/sample - loss: 0.7432 - mean_absolute_error: 0.7432 - mean_squared_error: 0.8939 - val_loss: 0.3466 - val_mean_absolute_error: 0.3466 - val_mean_squared_error: 0.2389\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.7273 - mean_absolute_error: 0.7273 - mean_squared_error: 0.8601 - val_loss: 0.3590 - val_mean_absolute_error: 0.3590 - val_mean_squared_error: 0.2549\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 45us/sample - loss: 0.7158 - mean_absolute_error: 0.7158 - mean_squared_error: 0.8312 - val_loss: 0.3455 - val_mean_absolute_error: 0.3455 - val_mean_squared_error: 0.2367\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 51us/sample - loss: 0.6973 - mean_absolute_error: 0.6973 - mean_squared_error: 0.7944 - val_loss: 0.3393 - val_mean_absolute_error: 0.3393 - val_mean_squared_error: 0.2266\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 48us/sample - loss: 0.6855 - mean_absolute_error: 0.6855 - mean_squared_error: 0.7666 - val_loss: 0.3382 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.2256\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.6680 - mean_absolute_error: 0.6680 - mean_squared_error: 0.7326 - val_loss: 0.3405 - val_mean_absolute_error: 0.3405 - val_mean_squared_error: 0.2311\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.6602 - mean_absolute_error: 0.6602 - mean_squared_error: 0.7151 - val_loss: 0.3394 - val_mean_absolute_error: 0.3394 - val_mean_squared_error: 0.2270\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.6450 - mean_absolute_error: 0.6450 - mean_squared_error: 0.6817 - val_loss: 0.3389 - val_mean_absolute_error: 0.3389 - val_mean_squared_error: 0.2267\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 50us/sample - loss: 0.6290 - mean_absolute_error: 0.6290 - mean_squared_error: 0.6517 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.2224\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.6145 - mean_absolute_error: 0.6145 - mean_squared_error: 0.6211 - val_loss: 0.3312 - val_mean_absolute_error: 0.3312 - val_mean_squared_error: 0.2148\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 49us/sample - loss: 0.6026 - mean_absolute_error: 0.6026 - mean_squared_error: 0.6047 - val_loss: 0.3332 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.2223\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 46us/sample - loss: 0.5889 - mean_absolute_error: 0.5889 - mean_squared_error: 0.5770 - val_loss: 0.3364 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.2232\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.5698 - mean_absolute_error: 0.5698 - mean_squared_error: 0.5491 - val_loss: 0.3386 - val_mean_absolute_error: 0.3386 - val_mean_squared_error: 0.2277\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.5621 - mean_absolute_error: 0.5621 - mean_squared_error: 0.5314 - val_loss: 0.3284 - val_mean_absolute_error: 0.3284 - val_mean_squared_error: 0.2115\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 20us/sample - loss: 0.5428 - mean_absolute_error: 0.5428 - mean_squared_error: 0.4971 - val_loss: 0.3372 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.2269\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 20us/sample - loss: 0.5330 - mean_absolute_error: 0.5330 - mean_squared_error: 0.4802 - val_loss: 0.3347 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.2221\n",
      "RESULTS ----- Dropout = 0.6-------\n",
      "NN1: MSE = 0.21489553184186344, MAE = 0.335860821668374, R2 = 0.5283072374858884\n",
      "NN2: MSE = 0.20376395541366057, MAE = 0.3342262058692374, R2 = 0.5527408959782383\n",
      "NN3: MSE = 0.21554899085960547, MAE = 0.3342262058692374, R2 = 0.5268729038511839\n",
      "0.7-Epochs=30-TIME=1586777604\n",
      "NN1 dropout=0.7\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 5s 170us/sample - loss: 1.3700 - mean_absolute_error: 1.3700 - mean_squared_error: 3.6561 - val_loss: 0.5533 - val_mean_absolute_error: 0.5533 - val_mean_squared_error: 0.4698\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 4s 140us/sample - loss: 0.7656 - mean_absolute_error: 0.7656 - mean_squared_error: 0.9261 - val_loss: 0.5398 - val_mean_absolute_error: 0.5398 - val_mean_squared_error: 0.4577\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 4s 134us/sample - loss: 0.7318 - mean_absolute_error: 0.7318 - mean_squared_error: 0.8504 - val_loss: 0.5392 - val_mean_absolute_error: 0.5392 - val_mean_squared_error: 0.4563\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 3s 105us/sample - loss: 0.7312 - mean_absolute_error: 0.7312 - mean_squared_error: 0.8503 - val_loss: 0.5382 - val_mean_absolute_error: 0.5382 - val_mean_squared_error: 0.4543\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 3s 82us/sample - loss: 0.7249 - mean_absolute_error: 0.7249 - mean_squared_error: 0.8377 - val_loss: 0.5334 - val_mean_absolute_error: 0.5334 - val_mean_squared_error: 0.4490\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.7072 - mean_absolute_error: 0.7072 - mean_squared_error: 0.8033 - val_loss: 0.4206 - val_mean_absolute_error: 0.4206 - val_mean_squared_error: 0.3003\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 53us/sample - loss: 0.6634 - mean_absolute_error: 0.6634 - mean_squared_error: 0.7134 - val_loss: 0.3742 - val_mean_absolute_error: 0.3742 - val_mean_squared_error: 0.2659\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.6501 - mean_absolute_error: 0.6501 - mean_squared_error: 0.6870 - val_loss: 0.3746 - val_mean_absolute_error: 0.3746 - val_mean_squared_error: 0.2563\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 2s 54us/sample - loss: 0.6392 - mean_absolute_error: 0.6392 - mean_squared_error: 0.6630 - val_loss: 0.3737 - val_mean_absolute_error: 0.3737 - val_mean_squared_error: 0.2609\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 5s 173us/sample - loss: 0.6316 - mean_absolute_error: 0.6316 - mean_squared_error: 0.6498 - val_loss: 0.3657 - val_mean_absolute_error: 0.3657 - val_mean_squared_error: 0.2508os\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 4s 123us/sample - loss: 0.6221 - mean_absolute_error: 0.6221 - mean_squared_error: 0.6366 - val_loss: 0.3671 - val_mean_absolute_error: 0.3671 - val_mean_squared_error: 0.2505\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 4s 123us/sample - loss: 0.6228 - mean_absolute_error: 0.6228 - mean_squared_error: 0.6324 - val_loss: 0.3675 - val_mean_absolute_error: 0.3675 - val_mean_squared_error: 0.2511\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 4s 119us/sample - loss: 0.6074 - mean_absolute_error: 0.6074 - mean_squared_error: 0.6078 - val_loss: 0.3673 - val_mean_absolute_error: 0.3673 - val_mean_squared_error: 0.2471\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 3s 108us/sample - loss: 0.5978 - mean_absolute_error: 0.5978 - mean_squared_error: 0.5867 - val_loss: 0.3609 - val_mean_absolute_error: 0.3609 - val_mean_squared_error: 0.2379\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 108us/sample - loss: 0.5945 - mean_absolute_error: 0.5945 - mean_squared_error: 0.5811 - val_loss: 0.3629 - val_mean_absolute_error: 0.3629 - val_mean_squared_error: 0.2491\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 60us/sample - loss: 0.5892 - mean_absolute_error: 0.5892 - mean_squared_error: 0.5682 - val_loss: 0.3595 - val_mean_absolute_error: 0.3595 - val_mean_squared_error: 0.2434\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 56us/sample - loss: 0.5796 - mean_absolute_error: 0.5796 - mean_squared_error: 0.5539 - val_loss: 0.3595 - val_mean_absolute_error: 0.3595 - val_mean_squared_error: 0.2371\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.5725 - mean_absolute_error: 0.5725 - mean_squared_error: 0.5392 - val_loss: 0.3588 - val_mean_absolute_error: 0.3588 - val_mean_squared_error: 0.2402\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 2s 59us/sample - loss: 0.5681 - mean_absolute_error: 0.5681 - mean_squared_error: 0.5309 - val_loss: 0.3573 - val_mean_absolute_error: 0.3573 - val_mean_squared_error: 0.2449\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 2s 57us/sample - loss: 0.5591 - mean_absolute_error: 0.5591 - mean_squared_error: 0.5210 - val_loss: 0.3550 - val_mean_absolute_error: 0.3550 - val_mean_squared_error: 0.2325\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.5529 - mean_absolute_error: 0.5529 - mean_squared_error: 0.5066 - val_loss: 0.3566 - val_mean_absolute_error: 0.3566 - val_mean_squared_error: 0.2381\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.5444 - mean_absolute_error: 0.5444 - mean_squared_error: 0.4923 - val_loss: 0.3470 - val_mean_absolute_error: 0.3470 - val_mean_squared_error: 0.2235\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 2s 68us/sample - loss: 0.5357 - mean_absolute_error: 0.5357 - mean_squared_error: 0.4785 - val_loss: 0.3519 - val_mean_absolute_error: 0.3519 - val_mean_squared_error: 0.2334\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.5330 - mean_absolute_error: 0.5330 - mean_squared_error: 0.4748 - val_loss: 0.3574 - val_mean_absolute_error: 0.3574 - val_mean_squared_error: 0.2442\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.5240 - mean_absolute_error: 0.5240 - mean_squared_error: 0.4605 - val_loss: 0.3556 - val_mean_absolute_error: 0.3556 - val_mean_squared_error: 0.2434\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.5191 - mean_absolute_error: 0.5191 - mean_squared_error: 0.4508 - val_loss: 0.3475 - val_mean_absolute_error: 0.3475 - val_mean_squared_error: 0.2308\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 2s 66us/sample - loss: 0.5119 - mean_absolute_error: 0.5119 - mean_squared_error: 0.4409 - val_loss: 0.3462 - val_mean_absolute_error: 0.3462 - val_mean_squared_error: 0.2294\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 2s 67us/sample - loss: 0.5061 - mean_absolute_error: 0.5061 - mean_squared_error: 0.4314 - val_loss: 0.3477 - val_mean_absolute_error: 0.3477 - val_mean_squared_error: 0.2279\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 2s 61us/sample - loss: 0.5028 - mean_absolute_error: 0.5028 - mean_squared_error: 0.4236 - val_loss: 0.3485 - val_mean_absolute_error: 0.3485 - val_mean_squared_error: 0.2290\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 2s 69us/sample - loss: 0.4949 - mean_absolute_error: 0.4949 - mean_squared_error: 0.4113 - val_loss: 0.3470 - val_mean_absolute_error: 0.3470 - val_mean_squared_error: 0.2198\n",
      "NN2 dropout=0.7\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 6s 191us/sample - loss: 1.5881 - mean_absolute_error: 1.5881 - mean_squared_error: 4.4632 - val_loss: 0.5646 - val_mean_absolute_error: 0.5646 - val_mean_squared_error: 0.5125\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 3s 89us/sample - loss: 0.7544 - mean_absolute_error: 0.7544 - mean_squared_error: 0.9204 - val_loss: 0.4085 - val_mean_absolute_error: 0.4085 - val_mean_squared_error: 0.2883\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 3s 91us/sample - loss: 0.6742 - mean_absolute_error: 0.6742 - mean_squared_error: 0.7350 - val_loss: 0.3663 - val_mean_absolute_error: 0.3663 - val_mean_squared_error: 0.2463\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 2s 76us/sample - loss: 0.6539 - mean_absolute_error: 0.6539 - mean_squared_error: 0.6975 - val_loss: 0.3538 - val_mean_absolute_error: 0.3538 - val_mean_squared_error: 0.2308\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 2s 77us/sample - loss: 0.6355 - mean_absolute_error: 0.6355 - mean_squared_error: 0.6597 - val_loss: 0.3458 - val_mean_absolute_error: 0.3458 - val_mean_squared_error: 0.2279\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 3s 83us/sample - loss: 0.6283 - mean_absolute_error: 0.6283 - mean_squared_error: 0.6446 - val_loss: 0.3494 - val_mean_absolute_error: 0.3494 - val_mean_squared_error: 0.2271\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 2s 73us/sample - loss: 0.6194 - mean_absolute_error: 0.6194 - mean_squared_error: 0.6289 - val_loss: 0.3579 - val_mean_absolute_error: 0.3579 - val_mean_squared_error: 0.2293\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 2s 70us/sample - loss: 0.6136 - mean_absolute_error: 0.6136 - mean_squared_error: 0.6169 - val_loss: 0.3630 - val_mean_absolute_error: 0.3630 - val_mean_squared_error: 0.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.6013 - mean_absolute_error: 0.6013 - mean_squared_error: 0.5928 - val_loss: 0.3432 - val_mean_absolute_error: 0.3432 - val_mean_squared_error: 0.2268\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 4s 137us/sample - loss: 0.5971 - mean_absolute_error: 0.5971 - mean_squared_error: 0.5851 - val_loss: 0.3409 - val_mean_absolute_error: 0.3409 - val_mean_squared_error: 0.2216\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 3s 80us/sample - loss: 0.5897 - mean_absolute_error: 0.5897 - mean_squared_error: 0.5710 - val_loss: 0.3491 - val_mean_absolute_error: 0.3491 - val_mean_squared_error: 0.2206\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 3s 84us/sample - loss: 0.5885 - mean_absolute_error: 0.5885 - mean_squared_error: 0.5679 - val_loss: 0.3440 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.2226\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.5824 - mean_absolute_error: 0.5824 - mean_squared_error: 0.5599 - val_loss: 0.3414 - val_mean_absolute_error: 0.3414 - val_mean_squared_error: 0.2182\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.5743 - mean_absolute_error: 0.5743 - mean_squared_error: 0.5430 - val_loss: 0.3421 - val_mean_absolute_error: 0.3421 - val_mean_squared_error: 0.2241\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 3s 88us/sample - loss: 0.5650 - mean_absolute_error: 0.5650 - mean_squared_error: 0.5282 - val_loss: 0.3440 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.2180\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 2s 78us/sample - loss: 0.5594 - mean_absolute_error: 0.5594 - mean_squared_error: 0.5199 - val_loss: 0.3434 - val_mean_absolute_error: 0.3434 - val_mean_squared_error: 0.2288\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 2s 74us/sample - loss: 0.5492 - mean_absolute_error: 0.5492 - mean_squared_error: 0.5029 - val_loss: 0.3348 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.2125\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 2s 52us/sample - loss: 0.5487 - mean_absolute_error: 0.5487 - mean_squared_error: 0.5015 - val_loss: 0.3379 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.2173\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 42us/sample - loss: 0.5375 - mean_absolute_error: 0.5375 - mean_squared_error: 0.4830 - val_loss: 0.3370 - val_mean_absolute_error: 0.3370 - val_mean_squared_error: 0.2128\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.5358 - mean_absolute_error: 0.5358 - mean_squared_error: 0.4770 - val_loss: 0.3373 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.2118\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 39us/sample - loss: 0.5266 - mean_absolute_error: 0.5266 - mean_squared_error: 0.4656 - val_loss: 0.3330 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.2131\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.5181 - mean_absolute_error: 0.5181 - mean_squared_error: 0.4522 - val_loss: 0.3356 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.2201\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.5114 - mean_absolute_error: 0.5114 - mean_squared_error: 0.4384 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.2203\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 34us/sample - loss: 0.5031 - mean_absolute_error: 0.5031 - mean_squared_error: 0.4276 - val_loss: 0.3329 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2112\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 38us/sample - loss: 0.4968 - mean_absolute_error: 0.4968 - mean_squared_error: 0.4200 - val_loss: 0.3332 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.2076\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 41us/sample - loss: 0.4927 - mean_absolute_error: 0.4927 - mean_squared_error: 0.4109 - val_loss: 0.3371 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.2210\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 37us/sample - loss: 0.4865 - mean_absolute_error: 0.4865 - mean_squared_error: 0.4023 - val_loss: 0.3319 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.2087\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 44us/sample - loss: 0.4777 - mean_absolute_error: 0.4777 - mean_squared_error: 0.3922 - val_loss: 0.3327 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.2074\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 47us/sample - loss: 0.4684 - mean_absolute_error: 0.4684 - mean_squared_error: 0.3751 - val_loss: 0.3317 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.2061\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 48us/sample - loss: 0.4669 - mean_absolute_error: 0.4669 - mean_squared_error: 0.3728 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303 - val_mean_squared_error: 0.2071\n",
      "NN3 dropout=0.7\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 1s 40us/sample - loss: 3.2155 - mean_absolute_error: 3.2155 - mean_squared_error: 12.5268 - val_loss: 1.2026 - val_mean_absolute_error: 1.2026 - val_mean_squared_error: 2.3721\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 1.3719 - mean_absolute_error: 1.3719 - mean_squared_error: 2.8689 - val_loss: 0.8518 - val_mean_absolute_error: 0.8518 - val_mean_squared_error: 1.1795\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 1.2345 - mean_absolute_error: 1.2345 - mean_squared_error: 2.3494 - val_loss: 0.7263 - val_mean_absolute_error: 0.7263 - val_mean_squared_error: 0.8627\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 1.1699 - mean_absolute_error: 1.1699 - mean_squared_error: 2.1281 - val_loss: 0.6416 - val_mean_absolute_error: 0.6416 - val_mean_squared_error: 0.6785\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 1.1116 - mean_absolute_error: 1.1116 - mean_squared_error: 1.9257 - val_loss: 0.5799 - val_mean_absolute_error: 0.5799 - val_mean_squared_error: 0.5727\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 1.0666 - mean_absolute_error: 1.0666 - mean_squared_error: 1.7812 - val_loss: 0.4950 - val_mean_absolute_error: 0.4950 - val_mean_squared_error: 0.4347\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 1.0322 - mean_absolute_error: 1.0322 - mean_squared_error: 1.6776 - val_loss: 0.4675 - val_mean_absolute_error: 0.4675 - val_mean_squared_error: 0.4010\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 1.0074 - mean_absolute_error: 1.0074 - mean_squared_error: 1.5881 - val_loss: 0.4489 - val_mean_absolute_error: 0.4489 - val_mean_squared_error: 0.3740\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.9761 - mean_absolute_error: 0.9761 - mean_squared_error: 1.5087 - val_loss: 0.4153 - val_mean_absolute_error: 0.4153 - val_mean_squared_error: 0.3272\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.9590 - mean_absolute_error: 0.9590 - mean_squared_error: 1.4580 - val_loss: 0.4163 - val_mean_absolute_error: 0.4163 - val_mean_squared_error: 0.3300\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 1s 26us/sample - loss: 0.9430 - mean_absolute_error: 0.9430 - mean_squared_error: 1.4052 - val_loss: 0.3881 - val_mean_absolute_error: 0.3881 - val_mean_squared_error: 0.2889\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.9240 - mean_absolute_error: 0.9240 - mean_squared_error: 1.3612 - val_loss: 0.3866 - val_mean_absolute_error: 0.3866 - val_mean_squared_error: 0.2882\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.9012 - mean_absolute_error: 0.9012 - mean_squared_error: 1.3009 - val_loss: 0.3735 - val_mean_absolute_error: 0.3735 - val_mean_squared_error: 0.2737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.8877 - mean_absolute_error: 0.8877 - mean_squared_error: 1.2582 - val_loss: 0.4141 - val_mean_absolute_error: 0.4141 - val_mean_squared_error: 0.3226\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 1s 25us/sample - loss: 0.8590 - mean_absolute_error: 0.8590 - mean_squared_error: 1.1799 - val_loss: 0.3675 - val_mean_absolute_error: 0.3675 - val_mean_squared_error: 0.2651\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 1s 24us/sample - loss: 0.8380 - mean_absolute_error: 0.8380 - mean_squared_error: 1.1273 - val_loss: 0.3622 - val_mean_absolute_error: 0.3622 - val_mean_squared_error: 0.2592\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 1s 23us/sample - loss: 0.8201 - mean_absolute_error: 0.8201 - mean_squared_error: 1.0785 - val_loss: 0.3766 - val_mean_absolute_error: 0.3766 - val_mean_squared_error: 0.2784\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 1s 29us/sample - loss: 0.8053 - mean_absolute_error: 0.8053 - mean_squared_error: 1.0462 - val_loss: 0.3894 - val_mean_absolute_error: 0.3894 - val_mean_squared_error: 0.2907\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.7821 - mean_absolute_error: 0.7821 - mean_squared_error: 0.9895 - val_loss: 0.3771 - val_mean_absolute_error: 0.3771 - val_mean_squared_error: 0.2760\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.7642 - mean_absolute_error: 0.7642 - mean_squared_error: 0.9453 - val_loss: 0.3708 - val_mean_absolute_error: 0.3708 - val_mean_squared_error: 0.2699\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 1s 28us/sample - loss: 0.7450 - mean_absolute_error: 0.7450 - mean_squared_error: 0.8957 - val_loss: 0.3501 - val_mean_absolute_error: 0.3501 - val_mean_squared_error: 0.2424\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.7248 - mean_absolute_error: 0.7248 - mean_squared_error: 0.8546 - val_loss: 0.3504 - val_mean_absolute_error: 0.3504 - val_mean_squared_error: 0.2404\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 1s 31us/sample - loss: 0.7056 - mean_absolute_error: 0.7056 - mean_squared_error: 0.8088 - val_loss: 0.3630 - val_mean_absolute_error: 0.3630 - val_mean_squared_error: 0.2587\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.6889 - mean_absolute_error: 0.6889 - mean_squared_error: 0.7806 - val_loss: 0.3616 - val_mean_absolute_error: 0.3616 - val_mean_squared_error: 0.2602\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 1s 30us/sample - loss: 0.6698 - mean_absolute_error: 0.6698 - mean_squared_error: 0.7371 - val_loss: 0.3655 - val_mean_absolute_error: 0.3655 - val_mean_squared_error: 0.2618\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 1s 27us/sample - loss: 0.6480 - mean_absolute_error: 0.6480 - mean_squared_error: 0.6927 - val_loss: 0.3617 - val_mean_absolute_error: 0.3617 - val_mean_squared_error: 0.2575\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 1s 33us/sample - loss: 0.6296 - mean_absolute_error: 0.6296 - mean_squared_error: 0.6576 - val_loss: 0.3584 - val_mean_absolute_error: 0.3584 - val_mean_squared_error: 0.2523\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 1s 32us/sample - loss: 0.6107 - mean_absolute_error: 0.6107 - mean_squared_error: 0.6195 - val_loss: 0.3371 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.2274\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 1s 20us/sample - loss: 0.5924 - mean_absolute_error: 0.5924 - mean_squared_error: 0.5885 - val_loss: 0.3389 - val_mean_absolute_error: 0.3389 - val_mean_squared_error: 0.2266\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 1s 22us/sample - loss: 0.5762 - mean_absolute_error: 0.5762 - mean_squared_error: 0.5579 - val_loss: 0.3424 - val_mean_absolute_error: 0.3424 - val_mean_squared_error: 0.2317\n",
      "RESULTS ----- Dropout = 0.7-------\n",
      "NN1: MSE = 0.21325892905503752, MAE = 0.3434928600804041, R2 = 0.5318995582895815\n",
      "NN2: MSE = 0.20089386904547374, MAE = 0.34126153926682606, R2 = 0.559040696425743\n",
      "NN3: MSE = 0.22434703168213438, MAE = 0.34126153926682606, R2 = 0.5075613241979389\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "do_values = []\n",
    "mse_final1 = []\n",
    "mae_final1 = []\n",
    "r2_final1 = []\n",
    "mse_final2 = []\n",
    "mae_final2 = []\n",
    "r2_final2 = []\n",
    "mse_final3 = []\n",
    "mae_final3 = []\n",
    "r2_final3 = []\n",
    "\n",
    "for i in range(1,8):\n",
    "    do_value = i/10\n",
    "    LOGNAME = \"{}-Epochs={}-TIME={}\".format(do_value , EPOCHS, int(time.time()) )\n",
    "    print(LOGNAME)\n",
    "    tensorboard1 = TensorBoard(log_dir='logs/NN/dropouts/NN1-{}'.format(LOGNAME))\n",
    "    tensorboard2 = TensorBoard(log_dir='logs/NN/dropouts/NN2-{}'.format(LOGNAME))\n",
    "    tensorboard3 = TensorBoard(log_dir='logs/NN/dropouts/NN3-{}'.format(LOGNAME))\n",
    "    \n",
    "    NN1_adv = buildNN_adv(X, num_hidden_layers = 4, \n",
    "                          hidden_nodes = 128,\n",
    "                          regularizer=False,\n",
    "                          do = do_value,\n",
    "                          act = 'tanh')\n",
    "    NN2_adv = buildNN_adv(X, num_hidden_layers = 2, \n",
    "                          hidden_nodes = 128, \n",
    "                          regularizer=False,\n",
    "                          do = do_value,\n",
    "                          act = 'tanh')\n",
    "    NN3_adv = buildNN_adv(X, num_hidden_layers = 1, \n",
    "                          hidden_nodes = 32,\n",
    "                          regularizer=False,\n",
    "                          do = do_value,\n",
    "                          act = 'tanh')\n",
    "    \n",
    "    ## Training Nets\n",
    "    print(\"NN1 dropout={}\".format(do_value))\n",
    "    NN1_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard1],\n",
    "            validation_split = 0.2)\n",
    "    print(\"NN2 dropout={}\".format(do_value))\n",
    "    NN2_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard2],\n",
    "            validation_split = 0.2)\n",
    "    print(\"NN3 dropout={}\".format(do_value))\n",
    "    NN3_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard3],\n",
    "            validation_split = 0.2)\n",
    "    \n",
    "    ## Evaluating Nets\n",
    "    mse_1, r2_1, mae_1 = evaluateModel(NN1_adv, X_test, y_test)\n",
    "    mse_2, r2_2, mae_2 = evaluateModel(NN2_adv, X_test, y_test)\n",
    "    mse_3, r2_3, mae_3 = evaluateModel(NN3_adv, X_test, y_test)\n",
    "    \n",
    "    print('RESULTS ----- Dropout = {}-------'.format(do_value))\n",
    "    print('NN1: MSE = {}, MAE = {}, R2 = {}'.format(mse_1,mae_1,r2_1))\n",
    "    print('NN2: MSE = {}, MAE = {}, R2 = {}'.format(mse_2,mae_3,r2_2))\n",
    "    print('NN3: MSE = {}, MAE = {}, R2 = {}'.format(mse_3,mae_3,r2_3))\n",
    "    \n",
    "    ## Recording results in lists\n",
    "    do_values.append(do_value)\n",
    "    mse_final1.append(mse_1)\n",
    "    mae_final1.append(mae_1)\n",
    "    r2_final1.append(r2_1)\n",
    "    mse_final2.append(mse_2)\n",
    "    mae_final2.append(mae_2)\n",
    "    r2_final2.append(r2_2)\n",
    "    mse_final3.append(mse_3)\n",
    "    mae_final3.append(mae_3)\n",
    "    r2_final3.append(r2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df2 = pd.DataFrame({\n",
    "    'Dropout': do_values,\n",
    "    'MSE_NN1': mse_final1,\n",
    "    'MAE_NN1': mae_final1,\n",
    "    'R2_NN1': r2_final1,\n",
    "    'MSE_NN2': mse_final2,\n",
    "    'MAE_NN2': mae_final2,\n",
    "    'R2_NN2': r2_final2,\n",
    "    'MSE_NN3': mse_final3,\n",
    "    'MAE_NN3': mae_final3,\n",
    "    'R2_NN3': r2_final3\n",
    "})\n",
    "\n",
    "result_df2.to_csv('output/results_NN_dropouts.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dropout</th>\n",
       "      <th>MSE_NN1</th>\n",
       "      <th>MAE_NN1</th>\n",
       "      <th>R2_NN1</th>\n",
       "      <th>MSE_NN2</th>\n",
       "      <th>MAE_NN2</th>\n",
       "      <th>R2_NN2</th>\n",
       "      <th>MSE_NN3</th>\n",
       "      <th>MAE_NN3</th>\n",
       "      <th>R2_NN3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.188088</td>\n",
       "      <td>0.314048</td>\n",
       "      <td>0.587149</td>\n",
       "      <td>0.184591</td>\n",
       "      <td>0.313270</td>\n",
       "      <td>0.594824</td>\n",
       "      <td>0.192886</td>\n",
       "      <td>0.317882</td>\n",
       "      <td>0.576617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.188525</td>\n",
       "      <td>0.317429</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>0.186366</td>\n",
       "      <td>0.316387</td>\n",
       "      <td>0.590929</td>\n",
       "      <td>0.191859</td>\n",
       "      <td>0.320603</td>\n",
       "      <td>0.578871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.196201</td>\n",
       "      <td>0.334846</td>\n",
       "      <td>0.569342</td>\n",
       "      <td>0.190619</td>\n",
       "      <td>0.317520</td>\n",
       "      <td>0.581595</td>\n",
       "      <td>0.196032</td>\n",
       "      <td>0.321497</td>\n",
       "      <td>0.569713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.193154</td>\n",
       "      <td>0.323390</td>\n",
       "      <td>0.576029</td>\n",
       "      <td>0.216943</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.523813</td>\n",
       "      <td>0.207691</td>\n",
       "      <td>0.329203</td>\n",
       "      <td>0.544121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.205201</td>\n",
       "      <td>0.327363</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>0.197931</td>\n",
       "      <td>0.326285</td>\n",
       "      <td>0.565544</td>\n",
       "      <td>0.202977</td>\n",
       "      <td>0.326741</td>\n",
       "      <td>0.554469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.214896</td>\n",
       "      <td>0.335861</td>\n",
       "      <td>0.528307</td>\n",
       "      <td>0.203764</td>\n",
       "      <td>0.326412</td>\n",
       "      <td>0.552741</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>0.334226</td>\n",
       "      <td>0.526873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.213259</td>\n",
       "      <td>0.343493</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.200894</td>\n",
       "      <td>0.329107</td>\n",
       "      <td>0.559041</td>\n",
       "      <td>0.224347</td>\n",
       "      <td>0.341262</td>\n",
       "      <td>0.507561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dropout   MSE_NN1   MAE_NN1    R2_NN1   MSE_NN2   MAE_NN2    R2_NN2  \\\n",
       "0      0.1  0.188088  0.314048  0.587149  0.184591  0.313270  0.594824   \n",
       "1      0.2  0.188525  0.317429  0.586190  0.186366  0.316387  0.590929   \n",
       "2      0.3  0.196201  0.334846  0.569342  0.190619  0.317520  0.581595   \n",
       "3      0.4  0.193154  0.323390  0.576029  0.216943  0.334900  0.523813   \n",
       "4      0.5  0.205201  0.327363  0.549587  0.197931  0.326285  0.565544   \n",
       "5      0.6  0.214896  0.335861  0.528307  0.203764  0.326412  0.552741   \n",
       "6      0.7  0.213259  0.343493  0.531900  0.200894  0.329107  0.559041   \n",
       "\n",
       "    MSE_NN3   MAE_NN3    R2_NN3  \n",
       "0  0.192886  0.317882  0.576617  \n",
       "1  0.191859  0.320603  0.578871  \n",
       "2  0.196032  0.321497  0.569713  \n",
       "3  0.207691  0.329203  0.544121  \n",
       "4  0.202977  0.326741  0.554469  \n",
       "5  0.215549  0.334226  0.526873  \n",
       "6  0.224347  0.341262  0.507561  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, we can see that increasing the dropout had negative impact on model performance. So we will choose a dropout of 0.1. Even though small dropout does not seem to have an effect on the numerical results, it is still expected to improve generalization on unseen data; therefore, it will be used in our neural nets.\n",
    "\n",
    "### 3.3 Testing Loss Functions\n",
    "\n",
    "Here we will test the top 3 neural networks from earlier with different loss functions and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error-Epochs=100-TIME=1586809930\n",
      "NN1 with mean_absolute_error\n",
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/100\n",
      "31211/31211 [==============================] - 7s 235us/sample - loss: 0.9662 - mean_absolute_error: 0.9662 - mean_squared_error: 2.2379 - val_loss: 0.5300 - val_mean_absolute_error: 0.5300 - val_mean_squared_error: 0.4453\n",
      "Epoch 2/100\n",
      "31211/31211 [==============================] - 4s 122us/sample - loss: 0.4361 - mean_absolute_error: 0.4361 - mean_squared_error: 0.3341 - val_loss: 0.3362 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.2158\n",
      "Epoch 3/100\n",
      "31211/31211 [==============================] - 4s 125us/sample - loss: 0.3770 - mean_absolute_error: 0.3770 - mean_squared_error: 0.2571 - val_loss: 0.3309 - val_mean_absolute_error: 0.3309 - val_mean_squared_error: 0.2104\n",
      "Epoch 4/100\n",
      "31211/31211 [==============================] - 4s 122us/sample - loss: 0.3672 - mean_absolute_error: 0.3672 - mean_squared_error: 0.2453 - val_loss: 0.3254 - val_mean_absolute_error: 0.3254 - val_mean_squared_error: 0.2041\n",
      "Epoch 5/100\n",
      "31211/31211 [==============================] - 4s 118us/sample - loss: 0.3637 - mean_absolute_error: 0.3637 - mean_squared_error: 0.2409 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.1994\n",
      "Epoch 6/100\n",
      "31211/31211 [==============================] - 6s 181us/sample - loss: 0.3586 - mean_absolute_error: 0.3586 - mean_squared_error: 0.2360 - val_loss: 0.3301 - val_mean_absolute_error: 0.3301 - val_mean_squared_error: 0.1997\n",
      "Epoch 7/100\n",
      "31211/31211 [==============================] - 4s 143us/sample - loss: 0.3559 - mean_absolute_error: 0.3559 - mean_squared_error: 0.2324 - val_loss: 0.3204 - val_mean_absolute_error: 0.3204 - val_mean_squared_error: 0.1952\n",
      "Epoch 8/100\n",
      "31211/31211 [==============================] - 5s 147us/sample - loss: 0.3520 - mean_absolute_error: 0.3520 - mean_squared_error: 0.2279 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205 - val_mean_squared_error: 0.1963\n",
      "Epoch 9/100\n",
      "31211/31211 [==============================] - 4s 134us/sample - loss: 0.3523 - mean_absolute_error: 0.3523 - mean_squared_error: 0.2280 - val_loss: 0.3300 - val_mean_absolute_error: 0.3300 - val_mean_squared_error: 0.2134\n",
      "Epoch 10/100\n",
      "31211/31211 [==============================] - 4s 120us/sample - loss: 0.3515 - mean_absolute_error: 0.3515 - mean_squared_error: 0.2283 - val_loss: 0.3228 - val_mean_absolute_error: 0.3228 - val_mean_squared_error: 0.1969\n",
      "Epoch 11/100\n",
      "29440/31211 [===========================>..] - ETA: 0s - loss: 0.3478 - mean_absolute_error: 0.3478 - mean_squared_error: 0.2242"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "LOSSES = ['mean_absolute_error', 'mean_squared_error', 'mean_squared_logarithmic_error']\n",
    "\n",
    "losses = []\n",
    "mse_final1 = []\n",
    "mae_final1 = []\n",
    "r2_final1 = []\n",
    "mse_final2 = []\n",
    "mae_final2 = []\n",
    "r2_final2 = []\n",
    "mse_final3 = []\n",
    "mae_final3 = []\n",
    "r2_final3 = []\n",
    "\n",
    "for loss in LOSSES:\n",
    "    LOGNAME = \"{}-Epochs={}-TIME={}\".format(loss , EPOCHS, int(time.time()) )\n",
    "    print(LOGNAME)\n",
    "    tensorboard1 = TensorBoard(log_dir='logs/NN/losses/NN1-{}'.format(LOGNAME))\n",
    "    tensorboard2 = TensorBoard(log_dir='logs/NN/losses/NN2-{}'.format(LOGNAME))\n",
    "    tensorboard3 = TensorBoard(log_dir='logs/NN/losses/NN3-{}'.format(LOGNAME))\n",
    "    \n",
    "    NN1_adv = buildNN_adv(X, num_hidden_layers = 4, \n",
    "                          hidden_nodes = 128,\n",
    "                          regularizer=False,\n",
    "                          do = 0.1,\n",
    "                          loss_function = loss,\n",
    "                          act = 'tanh')\n",
    "    NN2_adv = buildNN_adv(X, num_hidden_layers = 2, \n",
    "                          hidden_nodes = 128, \n",
    "                          regularizer=False,\n",
    "                          do = 0.1,\n",
    "                          loss_function = loss,\n",
    "                          act = 'tanh')\n",
    "    NN3_adv = buildNN_adv(X, num_hidden_layers = 1, \n",
    "                          hidden_nodes = 32,\n",
    "                          regularizer=False,\n",
    "                          do = 0.1,\n",
    "                          loss_function = loss,\n",
    "                          act = 'tanh')\n",
    "    \n",
    "    ## Training Nets\n",
    "    print(\"NN1 with {}\".format(loss))\n",
    "    NN1_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard1],\n",
    "            validation_split = 0.2)\n",
    "    print(\"NN2 with {}\".format(loss))\n",
    "    NN2_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard2],\n",
    "            validation_split = 0.2)\n",
    "    print(\"NN3 with {}\".format(loss))\n",
    "    NN3_adv.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "            callbacks = [tensorboard3],\n",
    "            validation_split = 0.2)\n",
    "    \n",
    "    ## Evaluating Nets\n",
    "    mse_1, r2_1, mae_1 = evaluateModel(NN1_adv, X_test, y_test)\n",
    "    mse_2, r2_2, mae_2 = evaluateModel(NN2_adv, X_test, y_test)\n",
    "    mse_3, r2_3, mae_3 = evaluateModel(NN3_adv, X_test, y_test)\n",
    "    \n",
    "    print('RESULTS ----- Loss = {} -------'.format(loss))\n",
    "    print('NN1: MSE = {}, MAE = {}, R2 = {}'.format(mse_1,mae_1,r2_1))\n",
    "    print('NN2: MSE = {}, MAE = {}, R2 = {}'.format(mse_2,mae_3,r2_2))\n",
    "    print('NN3: MSE = {}, MAE = {}, R2 = {}'.format(mse_3,mae_3,r2_3))\n",
    "    \n",
    "    ## Recording results in lists\n",
    "    losses.append(loss)\n",
    "    mse_final1.append(mse_1)\n",
    "    mae_final1.append(mae_1)\n",
    "    r2_final1.append(r2_1)\n",
    "    mse_final2.append(mse_2)\n",
    "    mae_final2.append(mae_2)\n",
    "    r2_final2.append(r2_2)\n",
    "    mse_final3.append(mse_3)\n",
    "    mae_final3.append(mae_3)\n",
    "    r2_final3.append(r2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>MSE_NN1</th>\n",
       "      <th>MAE_NN1</th>\n",
       "      <th>R2_NN1</th>\n",
       "      <th>MSE_NN2</th>\n",
       "      <th>MAE_NN2</th>\n",
       "      <th>R2_NN2</th>\n",
       "      <th>MSE_NN3</th>\n",
       "      <th>MAE_NN3</th>\n",
       "      <th>R2_NN3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.186119</td>\n",
       "      <td>0.318390</td>\n",
       "      <td>0.591471</td>\n",
       "      <td>0.191439</td>\n",
       "      <td>0.316403</td>\n",
       "      <td>0.579793</td>\n",
       "      <td>0.191159</td>\n",
       "      <td>0.318819</td>\n",
       "      <td>0.580408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>0.322718</td>\n",
       "      <td>0.585350</td>\n",
       "      <td>0.185217</td>\n",
       "      <td>0.315449</td>\n",
       "      <td>0.593451</td>\n",
       "      <td>0.189995</td>\n",
       "      <td>0.324927</td>\n",
       "      <td>0.582963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>0.320969</td>\n",
       "      <td>0.571069</td>\n",
       "      <td>0.186806</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.589962</td>\n",
       "      <td>0.198367</td>\n",
       "      <td>0.328574</td>\n",
       "      <td>0.564588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Loss   MSE_NN1   MAE_NN1    R2_NN1   MSE_NN2  \\\n",
       "0             mean_absolute_error  0.186119  0.318390  0.591471  0.191439   \n",
       "1              mean_squared_error  0.188908  0.322718  0.585350  0.185217   \n",
       "2  mean_squared_logarithmic_error  0.195414  0.320969  0.571069  0.186806   \n",
       "\n",
       "    MAE_NN2    R2_NN2   MSE_NN3   MAE_NN3    R2_NN3  \n",
       "0  0.316403  0.579793  0.191159  0.318819  0.580408  \n",
       "1  0.315449  0.593451  0.189995  0.324927  0.582963  \n",
       "2  0.317900  0.589962  0.198367  0.328574  0.564588  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df3 = pd.DataFrame({\n",
    "    'Loss': losses,\n",
    "    'MSE_NN1': mse_final1,\n",
    "    'MAE_NN1': mae_final1,\n",
    "    'R2_NN1': r2_final1,\n",
    "    'MSE_NN2': mse_final2,\n",
    "    'MAE_NN2': mae_final2,\n",
    "    'R2_NN2': r2_final2,\n",
    "    'MSE_NN3': mse_final3,\n",
    "    'MAE_NN3': mae_final3,\n",
    "    'R2_NN3': r2_final3\n",
    "})\n",
    "\n",
    "result_df3.to_csv('output/results_NN_losses.csv', index = False, header=True)\n",
    "\n",
    "result_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50)\n",
    "ridge = Ridge(alpha=5)\n",
    "huber = HuberRegressor(alpha=10, epsilon=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1 = buildNN_adv(X, num_hidden_layers = 4, \n",
    "                          hidden_nodes = 128,\n",
    "                          regularizer=False,\n",
    "                          do = 0.1,\n",
    "                          act = 'tanh')\n",
    "\n",
    "NN2 = buildNN_adv(X, num_hidden_layers = 2, \n",
    "                          hidden_nodes = 128, \n",
    "                          regularizer=False,\n",
    "                          do = do_value,\n",
    "                          act = 'tanh')\n",
    "\n",
    "NN3= buildNN_adv(X, num_hidden_layers = 1, \n",
    "                          hidden_nodes = 128,\n",
    "                          regularizer=False,\n",
    "                          do = do_value,\n",
    "                          act = 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n",
      "Ignored MSE = 0.1854306138774688\n",
      "Train MSE = 0.0908593748777104\n",
      "Test MSE = 0.17965943200400852\n",
      "Sequential\n",
      "Train on 18726 samples, validate on 4682 samples\n",
      "Epoch 1/30\n",
      "18726/18726 [==============================] - 12s 633us/sample - loss: 0.5449 - mean_absolute_error: 0.5449 - mean_squared_error: 0.7367 - val_loss: 0.3440 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.2212\n",
      "Epoch 2/30\n",
      "18726/18726 [==============================] - 8s 432us/sample - loss: 0.3723 - mean_absolute_error: 0.3723 - mean_squared_error: 0.2502 - val_loss: 0.3351 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.2154\n",
      "Epoch 3/30\n",
      "18726/18726 [==============================] - 6s 302us/sample - loss: 0.3659 - mean_absolute_error: 0.3659 - mean_squared_error: 0.2424 - val_loss: 0.3301 - val_mean_absolute_error: 0.3301 - val_mean_squared_error: 0.2157\n",
      "Epoch 4/30\n",
      "18726/18726 [==============================] - 12s 627us/sample - loss: 0.3595 - mean_absolute_error: 0.3595 - mean_squared_error: 0.2370 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2057\n",
      "Epoch 5/30\n",
      "18726/18726 [==============================] - 9s 468us/sample - loss: 0.3576 - mean_absolute_error: 0.3576 - mean_squared_error: 0.2353 - val_loss: 0.3598 - val_mean_absolute_error: 0.3598 - val_mean_squared_error: 0.2181\n",
      "Epoch 6/30\n",
      "18726/18726 [==============================] - 9s 464us/sample - loss: 0.3562 - mean_absolute_error: 0.3562 - mean_squared_error: 0.2364 - val_loss: 0.4021 - val_mean_absolute_error: 0.4021 - val_mean_squared_error: 0.2519error: 0.3562 - mean_s\n",
      "Epoch 7/30\n",
      "18726/18726 [==============================] - 10s 545us/sample - loss: 0.3552 - mean_absolute_error: 0.3552 - mean_squared_error: 0.2312 - val_loss: 0.3276 - val_mean_absolute_error: 0.3276 - val_mean_squared_error: 0.2054\n",
      "Epoch 8/30\n",
      "18726/18726 [==============================] - 8s 439us/sample - loss: 0.3544 - mean_absolute_error: 0.3544 - mean_squared_error: 0.2321 - val_loss: 0.3361 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.2029\n",
      "Epoch 9/30\n",
      "18726/18726 [==============================] - 9s 479us/sample - loss: 0.3533 - mean_absolute_error: 0.3533 - mean_squared_error: 0.2293 - val_loss: 0.3250 - val_mean_absolute_error: 0.3250 - val_mean_squared_error: 0.2017\n",
      "Epoch 10/30\n",
      "18726/18726 [==============================] - 9s 502us/sample - loss: 0.3540 - mean_absolute_error: 0.3540 - mean_squared_error: 0.2309 - val_loss: 0.3257 - val_mean_absolute_error: 0.3257 - val_mean_squared_error: 0.2034\n",
      "Epoch 11/30\n",
      "18726/18726 [==============================] - 7s 380us/sample - loss: 0.3516 - mean_absolute_error: 0.3516 - mean_squared_error: 0.2291 - val_loss: 0.3407 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.2060\n",
      "Epoch 12/30\n",
      "18726/18726 [==============================] - 11s 599us/sample - loss: 0.3502 - mean_absolute_error: 0.3502 - mean_squared_error: 0.2256 - val_loss: 0.3270 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.2073\n",
      "Epoch 13/30\n",
      "18726/18726 [==============================] - 9s 505us/sample - loss: 0.3514 - mean_absolute_error: 0.3514 - mean_squared_error: 0.2274 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2014\n",
      "Epoch 14/30\n",
      "18726/18726 [==============================] - 5s 292us/sample - loss: 0.3466 - mean_absolute_error: 0.3466 - mean_squared_error: 0.2248 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234 - val_mean_squared_error: 0.2041\n",
      "Epoch 15/30\n",
      "18726/18726 [==============================] - 12s 640us/sample - loss: 0.3485 - mean_absolute_error: 0.3485 - mean_squared_error: 0.2250 - val_loss: 0.3311 - val_mean_absolute_error: 0.3311 - val_mean_squared_error: 0.1992\n",
      "Epoch 16/30\n",
      "18726/18726 [==============================] - 9s 502us/sample - loss: 0.3496 - mean_absolute_error: 0.3496 - mean_squared_error: 0.2311 - val_loss: 0.3268 - val_mean_absolute_error: 0.3268 - val_mean_squared_error: 0.2062\n",
      "Epoch 17/30\n",
      "18726/18726 [==============================] - 10s 557us/sample - loss: 0.3487 - mean_absolute_error: 0.3487 - mean_squared_error: 0.2257 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.2241\n",
      "Epoch 18/30\n",
      "18726/18726 [==============================] - 10s 523us/sample - loss: 0.3439 - mean_absolute_error: 0.3439 - mean_squared_error: 0.2198 - val_loss: 0.3300 - val_mean_absolute_error: 0.3300 - val_mean_squared_error: 0.2122\n",
      "Epoch 19/30\n",
      "18726/18726 [==============================] - 9s 473us/sample - loss: 0.3447 - mean_absolute_error: 0.3447 - mean_squared_error: 0.2215 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_mean_squared_error: 0.2066\n",
      "Epoch 20/30\n",
      "18726/18726 [==============================] - 12s 649us/sample - loss: 0.3411 - mean_absolute_error: 0.3411 - mean_squared_error: 0.2179 - val_loss: 0.3251 - val_mean_absolute_error: 0.3251 - val_mean_squared_error: 0.2112\n",
      "Epoch 21/30\n",
      "18726/18726 [==============================] - 8s 444us/sample - loss: 0.3453 - mean_absolute_error: 0.3453 - mean_squared_error: 0.2204 - val_loss: 0.3535 - val_mean_absolute_error: 0.3535 - val_mean_squared_error: 0.2114\n",
      "Epoch 22/30\n",
      "18726/18726 [==============================] - 13s 673us/sample - loss: 0.3426 - mean_absolute_error: 0.3426 - mean_squared_error: 0.2185 - val_loss: 0.3323 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.2187\n",
      "Epoch 23/30\n",
      "18726/18726 [==============================] - 9s 489us/sample - loss: 0.3419 - mean_absolute_error: 0.3419 - mean_squared_error: 0.2169 - val_loss: 0.3381 - val_mean_absolute_error: 0.3381 - val_mean_squared_error: 0.2294\n",
      "Epoch 24/30\n",
      "18726/18726 [==============================] - 10s 557us/sample - loss: 0.3432 - mean_absolute_error: 0.3432 - mean_squared_error: 0.2191 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.2158\n",
      "Epoch 25/30\n",
      "18726/18726 [==============================] - 11s 566us/sample - loss: 0.3427 - mean_absolute_error: 0.3427 - mean_squared_error: 0.2182 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_mean_squared_error: 0.2074\n",
      "Epoch 26/30\n",
      "18726/18726 [==============================] - 12s 652us/sample - loss: 0.3400 - mean_absolute_error: 0.3400 - mean_squared_error: 0.2165 - val_loss: 0.3266 - val_mean_absolute_error: 0.3266 - val_mean_squared_error: 0.1962\n",
      "Epoch 27/30\n",
      "18726/18726 [==============================] - 11s 588us/sample - loss: 0.3415 - mean_absolute_error: 0.3415 - mean_squared_error: 0.2182 - val_loss: 0.3338 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.2031\n",
      "Epoch 28/30\n",
      "18726/18726 [==============================] - 12s 633us/sample - loss: 0.3385 - mean_absolute_error: 0.3385 - mean_squared_error: 0.2148 - val_loss: 0.3239 - val_mean_absolute_error: 0.3239 - val_mean_squared_error: 0.1953\n",
      "Epoch 29/30\n",
      "18726/18726 [==============================] - 10s 550us/sample - loss: 0.3401 - mean_absolute_error: 0.3401 - mean_squared_error: 0.2153 - val_loss: 0.3335 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.2000\n",
      "Epoch 30/30\n",
      "18726/18726 [==============================] - 10s 513us/sample - loss: 0.3385 - mean_absolute_error: 0.3385 - mean_squared_error: 0.2152 - val_loss: 0.3222 - val_mean_absolute_error: 0.3222 - val_mean_squared_error: 0.1958\n",
      "Ignored MSE = 0.19178494888766395\n",
      "Train MSE = 0.18883668570864853\n",
      "Test MSE = 0.18857516489337928\n",
      "Sequential\n",
      "Train on 18726 samples, validate on 4682 samples\n",
      "Epoch 1/30\n",
      "18726/18726 [==============================] - 9s 463us/sample - loss: 0.9900 - mean_absolute_error: 0.9900 - mean_squared_error: 1.9013 - val_loss: 0.3839 - val_mean_absolute_error: 0.3839 - val_mean_squared_error: 0.2741\n",
      "Epoch 2/30\n",
      "18726/18726 [==============================] - 6s 309us/sample - loss: 0.6522 - mean_absolute_error: 0.6522 - mean_squared_error: 0.6903 - val_loss: 0.4077 - val_mean_absolute_error: 0.4077 - val_mean_squared_error: 0.2747\n",
      "Epoch 3/30\n",
      "18726/18726 [==============================] - 9s 457us/sample - loss: 0.6220 - mean_absolute_error: 0.6220 - mean_squared_error: 0.6317 - val_loss: 0.3577 - val_mean_absolute_error: 0.3577 - val_mean_squared_error: 0.2391\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18726/18726 [==============================] - 5s 290us/sample - loss: 0.5964 - mean_absolute_error: 0.5964 - mean_squared_error: 0.5821 - val_loss: 0.3623 - val_mean_absolute_error: 0.3623 - val_mean_squared_error: 0.2334\n",
      "Epoch 5/30\n",
      "18726/18726 [==============================] - 5s 275us/sample - loss: 0.5782 - mean_absolute_error: 0.5782 - mean_squared_error: 0.5512 - val_loss: 0.3540 - val_mean_absolute_error: 0.3540 - val_mean_squared_error: 0.2471\n",
      "Epoch 6/30\n",
      "18726/18726 [==============================] - 3s 185us/sample - loss: 0.5568 - mean_absolute_error: 0.5568 - mean_squared_error: 0.5125 - val_loss: 0.3469 - val_mean_absolute_error: 0.3469 - val_mean_squared_error: 0.2320\n",
      "Epoch 7/30\n",
      "18726/18726 [==============================] - 8s 437us/sample - loss: 0.5443 - mean_absolute_error: 0.5443 - mean_squared_error: 0.4925 - val_loss: 0.3438 - val_mean_absolute_error: 0.3438 - val_mean_squared_error: 0.2221\n",
      "Epoch 8/30\n",
      "18726/18726 [==============================] - 6s 316us/sample - loss: 0.5209 - mean_absolute_error: 0.5209 - mean_squared_error: 0.4592 - val_loss: 0.3517 - val_mean_absolute_error: 0.3517 - val_mean_squared_error: 0.2402\n",
      "Epoch 9/30\n",
      "18726/18726 [==============================] - 5s 258us/sample - loss: 0.5069 - mean_absolute_error: 0.5069 - mean_squared_error: 0.4325 - val_loss: 0.3445 - val_mean_absolute_error: 0.3445 - val_mean_squared_error: 0.2201\n",
      "Epoch 10/30\n",
      "18726/18726 [==============================] - 6s 304us/sample - loss: 0.4828 - mean_absolute_error: 0.4828 - mean_squared_error: 0.3969 - val_loss: 0.3506 - val_mean_absolute_error: 0.3506 - val_mean_squared_error: 0.2441\n",
      "Epoch 11/30\n",
      "18726/18726 [==============================] - 7s 390us/sample - loss: 0.4698 - mean_absolute_error: 0.4698 - mean_squared_error: 0.3775 - val_loss: 0.3551 - val_mean_absolute_error: 0.3551 - val_mean_squared_error: 0.2204\n",
      "Epoch 12/30\n",
      "18726/18726 [==============================] - 6s 320us/sample - loss: 0.4598 - mean_absolute_error: 0.4598 - mean_squared_error: 0.3618 - val_loss: 0.3386 - val_mean_absolute_error: 0.3386 - val_mean_squared_error: 0.2134\n",
      "Epoch 13/30\n",
      "18726/18726 [==============================] - 5s 286us/sample - loss: 0.4393 - mean_absolute_error: 0.4393 - mean_squared_error: 0.3366 - val_loss: 0.3389 - val_mean_absolute_error: 0.3389 - val_mean_squared_error: 0.2151\n",
      "Epoch 14/30\n",
      "18726/18726 [==============================] - 8s 419us/sample - loss: 0.4348 - mean_absolute_error: 0.4348 - mean_squared_error: 0.3298 - val_loss: 0.3367 - val_mean_absolute_error: 0.3367 - val_mean_squared_error: 0.2182\n",
      "Epoch 15/30\n",
      "18726/18726 [==============================] - 6s 325us/sample - loss: 0.4249 - mean_absolute_error: 0.4249 - mean_squared_error: 0.3160 - val_loss: 0.3340 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.2151\n",
      "Epoch 16/30\n",
      "18726/18726 [==============================] - 6s 299us/sample - loss: 0.4143 - mean_absolute_error: 0.4143 - mean_squared_error: 0.3050 - val_loss: 0.3352 - val_mean_absolute_error: 0.3352 - val_mean_squared_error: 0.2150\n",
      "Epoch 17/30\n",
      "18726/18726 [==============================] - 6s 311us/sample - loss: 0.4040 - mean_absolute_error: 0.4040 - mean_squared_error: 0.2942 - val_loss: 0.3356 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.2236\n",
      "Epoch 18/30\n",
      "18726/18726 [==============================] - 4s 202us/sample - loss: 0.3960 - mean_absolute_error: 0.3960 - mean_squared_error: 0.2805 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2139\n",
      "Epoch 19/30\n",
      "18726/18726 [==============================] - 3s 166us/sample - loss: 0.3893 - mean_absolute_error: 0.3893 - mean_squared_error: 0.2737 - val_loss: 0.3487 - val_mean_absolute_error: 0.3487 - val_mean_squared_error: 0.2154\n",
      "Epoch 20/30\n",
      "18726/18726 [==============================] - 3s 158us/sample - loss: 0.3855 - mean_absolute_error: 0.3855 - mean_squared_error: 0.2701 - val_loss: 0.3315 - val_mean_absolute_error: 0.3315 - val_mean_squared_error: 0.2125\n",
      "Epoch 21/30\n",
      "18726/18726 [==============================] - 3s 148us/sample - loss: 0.3780 - mean_absolute_error: 0.3780 - mean_squared_error: 0.2598 - val_loss: 0.3310 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2094\n",
      "Epoch 22/30\n",
      "18726/18726 [==============================] - 3s 136us/sample - loss: 0.3720 - mean_absolute_error: 0.3720 - mean_squared_error: 0.2558 - val_loss: 0.3329 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.2105\n",
      "Epoch 23/30\n",
      "18726/18726 [==============================] - 7s 375us/sample - loss: 0.3701 - mean_absolute_error: 0.3701 - mean_squared_error: 0.2515 - val_loss: 0.3312 - val_mean_absolute_error: 0.3312 - val_mean_squared_error: 0.2105\n",
      "Epoch 24/30\n",
      "18726/18726 [==============================] - 8s 430us/sample - loss: 0.3656 - mean_absolute_error: 0.3656 - mean_squared_error: 0.2464 - val_loss: 0.3335 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.2171\n",
      "Epoch 25/30\n",
      "18726/18726 [==============================] - 7s 362us/sample - loss: 0.3618 - mean_absolute_error: 0.3618 - mean_squared_error: 0.2406 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2069\n",
      "Epoch 26/30\n",
      "18726/18726 [==============================] - 5s 247us/sample - loss: 0.3591 - mean_absolute_error: 0.3591 - mean_squared_error: 0.2391 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2163\n",
      "Epoch 27/30\n",
      "18726/18726 [==============================] - 3s 158us/sample - loss: 0.3556 - mean_absolute_error: 0.3556 - mean_squared_error: 0.2347 - val_loss: 0.3288 - val_mean_absolute_error: 0.3288 - val_mean_squared_error: 0.2092\n",
      "Epoch 28/30\n",
      "18726/18726 [==============================] - 3s 146us/sample - loss: 0.3529 - mean_absolute_error: 0.3529 - mean_squared_error: 0.2333 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.2079\n",
      "Epoch 29/30\n",
      "18726/18726 [==============================] - 3s 157us/sample - loss: 0.3505 - mean_absolute_error: 0.3505 - mean_squared_error: 0.2306 - val_loss: 0.3312 - val_mean_absolute_error: 0.3312 - val_mean_squared_error: 0.2140\n",
      "Epoch 30/30\n",
      "18726/18726 [==============================] - 4s 208us/sample - loss: 0.3492 - mean_absolute_error: 0.3492 - mean_squared_error: 0.2264 - val_loss: 0.3314 - val_mean_absolute_error: 0.3314 - val_mean_squared_error: 0.2190\n",
      "Ignored MSE = 0.2119870049923725\n",
      "Train MSE = 0.21350813428898807\n",
      "Test MSE = 0.20747365571550347\n",
      "Sequential\n",
      "Train on 18726 samples, validate on 4682 samples\n",
      "Epoch 1/30\n",
      "18726/18726 [==============================] - 4s 195us/sample - loss: 1.4652 - mean_absolute_error: 1.4652 - mean_squared_error: 4.2842 - val_loss: 0.3922 - val_mean_absolute_error: 0.3922 - val_mean_squared_error: 0.2877\n",
      "Epoch 2/30\n",
      "18726/18726 [==============================] - 3s 182us/sample - loss: 0.7561 - mean_absolute_error: 0.7561 - mean_squared_error: 1.0285 - val_loss: 0.3578 - val_mean_absolute_error: 0.3578 - val_mean_squared_error: 0.2573\n",
      "Epoch 3/30\n",
      "18726/18726 [==============================] - 3s 174us/sample - loss: 0.6972 - mean_absolute_error: 0.6972 - mean_squared_error: 0.8355 - val_loss: 0.3638 - val_mean_absolute_error: 0.3638 - val_mean_squared_error: 0.2596\n",
      "Epoch 4/30\n",
      "18726/18726 [==============================] - 3s 158us/sample - loss: 0.6475 - mean_absolute_error: 0.6475 - mean_squared_error: 0.7279 - val_loss: 0.3434 - val_mean_absolute_error: 0.3434 - val_mean_squared_error: 0.2295\n",
      "Epoch 5/30\n",
      "18726/18726 [==============================] - 3s 172us/sample - loss: 0.6082 - mean_absolute_error: 0.6082 - mean_squared_error: 0.6302 - val_loss: 0.3449 - val_mean_absolute_error: 0.3449 - val_mean_squared_error: 0.2343\n",
      "Epoch 6/30\n",
      "18726/18726 [==============================] - 3s 181us/sample - loss: 0.5767 - mean_absolute_error: 0.5767 - mean_squared_error: 0.5734 - val_loss: 0.3599 - val_mean_absolute_error: 0.3599 - val_mean_squared_error: 0.2605\n",
      "Epoch 7/30\n",
      "18726/18726 [==============================] - 3s 166us/sample - loss: 0.5404 - mean_absolute_error: 0.5404 - mean_squared_error: 0.5043 - val_loss: 0.3422 - val_mean_absolute_error: 0.3422 - val_mean_squared_error: 0.2388\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18726/18726 [==============================] - 3s 154us/sample - loss: 0.5069 - mean_absolute_error: 0.5069 - mean_squared_error: 0.4467 - val_loss: 0.3308 - val_mean_absolute_error: 0.3308 - val_mean_squared_error: 0.2115\n",
      "Epoch 9/30\n",
      "18726/18726 [==============================] - 3s 158us/sample - loss: 0.4771 - mean_absolute_error: 0.4771 - mean_squared_error: 0.4040 - val_loss: 0.3353 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.2158\n",
      "Epoch 10/30\n",
      "18726/18726 [==============================] - 3s 170us/sample - loss: 0.4561 - mean_absolute_error: 0.4561 - mean_squared_error: 0.3678 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2027\n",
      "Epoch 11/30\n",
      "18726/18726 [==============================] - 3s 165us/sample - loss: 0.4364 - mean_absolute_error: 0.4364 - mean_squared_error: 0.3422 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2169\n",
      "Epoch 12/30\n",
      "18726/18726 [==============================] - 3s 157us/sample - loss: 0.4149 - mean_absolute_error: 0.4149 - mean_squared_error: 0.3102 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.2196\n",
      "Epoch 13/30\n",
      "18726/18726 [==============================] - 3s 169us/sample - loss: 0.3979 - mean_absolute_error: 0.3979 - mean_squared_error: 0.2903 - val_loss: 0.3292 - val_mean_absolute_error: 0.3292 - val_mean_squared_error: 0.2029\n",
      "Epoch 14/30\n",
      "18726/18726 [==============================] - 3s 173us/sample - loss: 0.3850 - mean_absolute_error: 0.3850 - mean_squared_error: 0.2739 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2125\n",
      "Epoch 15/30\n",
      "18726/18726 [==============================] - 3s 172us/sample - loss: 0.3753 - mean_absolute_error: 0.3753 - mean_squared_error: 0.2631 - val_loss: 0.3283 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2054\n",
      "Epoch 16/30\n",
      "18726/18726 [==============================] - 3s 186us/sample - loss: 0.3678 - mean_absolute_error: 0.3678 - mean_squared_error: 0.2537 - val_loss: 0.3265 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2083\n",
      "Epoch 17/30\n",
      "18726/18726 [==============================] - 4s 193us/sample - loss: 0.3627 - mean_absolute_error: 0.3627 - mean_squared_error: 0.2472 - val_loss: 0.3272 - val_mean_absolute_error: 0.3272 - val_mean_squared_error: 0.2089\n",
      "Epoch 18/30\n",
      "18726/18726 [==============================] - 4s 203us/sample - loss: 0.3552 - mean_absolute_error: 0.3552 - mean_squared_error: 0.2383 - val_loss: 0.3295 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.2061\n",
      "Epoch 19/30\n",
      "18726/18726 [==============================] - 4s 206us/sample - loss: 0.3541 - mean_absolute_error: 0.3541 - mean_squared_error: 0.2355 - val_loss: 0.3294 - val_mean_absolute_error: 0.3294 - val_mean_squared_error: 0.2100\n",
      "Epoch 20/30\n",
      "18726/18726 [==============================] - 4s 210us/sample - loss: 0.3515 - mean_absolute_error: 0.3515 - mean_squared_error: 0.2295 - val_loss: 0.3291 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2086\n",
      "Epoch 21/30\n",
      "18726/18726 [==============================] - 4s 208us/sample - loss: 0.3510 - mean_absolute_error: 0.3510 - mean_squared_error: 0.2316 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2080\n",
      "Epoch 22/30\n",
      "18726/18726 [==============================] - 4s 196us/sample - loss: 0.3511 - mean_absolute_error: 0.3511 - mean_squared_error: 0.2321 - val_loss: 0.3344 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.2194\n",
      "Epoch 23/30\n",
      "18726/18726 [==============================] - 4s 211us/sample - loss: 0.3485 - mean_absolute_error: 0.3485 - mean_squared_error: 0.2292 - val_loss: 0.3344 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.2057\n",
      "Epoch 24/30\n",
      "18726/18726 [==============================] - 4s 206us/sample - loss: 0.3488 - mean_absolute_error: 0.3488 - mean_squared_error: 0.2285 - val_loss: 0.3288 - val_mean_absolute_error: 0.3288 - val_mean_squared_error: 0.2064\n",
      "Epoch 25/30\n",
      "18726/18726 [==============================] - 4s 192us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - mean_squared_error: 0.2264 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287 - val_mean_squared_error: 0.2059\n",
      "Epoch 26/30\n",
      "18726/18726 [==============================] - 4s 196us/sample - loss: 0.3485 - mean_absolute_error: 0.3485 - mean_squared_error: 0.2277 - val_loss: 0.3302 - val_mean_absolute_error: 0.3302 - val_mean_squared_error: 0.2071\n",
      "Epoch 27/30\n",
      "18726/18726 [==============================] - 4s 190us/sample - loss: 0.3496 - mean_absolute_error: 0.3496 - mean_squared_error: 0.2297 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.2087\n",
      "Epoch 28/30\n",
      "18726/18726 [==============================] - 4s 213us/sample - loss: 0.3467 - mean_absolute_error: 0.3467 - mean_squared_error: 0.2258 - val_loss: 0.3282 - val_mean_absolute_error: 0.3282 - val_mean_squared_error: 0.2045\n",
      "Epoch 29/30\n",
      "18726/18726 [==============================] - 4s 219us/sample - loss: 0.3477 - mean_absolute_error: 0.3477 - mean_squared_error: 0.2271 - val_loss: 0.3327 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.2159\n",
      "Epoch 30/30\n",
      "18726/18726 [==============================] - 4s 212us/sample - loss: 0.3477 - mean_absolute_error: 0.3477 - mean_squared_error: 0.2294 - val_loss: 0.3270 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.2061\n",
      "Ignored MSE = 0.19841362981253793\n",
      "Train MSE = 0.19984878378607382\n",
      "Test MSE = 0.19622619267403832\n"
     ]
    }
   ],
   "source": [
    "MODELS = [NN1, NN2, NN3]\n",
    "\n",
    "## FIRST RF\n",
    "X_train1, X_ignore, y_train1, y_ignore = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "    \n",
    "#Train model on the randomly sectioned train data\n",
    "rf.fit(X_train1,y_train1)\n",
    "\n",
    "print(rf.__class__.__name__)\n",
    "\n",
    "# Display performance on ignored set\n",
    "y_pred = rf.predict(X_ignore)\n",
    "mse = mean_squared_error(y_ignore, y_pred)\n",
    "print(\"Ignored MSE = {}\".format(mse))\n",
    "\n",
    "rf_out = rf.predict(X_train)\n",
    "rf_out = np.reshape(rf_out, (rf_out.shape[0], 1) )\n",
    "mse = mean_squared_error(y_train, rf_out)\n",
    "print(\"Train MSE = {}\".format(mse))\n",
    "fusion_vector_train = rf_out\n",
    "\n",
    "rf_out = rf.predict(X_test)\n",
    "rf_out = np.reshape(rf_out, (rf_out.shape[0], 1) )\n",
    "fusion_vector_test = rf_out\n",
    "\n",
    "mse = mean_squared_error(y_test, rf_out)\n",
    "print(\"Test MSE = {}\".format(mse))\n",
    "\n",
    "for model in MODELS:\n",
    "    print(model.__class__.__name__)\n",
    "        \n",
    "    X_train1, X_ignore, y_train1, y_ignore = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "    \n",
    "    #Train model on the randomly sectioned train data\n",
    "    model.fit(X_train1, y_train1, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "               validation_split = 0.2)\n",
    "    \n",
    "    # Display performance on ignored set\n",
    "    y_pred = model.predict(X_ignore)\n",
    "    mse = mean_squared_error(y_ignore, y_pred)\n",
    "    print(\"Ignored MSE = {}\".format(mse))\n",
    "    \n",
    "    model_out = model.predict(X_train)\n",
    "    model_out = np.reshape(model_out, (model_out.shape[0], 1) )\n",
    "    mse = mean_squared_error(y_train, model_out)\n",
    "    print(\"Train MSE = {}\".format(mse))\n",
    "    \n",
    "    # Fusion Train\n",
    "    fusion_vector_train = np.hstack((fusion_vector_train,model_out))\n",
    "    \n",
    "    model_out = model.predict(X_test)\n",
    "    model_out = np.reshape(model_out, (model_out.shape[0], 1) )\n",
    "    mse = mean_squared_error(y_test, model_out)\n",
    "    print(\"Test MSE = {}\".format(mse))\n",
    "    \n",
    "    # Fusion Test\n",
    "    fusion_vector_test = np.hstack((fusion_vector_test,model_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=50, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(fusion_vector_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.19364103517168627\n"
     ]
    }
   ],
   "source": [
    "rf_out = rf.predict(fusion_vector_test)\n",
    "mse = mean_squared_error(y_test, rf_out)\n",
    "print(\"Test MSE = {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31211 samples, validate on 7803 samples\n",
      "Epoch 1/30\n",
      "31211/31211 [==============================] - 8s 247us/sample - loss: 0.5169 - mean_absolute_error: 0.5169 - mean_squared_error: 0.6079 - val_loss: 0.2820 - val_mean_absolute_error: 0.2820 - val_mean_squared_error: 0.1521\n",
      "Epoch 2/30\n",
      "31211/31211 [==============================] - 7s 222us/sample - loss: 0.3791 - mean_absolute_error: 0.3791 - mean_squared_error: 0.2460 - val_loss: 0.2791 - val_mean_absolute_error: 0.2791 - val_mean_squared_error: 0.1371\n",
      "Epoch 3/30\n",
      "31211/31211 [==============================] - 6s 202us/sample - loss: 0.3413 - mean_absolute_error: 0.3413 - mean_squared_error: 0.2056 - val_loss: 0.2593 - val_mean_absolute_error: 0.2593 - val_mean_squared_error: 0.1253\n",
      "Epoch 4/30\n",
      "31211/31211 [==============================] - 7s 214us/sample - loss: 0.3188 - mean_absolute_error: 0.3188 - mean_squared_error: 0.1833 - val_loss: 0.2002 - val_mean_absolute_error: 0.2002 - val_mean_squared_error: 0.0956\n",
      "Epoch 5/30\n",
      "31211/31211 [==============================] - 7s 221us/sample - loss: 0.3025 - mean_absolute_error: 0.3025 - mean_squared_error: 0.1682 - val_loss: 0.2222 - val_mean_absolute_error: 0.2222 - val_mean_squared_error: 0.1044\n",
      "Epoch 6/30\n",
      "31211/31211 [==============================] - 7s 218us/sample - loss: 0.2930 - mean_absolute_error: 0.2930 - mean_squared_error: 0.1587 - val_loss: 0.1902 - val_mean_absolute_error: 0.1902 - val_mean_squared_error: 0.0904\n",
      "Epoch 7/30\n",
      "31211/31211 [==============================] - 6s 201us/sample - loss: 0.2844 - mean_absolute_error: 0.2844 - mean_squared_error: 0.1520 - val_loss: 0.3078 - val_mean_absolute_error: 0.3078 - val_mean_squared_error: 0.1555\n",
      "Epoch 8/30\n",
      "31211/31211 [==============================] - 8s 256us/sample - loss: 0.2847 - mean_absolute_error: 0.2847 - mean_squared_error: 0.1523 - val_loss: 0.2129 - val_mean_absolute_error: 0.2129 - val_mean_squared_error: 0.0994\n",
      "Epoch 9/30\n",
      "31211/31211 [==============================] - 10s 319us/sample - loss: 0.2785 - mean_absolute_error: 0.2785 - mean_squared_error: 0.1465 - val_loss: 0.2550 - val_mean_absolute_error: 0.2550 - val_mean_squared_error: 0.1210\n",
      "Epoch 10/30\n",
      "31211/31211 [==============================] - 9s 277us/sample - loss: 0.2744 - mean_absolute_error: 0.2744 - mean_squared_error: 0.1437 - val_loss: 0.1863 - val_mean_absolute_error: 0.1863 - val_mean_squared_error: 0.0887\n",
      "Epoch 11/30\n",
      "31211/31211 [==============================] - 7s 217us/sample - loss: 0.2731 - mean_absolute_error: 0.2731 - mean_squared_error: 0.1427 - val_loss: 0.1870 - val_mean_absolute_error: 0.1870 - val_mean_squared_error: 0.0887\n",
      "Epoch 12/30\n",
      "31211/31211 [==============================] - 6s 207us/sample - loss: 0.2677 - mean_absolute_error: 0.2677 - mean_squared_error: 0.1386 - val_loss: 0.1865 - val_mean_absolute_error: 0.1865 - val_mean_squared_error: 0.0887\n",
      "Epoch 13/30\n",
      "31211/31211 [==============================] - 7s 211us/sample - loss: 0.2662 - mean_absolute_error: 0.2662 - mean_squared_error: 0.1364 - val_loss: 0.2026 - val_mean_absolute_error: 0.2026 - val_mean_squared_error: 0.0949\n",
      "Epoch 14/30\n",
      "31211/31211 [==============================] - 7s 215us/sample - loss: 0.2634 - mean_absolute_error: 0.2634 - mean_squared_error: 0.1349 - val_loss: 0.2051 - val_mean_absolute_error: 0.2051 - val_mean_squared_error: 0.0951\n",
      "Epoch 15/30\n",
      "31211/31211 [==============================] - 7s 223us/sample - loss: 0.2590 - mean_absolute_error: 0.2590 - mean_squared_error: 0.1315 - val_loss: 0.1883 - val_mean_absolute_error: 0.1883 - val_mean_squared_error: 0.0888\n",
      "Epoch 16/30\n",
      "31211/31211 [==============================] - 7s 230us/sample - loss: 0.2565 - mean_absolute_error: 0.2565 - mean_squared_error: 0.1304 - val_loss: 0.1860 - val_mean_absolute_error: 0.1860 - val_mean_squared_error: 0.0883\n",
      "Epoch 17/30\n",
      "31211/31211 [==============================] - 7s 234us/sample - loss: 0.2538 - mean_absolute_error: 0.2538 - mean_squared_error: 0.1278 - val_loss: 0.1906 - val_mean_absolute_error: 0.1906 - val_mean_squared_error: 0.0903\n",
      "Epoch 18/30\n",
      "31211/31211 [==============================] - 8s 260us/sample - loss: 0.2522 - mean_absolute_error: 0.2522 - mean_squared_error: 0.1274 - val_loss: 0.1917 - val_mean_absolute_error: 0.1917 - val_mean_squared_error: 0.0904\n",
      "Epoch 19/30\n",
      "31211/31211 [==============================] - 7s 240us/sample - loss: 0.2479 - mean_absolute_error: 0.2479 - mean_squared_error: 0.1244 - val_loss: 0.2138 - val_mean_absolute_error: 0.2138 - val_mean_squared_error: 0.0999\n",
      "Epoch 20/30\n",
      "31211/31211 [==============================] - 7s 235us/sample - loss: 0.2468 - mean_absolute_error: 0.2468 - mean_squared_error: 0.1234 - val_loss: 0.1850 - val_mean_absolute_error: 0.1850 - val_mean_squared_error: 0.0885\n",
      "Epoch 21/30\n",
      "31211/31211 [==============================] - 7s 235us/sample - loss: 0.2434 - mean_absolute_error: 0.2434 - mean_squared_error: 0.1208 - val_loss: 0.1862 - val_mean_absolute_error: 0.1862 - val_mean_squared_error: 0.0887\n",
      "Epoch 22/30\n",
      "31211/31211 [==============================] - 7s 224us/sample - loss: 0.2434 - mean_absolute_error: 0.2434 - mean_squared_error: 0.1214 - val_loss: 0.2015 - val_mean_absolute_error: 0.2015 - val_mean_squared_error: 0.0944\n",
      "Epoch 23/30\n",
      "31211/31211 [==============================] - 7s 225us/sample - loss: 0.2424 - mean_absolute_error: 0.2424 - mean_squared_error: 0.1211 - val_loss: 0.1983 - val_mean_absolute_error: 0.1983 - val_mean_squared_error: 0.0932\n",
      "Epoch 24/30\n",
      "31211/31211 [==============================] - 8s 252us/sample - loss: 0.2378 - mean_absolute_error: 0.2378 - mean_squared_error: 0.1177 - val_loss: 0.1851 - val_mean_absolute_error: 0.1851 - val_mean_squared_error: 0.0888\n",
      "Epoch 25/30\n",
      "31211/31211 [==============================] - 7s 233us/sample - loss: 0.2372 - mean_absolute_error: 0.2372 - mean_squared_error: 0.1175 - val_loss: 0.2286 - val_mean_absolute_error: 0.2286 - val_mean_squared_error: 0.1070\n",
      "Epoch 26/30\n",
      "31211/31211 [==============================] - 8s 253us/sample - loss: 0.2334 - mean_absolute_error: 0.2334 - mean_squared_error: 0.1147 - val_loss: 0.2211 - val_mean_absolute_error: 0.2211 - val_mean_squared_error: 0.1031\n",
      "Epoch 27/30\n",
      "31211/31211 [==============================] - 8s 248us/sample - loss: 0.2316 - mean_absolute_error: 0.2316 - mean_squared_error: 0.1144 - val_loss: 0.1861 - val_mean_absolute_error: 0.1861 - val_mean_squared_error: 0.0885\n",
      "Epoch 28/30\n",
      "31211/31211 [==============================] - 7s 240us/sample - loss: 0.2312 - mean_absolute_error: 0.2312 - mean_squared_error: 0.1140 - val_loss: 0.2006 - val_mean_absolute_error: 0.2006 - val_mean_squared_error: 0.0943\n",
      "Epoch 29/30\n",
      "31211/31211 [==============================] - 7s 237us/sample - loss: 0.2283 - mean_absolute_error: 0.2283 - mean_squared_error: 0.1120 - val_loss: 0.1870 - val_mean_absolute_error: 0.1870 - val_mean_squared_error: 0.0898\n",
      "Epoch 30/30\n",
      "31211/31211 [==============================] - 7s 237us/sample - loss: 0.2268 - mean_absolute_error: 0.2268 - mean_squared_error: 0.1110 - val_loss: 0.1892 - val_mean_absolute_error: 0.1892 - val_mean_squared_error: 0.0907\n",
      "final results ---  MSE = 0.1957203353689293, MAE = 0.32803307128984704, R2 = 0.570396532309966\n"
     ]
    }
   ],
   "source": [
    "numLayers = 2\n",
    "numNodes = 128\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.001, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "nn_model = buildNN_adv(fusion_vector_train, num_hidden_layers = numLayers, hidden_nodes = numNodes,\n",
    "                      regularizer = False, do = 0.2)\n",
    "nn_model.fit(fusion_vector_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, callbacks = [tensorboard],\n",
    "            validation_split = 0.2)\n",
    "\n",
    "mse_f, r2_f, mae_f = evaluateModel(nn_model, fusion_vector_test, y_test)\n",
    "print('final results ---  MSE = {}, MAE = {}, R2 = {}'.format(mse_f,mae_f,r2_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1: MSE = 0.20007391655180432, MAE = 0.3261489488214801, R2 = 0.5608404809701414\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb-env",
   "language": "python",
   "name": "airbnb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
